{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(1,10),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(10,10),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(10,1, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N = self.layers(x)\n",
    "        return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x, loss_fn, optimizer):\n",
    "    x = x.to(device)\n",
    "    def closure():\n",
    "        loss = loss_fn(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    torch.nn.utils.clip_grad_value_(model.parameters(), 1)\n",
    "    optimizer.step(closure)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 2\n",
    "global Z\n",
    "Z = 1\n",
    "global e\n",
    "#e = -1.602e-19\n",
    "e = -1\n",
    "global hbar\n",
    "#hbar = 1.054e-34\n",
    "hbar = 1\n",
    "global m\n",
    "#m = 9.109e-31\n",
    "m = 1\n",
    "global l\n",
    "l = 0\n",
    "global Phi_0\n",
    "\n",
    "V = lambda r: -(Z*e**2)/r\n",
    "Phi_aux = lambda r: r*torch.exp(-beta*r) * model.forward(r)\n",
    "Phi_t = lambda r: Phi_aux(r) - Phi_0*torch.trapezoid(Phi_0[100:]*Phi_aux(r)[100:], r[100:],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(r):\n",
    "    r.requires_grad = True\n",
    "    \n",
    "    Phi = Phi_t(r)    \n",
    "    Phi_t_r = torch.autograd.grad(Phi, r, grad_outputs=torch.ones_like(Phi), create_graph=True)[0]\n",
    "    Phi_t_r_r = torch.autograd.grad(Phi_t_r, r, grad_outputs=torch.ones_like(Phi_t_r), create_graph=True)[0]\n",
    "    H_Phi = -(hbar**2/(2*m))*Phi_t_r_r + (l*(l+1)*hbar**2/(2*m*r**2) + V(r))*Phi\n",
    "    \n",
    "    norm = torch.trapezoid(Phi[100:]**2,r[100:],dim=0) # integral over r=0 to 6\n",
    "\n",
    "    prom = Phi.size()[0]\n",
    "    \n",
    "    global E\n",
    "    E = torch.trapezoid(Phi[100:]*H_Phi[100:],r[100:],dim=0)/norm \n",
    "    \n",
    "    \n",
    "    return (torch.mean((H_Phi[100:] - E*Phi[100:])**2)*prom)/norm #multiply by m to avoit division by m in the mean function of torh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Linear)):\n",
    "            nn.init.xavier_normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2745])\n",
      "torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "upper_r = 6\n",
    "lower_r = -6\n",
    "steps = 200\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "\n",
    "Phi_0 = torch.Tensor(np.loadtxt(\"file.txt\")).reshape(200,1)\n",
    "print(torch.sqrt(torch.trapezoid(Phi_0[100:]**2,R_train[100:],dim=0)))\n",
    "#Phi_0 = Phi_0/torch.sqrt(torch.trapezoid(Phi_0[100:]**2,R_train[100:],dim=0))\n",
    "Phi_0 = Phi_0.detach()\n",
    "print(Phi_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-9.2641e+05],\n",
      "        [-8.1291e+05],\n",
      "        [-7.1325e+05],\n",
      "        [-6.2574e+05],\n",
      "        [-5.4892e+05],\n",
      "        [-4.8147e+05],\n",
      "        [-4.2227e+05],\n",
      "        [-3.7030e+05],\n",
      "        [-3.2470e+05],\n",
      "        [-2.8468e+05],\n",
      "        [-2.4956e+05],\n",
      "        [-2.1875e+05],\n",
      "        [-1.9172e+05],\n",
      "        [-1.6801e+05],\n",
      "        [-1.4721e+05],\n",
      "        [-1.2897e+05],\n",
      "        [-1.1297e+05],\n",
      "        [-9.8950e+04],\n",
      "        [-8.6654e+04],\n",
      "        [-7.5875e+04],\n",
      "        [-6.6427e+04],\n",
      "        [-5.8147e+04],\n",
      "        [-5.0891e+04],\n",
      "        [-4.4533e+04],\n",
      "        [-3.8964e+04],\n",
      "        [-3.4085e+04],\n",
      "        [-2.9812e+04],\n",
      "        [-2.6070e+04],\n",
      "        [-2.2793e+04],\n",
      "        [-1.9925e+04],\n",
      "        [-1.7414e+04],\n",
      "        [-1.5217e+04],\n",
      "        [-1.3294e+04],\n",
      "        [-1.1611e+04],\n",
      "        [-1.0140e+04],\n",
      "        [-8.8527e+03],\n",
      "        [-7.7271e+03],\n",
      "        [-6.7431e+03],\n",
      "        [-5.8829e+03],\n",
      "        [-5.1312e+03],\n",
      "        [-4.4743e+03],\n",
      "        [-3.9005e+03],\n",
      "        [-3.3992e+03],\n",
      "        [-2.9616e+03],\n",
      "        [-2.5794e+03],\n",
      "        [-2.2459e+03],\n",
      "        [-1.9549e+03],\n",
      "        [-1.7010e+03],\n",
      "        [-1.4795e+03],\n",
      "        [-1.2864e+03],\n",
      "        [-1.1181e+03],\n",
      "        [-9.7143e+02],\n",
      "        [-8.4364e+02],\n",
      "        [-7.3233e+02],\n",
      "        [-6.3542e+02],\n",
      "        [-5.5108e+02],\n",
      "        [-4.7769e+02],\n",
      "        [-4.1386e+02],\n",
      "        [-3.5836e+02],\n",
      "        [-3.1012e+02],\n",
      "        [-2.6822e+02],\n",
      "        [-2.3183e+02],\n",
      "        [-2.0024e+02],\n",
      "        [-1.7283e+02],\n",
      "        [-1.4907e+02],\n",
      "        [-1.2847e+02],\n",
      "        [-1.1062e+02],\n",
      "        [-9.5168e+01],\n",
      "        [-8.1796e+01],\n",
      "        [-7.0233e+01],\n",
      "        [-6.0239e+01],\n",
      "        [-5.1608e+01],\n",
      "        [-4.4158e+01],\n",
      "        [-3.7734e+01],\n",
      "        [-3.2198e+01],\n",
      "        [-2.7432e+01],\n",
      "        [-2.3332e+01],\n",
      "        [-1.9809e+01],\n",
      "        [-1.6784e+01],\n",
      "        [-1.4190e+01],\n",
      "        [-1.1969e+01],\n",
      "        [-1.0068e+01],\n",
      "        [-8.4443e+00],\n",
      "        [-7.0591e+00],\n",
      "        [-5.8794e+00],\n",
      "        [-4.8762e+00],\n",
      "        [-4.0249e+00],\n",
      "        [-3.3038e+00],\n",
      "        [-2.6945e+00],\n",
      "        [-2.1809e+00],\n",
      "        [-1.7490e+00],\n",
      "        [-1.3871e+00],\n",
      "        [-1.0848e+00],\n",
      "        [-8.3325e-01],\n",
      "        [-6.2484e-01],\n",
      "        [-4.5305e-01],\n",
      "        [-3.1224e-01],\n",
      "        [-1.9762e-01],\n",
      "        [-1.0505e-01],\n",
      "        [-3.1023e-02],\n",
      "        [ 2.7481e-02],\n",
      "        [ 7.3025e-02],\n",
      "        [ 1.0779e-01],\n",
      "        [ 1.3364e-01],\n",
      "        [ 1.5215e-01],\n",
      "        [ 1.6465e-01],\n",
      "        [ 1.7226e-01],\n",
      "        [ 1.7593e-01],\n",
      "        [ 1.7646e-01],\n",
      "        [ 1.7452e-01],\n",
      "        [ 1.7066e-01],\n",
      "        [ 1.6534e-01],\n",
      "        [ 1.5895e-01],\n",
      "        [ 1.5179e-01],\n",
      "        [ 1.4414e-01],\n",
      "        [ 1.3618e-01],\n",
      "        [ 1.2811e-01],\n",
      "        [ 1.2003e-01],\n",
      "        [ 1.1207e-01],\n",
      "        [ 1.0430e-01],\n",
      "        [ 9.6782e-02],\n",
      "        [ 8.9564e-02],\n",
      "        [ 8.2675e-02],\n",
      "        [ 7.6137e-02],\n",
      "        [ 6.9960e-02],\n",
      "        [ 6.4149e-02],\n",
      "        [ 5.8702e-02],\n",
      "        [ 5.3614e-02],\n",
      "        [ 4.8876e-02],\n",
      "        [ 4.4476e-02],\n",
      "        [ 4.0399e-02],\n",
      "        [ 3.6632e-02],\n",
      "        [ 3.3158e-02],\n",
      "        [ 2.9961e-02],\n",
      "        [ 2.7025e-02],\n",
      "        [ 2.4332e-02],\n",
      "        [ 2.1868e-02],\n",
      "        [ 1.9617e-02],\n",
      "        [ 1.7563e-02],\n",
      "        [ 1.5693e-02],\n",
      "        [ 1.3992e-02],\n",
      "        [ 1.2447e-02],\n",
      "        [ 1.1047e-02],\n",
      "        [ 9.7785e-03],\n",
      "        [ 8.6321e-03],\n",
      "        [ 7.5973e-03],\n",
      "        [ 6.6644e-03],\n",
      "        [ 5.8248e-03],\n",
      "        [ 5.0703e-03],\n",
      "        [ 4.3933e-03],\n",
      "        [ 3.7869e-03],\n",
      "        [ 3.2446e-03],\n",
      "        [ 2.7606e-03],\n",
      "        [ 2.3293e-03],\n",
      "        [ 1.9458e-03],\n",
      "        [ 1.6055e-03],\n",
      "        [ 1.3043e-03],\n",
      "        [ 1.0384e-03],\n",
      "        [ 8.0420e-04],\n",
      "        [ 5.9863e-04],\n",
      "        [ 4.1877e-04],\n",
      "        [ 2.6201e-04],\n",
      "        [ 1.2596e-04],\n",
      "        [ 8.4676e-06],\n",
      "        [-9.2439e-05],\n",
      "        [-1.7854e-04],\n",
      "        [-2.5145e-04],\n",
      "        [-3.1263e-04],\n",
      "        [-3.6341e-04],\n",
      "        [-4.0499e-04],\n",
      "        [-4.3846e-04],\n",
      "        [-4.6477e-04],\n",
      "        [-4.8482e-04],\n",
      "        [-4.9939e-04],\n",
      "        [-5.0917e-04],\n",
      "        [-5.1478e-04],\n",
      "        [-5.1676e-04],\n",
      "        [-5.1560e-04],\n",
      "        [-5.1172e-04],\n",
      "        [-5.0546e-04],\n",
      "        [-4.9716e-04],\n",
      "        [-4.8707e-04],\n",
      "        [-4.7545e-04],\n",
      "        [-4.6249e-04],\n",
      "        [-4.4838e-04],\n",
      "        [-4.3329e-04],\n",
      "        [-4.1738e-04],\n",
      "        [-4.0079e-04],\n",
      "        [-3.8367e-04],\n",
      "        [-3.6617e-04],\n",
      "        [-3.4844e-04],\n",
      "        [-3.3061e-04],\n",
      "        [-3.1278e-04],\n",
      "        [-2.9503e-04],\n",
      "        [-2.7745e-04],\n",
      "        [-2.6015e-04],\n",
      "        [-2.4317e-04],\n",
      "        [-2.2654e-04],\n",
      "        [-2.1034e-04],\n",
      "        [-1.9471e-04]], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.7843e+10], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "initialize_weights(model)\n",
    "print(Phi_t(R_train))\n",
    "loss_fn(R_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa2e074b9a0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.linspace(lower_r, upper_r, steps).shape)\n",
    "plt.plot(np.linspace(lower_r, upper_r, steps)[100:],np.divide(Phi_0.detach().numpy()[100:],np.linspace(lower_r, upper_r, steps).reshape(200,1)[100:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------- loss: tensor([1.7017e+10], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([1.9238e+10], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([1.7828e+10], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([1.7183e+10], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([1.6138e+10], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([1.4910e+10], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([1.3146e+10], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([1.1043e+10], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([8.6934e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([7.0285e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([5.6359e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([3.9358e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([2.5933e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([1.8296e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([1.1625e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([9.8585e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([1.8548e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([1.8148e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([7.4782e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([4.2865e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([8.6910e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([1.2407e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([1.2787e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([1.0163e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([5.7187e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([2.0730e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([1.6988e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([4.1283e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([5.8251e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([4.5887e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([2.1978e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([96449336.], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([1.2168e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([2.0906e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([2.7776e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([2.9334e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([2.5954e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([2.0015e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([1.4296e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([1.0887e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([1.0633e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([1.2876e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([1.5488e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([1.5864e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([1.3066e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([91061736.], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([71835224.], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([85273288.], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([1.1247e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([1.2270e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([1.0517e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([80361896.], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([75943072.], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([93155080.], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([1.0553e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([95934128.], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([78204816.], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([72627328.], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([80028280.], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([87091088.], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([84735624.], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([76049384.], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([69952136.], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([71001408.], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([75838480.], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([78089256.], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([75320480.], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([70603712.], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([68245584.], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([69361704.], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([71582736.], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([72018792.], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([70097168.], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([67761856.], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([67187040.], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([68530464.], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([69974912.], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([69891184.], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([68546472.], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([67482520.], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([67619424.], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([68384824.], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([68632960.], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([67962656.], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([67025412.], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([66654996.], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([66959324.], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([67312608.], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([67168648.], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([66635848.], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([66246956.], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([66288352.], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([66520432.], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([66522584.], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([66212564.], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([65891372.], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([65830064.], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([65956652.], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([65976944.], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([65773232.], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([65525748.], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([65436056.], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([65452832.], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([65386076.], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([65169420.], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([64928896.], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([64789452.], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([64700768.], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([64542156.], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([64290504.], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([64033180.], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([63838360.], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([63643348.], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([63369744.], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([63034416.], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([62709400.], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([62397084.], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([62045624.], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([61620620.], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([61166068.], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([60718156.], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([60245360.], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([59711984.], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([59136128.], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([58565772.], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([57980744.], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([57358596.], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([56714240.], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([56086292.], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([55463124.], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([54825984.], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([54202280.], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([53607152.], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([53025824.], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([52453972.], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([51913344.], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([51398288.], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([50893692.], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([50411280.], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([49953440.], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([49502496.], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([49064544.], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([48641848.], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([48212316.], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([47786832.], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([47362764.], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([46924956.], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([46484792.], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([46027716.], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([45552596.], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([45065804.], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([44552848.], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([44020692.], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([43461816.], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([42877524.], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([42261512.], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([41621904.], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([40944268.], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([40244972.], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([39508092.], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([38743328.], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([37951324.], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([37133492.], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([36294404.], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([35429180.], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([34554908.], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([33664240.], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([32772554.], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([31883946.], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([31000216.], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([30166618.], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([29603048.], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([31478808.], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([62534196.], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([4.9099e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([2.2169e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([4.8873e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([9.0016e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([1.5101e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([2.4720e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([2.6009e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([1.9864e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([1.9495e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([2.0000e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([1.9920e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([1.7953e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([1.3864e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([8.9846e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([4.6197e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([1.9592e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([2.6372e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([5.3639e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([8.2275e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([7.7115e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([5.5916e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([3.7735e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([2.5694e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([1.7607e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([1.6474e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([2.4621e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([3.5891e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([3.9638e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([3.2128e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([1.9718e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([1.0625e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([82059000.], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([1.1021e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([1.5730e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([1.9351e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([2.0175e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([1.7997e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([1.3958e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([99231456.], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([75867072.], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([76475408.], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([94456888.], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([1.1467e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([1.2377e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([1.1755e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([1.0110e+08], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([83509264.], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([72149416.], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([69694320.], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([74383224.], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([81851056.], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([87348128.], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([87750896.], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([82873904.], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([75315664.], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([68802120.], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([66032216.], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([67339072.], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([70869496.], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([73932080.], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([74590976.], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([72584960.], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([69153632.], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([66065648.], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([64570504.], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([64864408.], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([66208764.], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([67502112.], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([67894936.], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([67179232.], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([65766520.], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([64368996.], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([63579600.], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([63573072.], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([64088140.], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([64641496.], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([64822496.], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([64508236.], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([63873456.], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([63242336.], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([62876484.], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([62848084.], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([63029096.], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([63206156.], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([63210464.], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([63002232.], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([62674760.], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([62368476.], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([62190668.], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([62151544.], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([62185396.], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([62203152.], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([62144872.], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([62008684.], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([61839272.], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([61690772.], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([61591652.], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([61539776.], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([61507960.], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([61466184.], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([61401992.], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([61310524.], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([61209896.], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([61113812.], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([61036116.], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([60975268.], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([60928244.], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([60878424.], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([60821132.], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([60752960.], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([60678712.], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([60603988.], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([60539408.], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([60488524.], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([60445648.], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([60400316.], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([60351648.], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([60294040.], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([60234884.], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([60179620.], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([60132732.], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([60095572.], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([60056036.], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([60017012.], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([59972532.], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([59926448.], grad_fn=<DivBackward0>)\n",
      "Epoch 301\n",
      " ---------------------- loss: tensor([59882816.], grad_fn=<DivBackward0>)\n",
      "Epoch 302\n",
      " ---------------------- loss: tensor([59842332.], grad_fn=<DivBackward0>)\n",
      "Epoch 303\n",
      " ---------------------- loss: tensor([59806368.], grad_fn=<DivBackward0>)\n",
      "Epoch 304\n",
      " ---------------------- loss: tensor([59772088.], grad_fn=<DivBackward0>)\n",
      "Epoch 305\n",
      " ---------------------- loss: tensor([59737736.], grad_fn=<DivBackward0>)\n",
      "Epoch 306\n",
      " ---------------------- loss: tensor([59701928.], grad_fn=<DivBackward0>)\n",
      "Epoch 307\n",
      " ---------------------- loss: tensor([59665008.], grad_fn=<DivBackward0>)\n",
      "Epoch 308\n",
      " ---------------------- loss: tensor([59629976.], grad_fn=<DivBackward0>)\n",
      "Epoch 309\n",
      " ---------------------- loss: tensor([59596944.], grad_fn=<DivBackward0>)\n",
      "Epoch 310\n",
      " ---------------------- loss: tensor([59563700.], grad_fn=<DivBackward0>)\n",
      "Epoch 311\n",
      " ---------------------- loss: tensor([59531376.], grad_fn=<DivBackward0>)\n",
      "Epoch 312\n",
      " ---------------------- loss: tensor([59501396.], grad_fn=<DivBackward0>)\n",
      "Epoch 313\n",
      " ---------------------- loss: tensor([59470888.], grad_fn=<DivBackward0>)\n",
      "Epoch 314\n",
      " ---------------------- loss: tensor([59441664.], grad_fn=<DivBackward0>)\n",
      "Epoch 315\n",
      " ---------------------- loss: tensor([59408972.], grad_fn=<DivBackward0>)\n",
      "Epoch 316\n",
      " ---------------------- loss: tensor([59377344.], grad_fn=<DivBackward0>)\n",
      "Epoch 317\n",
      " ---------------------- loss: tensor([59348444.], grad_fn=<DivBackward0>)\n",
      "Epoch 318\n",
      " ---------------------- loss: tensor([59319484.], grad_fn=<DivBackward0>)\n",
      "Epoch 319\n",
      " ---------------------- loss: tensor([59289948.], grad_fn=<DivBackward0>)\n",
      "Epoch 320\n",
      " ---------------------- loss: tensor([59262144.], grad_fn=<DivBackward0>)\n",
      "Epoch 321\n",
      " ---------------------- loss: tensor([59233572.], grad_fn=<DivBackward0>)\n",
      "Epoch 322\n",
      " ---------------------- loss: tensor([59205116.], grad_fn=<DivBackward0>)\n",
      "Epoch 323\n",
      " ---------------------- loss: tensor([59174856.], grad_fn=<DivBackward0>)\n",
      "Epoch 324\n",
      " ---------------------- loss: tensor([59145900.], grad_fn=<DivBackward0>)\n",
      "Epoch 325\n",
      " ---------------------- loss: tensor([59117512.], grad_fn=<DivBackward0>)\n",
      "Epoch 326\n",
      " ---------------------- loss: tensor([59090036.], grad_fn=<DivBackward0>)\n",
      "Epoch 327\n",
      " ---------------------- loss: tensor([59061704.], grad_fn=<DivBackward0>)\n",
      "Epoch 328\n",
      " ---------------------- loss: tensor([59034292.], grad_fn=<DivBackward0>)\n",
      "Epoch 329\n",
      " ---------------------- loss: tensor([59006576.], grad_fn=<DivBackward0>)\n",
      "Epoch 330\n",
      " ---------------------- loss: tensor([58978128.], grad_fn=<DivBackward0>)\n",
      "Epoch 331\n",
      " ---------------------- loss: tensor([58949592.], grad_fn=<DivBackward0>)\n",
      "Epoch 332\n",
      " ---------------------- loss: tensor([58921300.], grad_fn=<DivBackward0>)\n",
      "Epoch 333\n",
      " ---------------------- loss: tensor([58894720.], grad_fn=<DivBackward0>)\n",
      "Epoch 334\n",
      " ---------------------- loss: tensor([58865520.], grad_fn=<DivBackward0>)\n",
      "Epoch 335\n",
      " ---------------------- loss: tensor([58838120.], grad_fn=<DivBackward0>)\n",
      "Epoch 336\n",
      " ---------------------- loss: tensor([58810864.], grad_fn=<DivBackward0>)\n",
      "Epoch 337\n",
      " ---------------------- loss: tensor([58784224.], grad_fn=<DivBackward0>)\n",
      "Epoch 338\n",
      " ---------------------- loss: tensor([58755492.], grad_fn=<DivBackward0>)\n",
      "Epoch 339\n",
      " ---------------------- loss: tensor([58728240.], grad_fn=<DivBackward0>)\n",
      "Epoch 340\n",
      " ---------------------- loss: tensor([58702504.], grad_fn=<DivBackward0>)\n",
      "Epoch 341\n",
      " ---------------------- loss: tensor([58673596.], grad_fn=<DivBackward0>)\n",
      "Epoch 342\n",
      " ---------------------- loss: tensor([58647144.], grad_fn=<DivBackward0>)\n",
      "Epoch 343\n",
      " ---------------------- loss: tensor([58620848.], grad_fn=<DivBackward0>)\n",
      "Epoch 344\n",
      " ---------------------- loss: tensor([58595272.], grad_fn=<DivBackward0>)\n",
      "Epoch 345\n",
      " ---------------------- loss: tensor([58567212.], grad_fn=<DivBackward0>)\n",
      "Epoch 346\n",
      " ---------------------- loss: tensor([58541312.], grad_fn=<DivBackward0>)\n",
      "Epoch 347\n",
      " ---------------------- loss: tensor([58514664.], grad_fn=<DivBackward0>)\n",
      "Epoch 348\n",
      " ---------------------- loss: tensor([58488756.], grad_fn=<DivBackward0>)\n",
      "Epoch 349\n",
      " ---------------------- loss: tensor([58463380.], grad_fn=<DivBackward0>)\n",
      "Epoch 350\n",
      " ---------------------- loss: tensor([58435756.], grad_fn=<DivBackward0>)\n",
      "Epoch 351\n",
      " ---------------------- loss: tensor([58411408.], grad_fn=<DivBackward0>)\n",
      "Epoch 352\n",
      " ---------------------- loss: tensor([58383920.], grad_fn=<DivBackward0>)\n",
      "Epoch 353\n",
      " ---------------------- loss: tensor([58358348.], grad_fn=<DivBackward0>)\n",
      "Epoch 354\n",
      " ---------------------- loss: tensor([58333028.], grad_fn=<DivBackward0>)\n",
      "Epoch 355\n",
      " ---------------------- loss: tensor([58307196.], grad_fn=<DivBackward0>)\n",
      "Epoch 356\n",
      " ---------------------- loss: tensor([58280416.], grad_fn=<DivBackward0>)\n",
      "Epoch 357\n",
      " ---------------------- loss: tensor([58256524.], grad_fn=<DivBackward0>)\n",
      "Epoch 358\n",
      " ---------------------- loss: tensor([58230416.], grad_fn=<DivBackward0>)\n",
      "Epoch 359\n",
      " ---------------------- loss: tensor([58204932.], grad_fn=<DivBackward0>)\n",
      "Epoch 360\n",
      " ---------------------- loss: tensor([58179592.], grad_fn=<DivBackward0>)\n",
      "Epoch 361\n",
      " ---------------------- loss: tensor([58154680.], grad_fn=<DivBackward0>)\n",
      "Epoch 362\n",
      " ---------------------- loss: tensor([58129248.], grad_fn=<DivBackward0>)\n",
      "Epoch 363\n",
      " ---------------------- loss: tensor([58104652.], grad_fn=<DivBackward0>)\n",
      "Epoch 364\n",
      " ---------------------- loss: tensor([58079508.], grad_fn=<DivBackward0>)\n",
      "Epoch 365\n",
      " ---------------------- loss: tensor([58053576.], grad_fn=<DivBackward0>)\n",
      "Epoch 366\n",
      " ---------------------- loss: tensor([58029352.], grad_fn=<DivBackward0>)\n",
      "Epoch 367\n",
      " ---------------------- loss: tensor([58003800.], grad_fn=<DivBackward0>)\n",
      "Epoch 368\n",
      " ---------------------- loss: tensor([57979004.], grad_fn=<DivBackward0>)\n",
      "Epoch 369\n",
      " ---------------------- loss: tensor([57956460.], grad_fn=<DivBackward0>)\n",
      "Epoch 370\n",
      " ---------------------- loss: tensor([57931032.], grad_fn=<DivBackward0>)\n",
      "Epoch 371\n",
      " ---------------------- loss: tensor([57906664.], grad_fn=<DivBackward0>)\n",
      "Epoch 372\n",
      " ---------------------- loss: tensor([57881188.], grad_fn=<DivBackward0>)\n",
      "Epoch 373\n",
      " ---------------------- loss: tensor([57857132.], grad_fn=<DivBackward0>)\n",
      "Epoch 374\n",
      " ---------------------- loss: tensor([57831004.], grad_fn=<DivBackward0>)\n",
      "Epoch 375\n",
      " ---------------------- loss: tensor([57808384.], grad_fn=<DivBackward0>)\n",
      "Epoch 376\n",
      " ---------------------- loss: tensor([57783616.], grad_fn=<DivBackward0>)\n",
      "Epoch 377\n",
      " ---------------------- loss: tensor([57759284.], grad_fn=<DivBackward0>)\n",
      "Epoch 378\n",
      " ---------------------- loss: tensor([57736264.], grad_fn=<DivBackward0>)\n",
      "Epoch 379\n",
      " ---------------------- loss: tensor([57712704.], grad_fn=<DivBackward0>)\n",
      "Epoch 380\n",
      " ---------------------- loss: tensor([57688812.], grad_fn=<DivBackward0>)\n",
      "Epoch 381\n",
      " ---------------------- loss: tensor([57663124.], grad_fn=<DivBackward0>)\n",
      "Epoch 382\n",
      " ---------------------- loss: tensor([57640968.], grad_fn=<DivBackward0>)\n",
      "Epoch 383\n",
      " ---------------------- loss: tensor([57616700.], grad_fn=<DivBackward0>)\n",
      "Epoch 384\n",
      " ---------------------- loss: tensor([57592652.], grad_fn=<DivBackward0>)\n",
      "Epoch 385\n",
      " ---------------------- loss: tensor([57568368.], grad_fn=<DivBackward0>)\n",
      "Epoch 386\n",
      " ---------------------- loss: tensor([57547696.], grad_fn=<DivBackward0>)\n",
      "Epoch 387\n",
      " ---------------------- loss: tensor([57522324.], grad_fn=<DivBackward0>)\n",
      "Epoch 388\n",
      " ---------------------- loss: tensor([57498320.], grad_fn=<DivBackward0>)\n",
      "Epoch 389\n",
      " ---------------------- loss: tensor([57474372.], grad_fn=<DivBackward0>)\n",
      "Epoch 390\n",
      " ---------------------- loss: tensor([57451060.], grad_fn=<DivBackward0>)\n",
      "Epoch 391\n",
      " ---------------------- loss: tensor([57428324.], grad_fn=<DivBackward0>)\n",
      "Epoch 392\n",
      " ---------------------- loss: tensor([57405680.], grad_fn=<DivBackward0>)\n",
      "Epoch 393\n",
      " ---------------------- loss: tensor([57381632.], grad_fn=<DivBackward0>)\n",
      "Epoch 394\n",
      " ---------------------- loss: tensor([57359964.], grad_fn=<DivBackward0>)\n",
      "Epoch 395\n",
      " ---------------------- loss: tensor([57336548.], grad_fn=<DivBackward0>)\n",
      "Epoch 396\n",
      " ---------------------- loss: tensor([57313408.], grad_fn=<DivBackward0>)\n",
      "Epoch 397\n",
      " ---------------------- loss: tensor([57290068.], grad_fn=<DivBackward0>)\n",
      "Epoch 398\n",
      " ---------------------- loss: tensor([57265864.], grad_fn=<DivBackward0>)\n",
      "Epoch 399\n",
      " ---------------------- loss: tensor([57243768.], grad_fn=<DivBackward0>)\n",
      "Epoch 400\n",
      " ---------------------- loss: tensor([57221664.], grad_fn=<DivBackward0>)\n",
      "Epoch 401\n",
      " ---------------------- loss: tensor([57198632.], grad_fn=<DivBackward0>)\n",
      "Epoch 402\n",
      " ---------------------- loss: tensor([57176424.], grad_fn=<DivBackward0>)\n",
      "Epoch 403\n",
      " ---------------------- loss: tensor([57153852.], grad_fn=<DivBackward0>)\n",
      "Epoch 404\n",
      " ---------------------- loss: tensor([57131636.], grad_fn=<DivBackward0>)\n",
      "Epoch 405\n",
      " ---------------------- loss: tensor([57108392.], grad_fn=<DivBackward0>)\n",
      "Epoch 406\n",
      " ---------------------- loss: tensor([57085832.], grad_fn=<DivBackward0>)\n",
      "Epoch 407\n",
      " ---------------------- loss: tensor([57063572.], grad_fn=<DivBackward0>)\n",
      "Epoch 408\n",
      " ---------------------- loss: tensor([57038824.], grad_fn=<DivBackward0>)\n",
      "Epoch 409\n",
      " ---------------------- loss: tensor([57018796.], grad_fn=<DivBackward0>)\n",
      "Epoch 410\n",
      " ---------------------- loss: tensor([56995980.], grad_fn=<DivBackward0>)\n",
      "Epoch 411\n",
      " ---------------------- loss: tensor([56973572.], grad_fn=<DivBackward0>)\n",
      "Epoch 412\n",
      " ---------------------- loss: tensor([56951552.], grad_fn=<DivBackward0>)\n",
      "Epoch 413\n",
      " ---------------------- loss: tensor([56930724.], grad_fn=<DivBackward0>)\n",
      "Epoch 414\n",
      " ---------------------- loss: tensor([56907692.], grad_fn=<DivBackward0>)\n",
      "Epoch 415\n",
      " ---------------------- loss: tensor([56886392.], grad_fn=<DivBackward0>)\n",
      "Epoch 416\n",
      " ---------------------- loss: tensor([56863984.], grad_fn=<DivBackward0>)\n",
      "Epoch 417\n",
      " ---------------------- loss: tensor([56841236.], grad_fn=<DivBackward0>)\n",
      "Epoch 418\n",
      " ---------------------- loss: tensor([56820480.], grad_fn=<DivBackward0>)\n",
      "Epoch 419\n",
      " ---------------------- loss: tensor([56798068.], grad_fn=<DivBackward0>)\n",
      "Epoch 420\n",
      " ---------------------- loss: tensor([56776456.], grad_fn=<DivBackward0>)\n",
      "Epoch 421\n",
      " ---------------------- loss: tensor([56754788.], grad_fn=<DivBackward0>)\n",
      "Epoch 422\n",
      " ---------------------- loss: tensor([56732812.], grad_fn=<DivBackward0>)\n",
      "Epoch 423\n",
      " ---------------------- loss: tensor([56710944.], grad_fn=<DivBackward0>)\n",
      "Epoch 424\n",
      " ---------------------- loss: tensor([56691052.], grad_fn=<DivBackward0>)\n",
      "Epoch 425\n",
      " ---------------------- loss: tensor([56668396.], grad_fn=<DivBackward0>)\n",
      "Epoch 426\n",
      " ---------------------- loss: tensor([56647480.], grad_fn=<DivBackward0>)\n",
      "Epoch 427\n",
      " ---------------------- loss: tensor([56626272.], grad_fn=<DivBackward0>)\n",
      "Epoch 428\n",
      " ---------------------- loss: tensor([56603692.], grad_fn=<DivBackward0>)\n",
      "Epoch 429\n",
      " ---------------------- loss: tensor([56582876.], grad_fn=<DivBackward0>)\n",
      "Epoch 430\n",
      " ---------------------- loss: tensor([56561852.], grad_fn=<DivBackward0>)\n",
      "Epoch 431\n",
      " ---------------------- loss: tensor([56540888.], grad_fn=<DivBackward0>)\n",
      "Epoch 432\n",
      " ---------------------- loss: tensor([56518420.], grad_fn=<DivBackward0>)\n",
      "Epoch 433\n",
      " ---------------------- loss: tensor([56499764.], grad_fn=<DivBackward0>)\n",
      "Epoch 434\n",
      " ---------------------- loss: tensor([56477864.], grad_fn=<DivBackward0>)\n",
      "Epoch 435\n",
      " ---------------------- loss: tensor([56457532.], grad_fn=<DivBackward0>)\n",
      "Epoch 436\n",
      " ---------------------- loss: tensor([56436548.], grad_fn=<DivBackward0>)\n",
      "Epoch 437\n",
      " ---------------------- loss: tensor([56416024.], grad_fn=<DivBackward0>)\n",
      "Epoch 438\n",
      " ---------------------- loss: tensor([56393232.], grad_fn=<DivBackward0>)\n",
      "Epoch 439\n",
      " ---------------------- loss: tensor([56373540.], grad_fn=<DivBackward0>)\n",
      "Epoch 440\n",
      " ---------------------- loss: tensor([56353584.], grad_fn=<DivBackward0>)\n",
      "Epoch 441\n",
      " ---------------------- loss: tensor([56333000.], grad_fn=<DivBackward0>)\n",
      "Epoch 442\n",
      " ---------------------- loss: tensor([56312784.], grad_fn=<DivBackward0>)\n",
      "Epoch 443\n",
      " ---------------------- loss: tensor([56293692.], grad_fn=<DivBackward0>)\n",
      "Epoch 444\n",
      " ---------------------- loss: tensor([56270080.], grad_fn=<DivBackward0>)\n",
      "Epoch 445\n",
      " ---------------------- loss: tensor([56251152.], grad_fn=<DivBackward0>)\n",
      "Epoch 446\n",
      " ---------------------- loss: tensor([56230488.], grad_fn=<DivBackward0>)\n",
      "Epoch 447\n",
      " ---------------------- loss: tensor([56210216.], grad_fn=<DivBackward0>)\n",
      "Epoch 448\n",
      " ---------------------- loss: tensor([56191040.], grad_fn=<DivBackward0>)\n",
      "Epoch 449\n",
      " ---------------------- loss: tensor([56169084.], grad_fn=<DivBackward0>)\n",
      "Epoch 450\n",
      " ---------------------- loss: tensor([56148768.], grad_fn=<DivBackward0>)\n",
      "Epoch 451\n",
      " ---------------------- loss: tensor([56129316.], grad_fn=<DivBackward0>)\n",
      "Epoch 452\n",
      " ---------------------- loss: tensor([56108888.], grad_fn=<DivBackward0>)\n",
      "Epoch 453\n",
      " ---------------------- loss: tensor([56089120.], grad_fn=<DivBackward0>)\n",
      "Epoch 454\n",
      " ---------------------- loss: tensor([56069804.], grad_fn=<DivBackward0>)\n",
      "Epoch 455\n",
      " ---------------------- loss: tensor([56050788.], grad_fn=<DivBackward0>)\n",
      "Epoch 456\n",
      " ---------------------- loss: tensor([56030936.], grad_fn=<DivBackward0>)\n",
      "Epoch 457\n",
      " ---------------------- loss: tensor([56011136.], grad_fn=<DivBackward0>)\n",
      "Epoch 458\n",
      " ---------------------- loss: tensor([55990868.], grad_fn=<DivBackward0>)\n",
      "Epoch 459\n",
      " ---------------------- loss: tensor([55971412.], grad_fn=<DivBackward0>)\n",
      "Epoch 460\n",
      " ---------------------- loss: tensor([55951992.], grad_fn=<DivBackward0>)\n",
      "Epoch 461\n",
      " ---------------------- loss: tensor([55933840.], grad_fn=<DivBackward0>)\n",
      "Epoch 462\n",
      " ---------------------- loss: tensor([55910808.], grad_fn=<DivBackward0>)\n",
      "Epoch 463\n",
      " ---------------------- loss: tensor([55891940.], grad_fn=<DivBackward0>)\n",
      "Epoch 464\n",
      " ---------------------- loss: tensor([55873908.], grad_fn=<DivBackward0>)\n",
      "Epoch 465\n",
      " ---------------------- loss: tensor([55853792.], grad_fn=<DivBackward0>)\n",
      "Epoch 466\n",
      " ---------------------- loss: tensor([55834380.], grad_fn=<DivBackward0>)\n",
      "Epoch 467\n",
      " ---------------------- loss: tensor([55814248.], grad_fn=<DivBackward0>)\n",
      "Epoch 468\n",
      " ---------------------- loss: tensor([55796520.], grad_fn=<DivBackward0>)\n",
      "Epoch 469\n",
      " ---------------------- loss: tensor([55776696.], grad_fn=<DivBackward0>)\n",
      "Epoch 470\n",
      " ---------------------- loss: tensor([55758328.], grad_fn=<DivBackward0>)\n",
      "Epoch 471\n",
      " ---------------------- loss: tensor([55739144.], grad_fn=<DivBackward0>)\n",
      "Epoch 472\n",
      " ---------------------- loss: tensor([55720336.], grad_fn=<DivBackward0>)\n",
      "Epoch 473\n",
      " ---------------------- loss: tensor([55701692.], grad_fn=<DivBackward0>)\n",
      "Epoch 474\n",
      " ---------------------- loss: tensor([55681912.], grad_fn=<DivBackward0>)\n",
      "Epoch 475\n",
      " ---------------------- loss: tensor([55664020.], grad_fn=<DivBackward0>)\n",
      "Epoch 476\n",
      " ---------------------- loss: tensor([55645232.], grad_fn=<DivBackward0>)\n",
      "Epoch 477\n",
      " ---------------------- loss: tensor([55626168.], grad_fn=<DivBackward0>)\n",
      "Epoch 478\n",
      " ---------------------- loss: tensor([55607628.], grad_fn=<DivBackward0>)\n",
      "Epoch 479\n",
      " ---------------------- loss: tensor([55588128.], grad_fn=<DivBackward0>)\n",
      "Epoch 480\n",
      " ---------------------- loss: tensor([55570656.], grad_fn=<DivBackward0>)\n",
      "Epoch 481\n",
      " ---------------------- loss: tensor([55551184.], grad_fn=<DivBackward0>)\n",
      "Epoch 482\n",
      " ---------------------- loss: tensor([55534620.], grad_fn=<DivBackward0>)\n",
      "Epoch 483\n",
      " ---------------------- loss: tensor([55515360.], grad_fn=<DivBackward0>)\n",
      "Epoch 484\n",
      " ---------------------- loss: tensor([55496028.], grad_fn=<DivBackward0>)\n",
      "Epoch 485\n",
      " ---------------------- loss: tensor([55478092.], grad_fn=<DivBackward0>)\n",
      "Epoch 486\n",
      " ---------------------- loss: tensor([55460796.], grad_fn=<DivBackward0>)\n",
      "Epoch 487\n",
      " ---------------------- loss: tensor([55443372.], grad_fn=<DivBackward0>)\n",
      "Epoch 488\n",
      " ---------------------- loss: tensor([55425636.], grad_fn=<DivBackward0>)\n",
      "Epoch 489\n",
      " ---------------------- loss: tensor([55406552.], grad_fn=<DivBackward0>)\n",
      "Epoch 490\n",
      " ---------------------- loss: tensor([55387444.], grad_fn=<DivBackward0>)\n",
      "Epoch 491\n",
      " ---------------------- loss: tensor([55370956.], grad_fn=<DivBackward0>)\n",
      "Epoch 492\n",
      " ---------------------- loss: tensor([55352696.], grad_fn=<DivBackward0>)\n",
      "Epoch 493\n",
      " ---------------------- loss: tensor([55335172.], grad_fn=<DivBackward0>)\n",
      "Epoch 494\n",
      " ---------------------- loss: tensor([55317048.], grad_fn=<DivBackward0>)\n",
      "Epoch 495\n",
      " ---------------------- loss: tensor([55299108.], grad_fn=<DivBackward0>)\n",
      "Epoch 496\n",
      " ---------------------- loss: tensor([55281192.], grad_fn=<DivBackward0>)\n",
      "Epoch 497\n",
      " ---------------------- loss: tensor([55264348.], grad_fn=<DivBackward0>)\n",
      "Epoch 498\n",
      " ---------------------- loss: tensor([55245604.], grad_fn=<DivBackward0>)\n",
      "Epoch 499\n",
      " ---------------------- loss: tensor([55228744.], grad_fn=<DivBackward0>)\n",
      "Epoch 500\n",
      " ---------------------- loss: tensor([55210240.], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "11.832435369491577\n"
     ]
    }
   ],
   "source": [
    "upper_r = 6\n",
    "lower_r = -6\n",
    "steps = 200\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "epoch = 500\n",
    "lr1 = 4e-1\n",
    "lr2 = 4e-2 \n",
    "Phis_t = []\n",
    "Es = []\n",
    "lss = []\n",
    "epochs = []\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "initialize_weights(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr1)\n",
    "for t in range(epoch):\n",
    "    loss = loss_fn(R_train.to(device))\n",
    "    print(f\"Epoch {t+1}\\n ---------------------- loss: {loss}\")\n",
    "    training(R_train, loss_fn, optimizer)\n",
    "    if t%100 == 0:\n",
    "        Phis_t.append(Phi_t(R_train).detach().numpy())\n",
    "        Es.append(E.detach().numpy())\n",
    "        lss.append(loss.detach().numpy())\n",
    "        epochs.append(t)    \n",
    "'''optimizer = torch.optim.Adam(model.parameters(), lr=lr2)\n",
    "for t in range(int(epoch/2)+1,epoch):\n",
    "    loss = loss_fn(R_train.to(device))\n",
    "    print(f\"Epoch {t+1}\\n ---------------------- loss: {loss}\")\n",
    "    training(R_train, loss_fn, optimizer)\n",
    "    if t%100 == 0:\n",
    "        Phis_t.append(Phi_t(R_train).detach().numpy())\n",
    "        Es.append(E.detach().numpy())\n",
    "        lss.append(loss.detach().numpy())\n",
    "        epochs.append(t)'''\n",
    "Es = np.squeeze(Es)\n",
    "lss = np.squeeze(lss)\n",
    "Phis_t = np.squeeze(Phis_t)\n",
    "print(\"Done!\")\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(1,2,figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, Es, \"r.\", label=\"Energies\")\n",
    "plt.title(\"Eigenvalues of Energy\")\n",
    "#plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Energy\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, lss, \"b.\", label=\"Losses\")\n",
    "plt.title(\"Loss per 100 epochs\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/andresgo/Documents/Degree project/Degree_project/Implementation to Quantum Mechanics/Hydrogen_atom_excitations_4.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andresgo/Documents/Degree%20project/Degree_project/Implementation%20to%20Quantum%20Mechanics/Hydrogen_atom_excitations_4.ipynb#ch0000011?line=4'>5</a>\u001b[0m col \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andresgo/Documents/Degree%20project/Degree_project/Implementation%20to%20Quantum%20Mechanics/Hydrogen_atom_excitations_4.ipynb#ch0000011?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m9\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/andresgo/Documents/Degree%20project/Degree_project/Implementation%20to%20Quantum%20Mechanics/Hydrogen_atom_excitations_4.ipynb#ch0000011?line=6'>7</a>\u001b[0m     yy \u001b[39m=\u001b[39m Phis_t[\u001b[39m50\u001b[39;49m\u001b[39m*\u001b[39;49mi]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andresgo/Documents/Degree%20project/Degree_project/Implementation%20to%20Quantum%20Mechanics/Hydrogen_atom_excitations_4.ipynb#ch0000011?line=7'>8</a>\u001b[0m     yy \u001b[39m=\u001b[39m yy\u001b[39m.\u001b[39mreshape((\u001b[39m200\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/andresgo/Documents/Degree%20project/Degree_project/Implementation%20to%20Quantum%20Mechanics/Hydrogen_atom_excitations_4.ipynb#ch0000011?line=8'>9</a>\u001b[0m     axs[fil,col]\u001b[39m.\u001b[39mplot(rr[\u001b[39m100\u001b[39m:], np\u001b[39m.\u001b[39mdivide(yy[\u001b[39m100\u001b[39m:], rr[\u001b[39m100\u001b[39m:]), \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpochs \u001b[39m\u001b[39m{\u001b[39;00mepochs[\u001b[39m50\u001b[39m\u001b[39m*\u001b[39mi]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 50 is out of bounds for axis 0 with size 5"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = np.linspace(lower_r, upper_r, steps)[:,None]\n",
    "fig, axs = plt.subplots(3,3,figsize=(15,10))\n",
    "\n",
    "fil = 0\n",
    "col = 0\n",
    "for i in range(0,9):\n",
    "    yy = Phis_t[50*i]\n",
    "    yy = yy.reshape((200,1))\n",
    "    axs[fil,col].plot(rr[100:], np.divide(yy[100:], rr[100:]), \".\", label=f\"Epochs {epochs[50*i]}\")\n",
    "    axs[fil,col].set_xlabel(\"$r$\")\n",
    "    axs[fil,col].set_ylabel(\"$R(r)$\")\n",
    "    axs[fil,col].legend(loc=\"best\")\n",
    "    axs[fil,col].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    axs[fil,col].grid()\n",
    "    if col == 2:\n",
    "       col = 0\n",
    "       fil = fil+1\n",
    "    else:\n",
    "       col = col+1\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90ce48d158604c100cef53b29ac4f6fa22cda1db579180edce6a822d9d38973a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
