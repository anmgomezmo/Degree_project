{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8059a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ace11",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15a69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(1,10),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(10,1, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N = self.layers(x)\n",
    "        return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0a6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x, loss_fn, optimizer):\n",
    "    x = x.to(device)\n",
    "    def closure():\n",
    "        loss = loss_fn(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    torch.nn.utils.clip_grad_value_(model.parameters(), 10)\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32fe71",
   "metadata": {},
   "source": [
    "### Differential equation\n",
    "$$\\frac{d^2\\phi(r)}{dr^2} + \\frac{2m}{\\hbar^2}\\left(E-\\frac{l(l+1)}{2mr^2}\\hbar^2+V(r)\\right)\\phi(r) = 0$$ \n",
    "Dataset are vectors of domain of differential equation, like the vectors are one-dimentional, the shape of dataset is one by m samples. Trial solution $\\phi_t(r) = e^{-\\beta r^2}N(r,\\vec{p})$, with $\\phi(r=0) = 0$ and $\\phi(r\\rightarrow\\infty) = 0$ as boundary conditions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b62799e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=10, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=10, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b53fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 2\n",
    "global Z\n",
    "Z = 1\n",
    "global e\n",
    "#e = -1.602e-19\n",
    "e = -1\n",
    "global hbar\n",
    "#hbar = 1.054e-34\n",
    "hbar = 1\n",
    "global m\n",
    "#m = 9.109e-31\n",
    "m = 1\n",
    "global l\n",
    "l = 0\n",
    "\n",
    "V = lambda r: -(Z*e**2)/r\n",
    "Phi_t = lambda r: torch.exp(-beta*r**2) * model.forward(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f68067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Linear)):\n",
    "            nn.init.xavier_normal_(m.weight.data,0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1acc5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(r):\n",
    "    r.requires_grad = True\n",
    "    \n",
    "    Phi = Phi_t(r)\n",
    "    Phi_t_r = torch.autograd.grad(Phi, r, grad_outputs=torch.ones_like(Phi), create_graph=True)[0]\n",
    "    Phi_t_r_r = torch.autograd.grad(Phi_t_r, r, grad_outputs=torch.ones_like(Phi_t_r), create_graph=True)[0]\n",
    "    H_Phi = -(hbar**2/(2*m))*Phi_t_r_r + (l*(l+1)*hbar**2/(2*m*r**2) + V(r))*Phi\n",
    "    \n",
    "    prom = Phi.size()[0]\n",
    "    \n",
    "    norm = torch.trapezoid(Phi**2,r,dim=0)/2 # integral over r=-6 to 6\n",
    "    \n",
    "    global E\n",
    "    E = torch.trapezoid(Phi*H_Phi,r,dim=0)/(2*norm) \n",
    "    \n",
    "    \n",
    "    return (torch.mean((H_Phi - E*Phi)**2)*prom)/norm #multiply by m to avoit division by m in the mean function of torh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8ecf40f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------- loss: tensor([5926.3345], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([4683.3184], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([747.1562], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([491.4069], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([483.8825], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([483.4265], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([1817.4159], grad_fn=<DivBackward0>)\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([5926.3794], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([5922.3130], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([609.6581], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([516.4819], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([484.6328], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([472.5750], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([467.9257], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([465.9424], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([465.1541], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([464.7860], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([464.5893], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([464.4684], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([464.4949], grad_fn=<DivBackward0>)\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([5926.5269], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([5923.0815], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([1027.5745], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([940.2750], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([834.6189], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([755.0856], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([703.3829], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([660.0287], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([612.8895], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([597.5850], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([589.5450], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([584.5323], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([581.1307], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([578.3168], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([575.0731], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([572.4657], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([570.7637], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([569.4320], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([567.8016], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([562.3550], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([6442.3828], grad_fn=<DivBackward0>)\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([5924.7461], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([5712.1626], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([5707.1685], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([5701.8984], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([5695.8335], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([5689.3276], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([5682.1670], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([5674.2417], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([5665.2466], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([5655.0444], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([5643.3232], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([5629.8364], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([5613.7095], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([5594.2510], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([5569.6748], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([5538.2583], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([5494.6250], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([5429.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([5314.6470], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([5020.2231], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([612.8960], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([612.6528], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([612.1812], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([612.0013], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([611.3070], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([610.7943], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([610.5868], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([610.2748], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([609.9628], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([609.8026], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([609.4700], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([608.8347], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([608.7669], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([607.5095], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([607.2263], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([606.7902], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([606.2429], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([606.2260], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([603.8893], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([603.7190], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([603.1390], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([602.6665], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([602.4684], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([602.2673], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([601.2151], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([601.0864], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([600.7401], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([600.4030], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([600.2515], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([599.9127], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([599.6063], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([599.2721], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([599.0713], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([598.2688], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([597.9902], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([597.4561], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([597.2466], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([596.7792], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([596.5670], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([596.3677], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([595.8220], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([595.4713], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([595.3077], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([594.8560], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([594.7056], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([593.6979], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([593.5542], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([592.9145], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([592.7662], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([592.6383], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([591.3925], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([591.2562], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([591.0975], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([590.7896], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([590.2606], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([590.0114], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([589.3826], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([589.2456], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([588.9839], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([588.6029], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([588.2247], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([588.0245], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([587.9324], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([587.0651], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([586.9211], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([586.5464], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([586.1666], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([586.0074], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89\n",
      " ---------------------- loss: tensor([585.6763], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([585.4728], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([585.0079], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([584.9506], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([584.5068], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([584.3172], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([583.9733], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([583.6929], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([583.3095], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([583.1758], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([582.9518], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([582.3608], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([582.2339], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([581.8832], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([581.6356], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([581.4034], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([581.3611], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([580.5294], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([580.3427], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([579.9473], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([579.6661], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([579.5188], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([579.1793], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([578.8640], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([578.5467], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([578.3342], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([578.1248], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([577.9828], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([577.4457], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([577.2748], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([577.1718], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([576.5536], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([576.3384], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([576.1536], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([575.8389], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([575.4911], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([575.2598], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([575.1161], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([574.6275], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([574.5367], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([574.1024], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([573.9257], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([573.8443], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([573.4864], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([573.0941], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([573.0175], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([572.3293], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([572.1503], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([572.0577], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([571.6122], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([571.4456], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([571.2219], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([570.8078], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([570.7893], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([570.3651], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([570.0381], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([569.8778], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([569.6580], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([569.0679], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([569.0236], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([568.7568], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([568.5791], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([568.2404], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([568.0469], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([567.8871], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([567.5242], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([567.3933], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([567.2173], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([566.2887], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([566.2653], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([565.6101], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([565.5588], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([564.9588], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([564.7068], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([564.6940], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([564.4619], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([564.3904], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([563.9694], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([563.6906], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([563.3613], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([563.0696], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([563.0538], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([560.7877], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([560.6780], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([560.2313], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([560.0792], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([559.7950], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([559.5408], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([559.2989], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([559.2418], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([559.0984], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([558.3658], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([558.2839], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([557.8258], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([557.6541], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([557.4367], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([557.2333], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([556.9888], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([556.5675], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([556.4747], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([556.3267], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190\n",
      " ---------------------- loss: tensor([556.1223], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([555.7908], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([555.6926], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([555.2542], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([555.2110], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([554.9725], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([554.5569], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([554.3893], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([554.1786], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([553.8571], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([553.7432], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([553.3967], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([553.1324], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([553.1177], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([552.0432], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([551.9580], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([551.5842], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([551.4623], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([551.1804], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([550.9763], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([550.6275], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([550.6212], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([548.6371], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([548.4908], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([548.3677], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([548.0120], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([547.8997], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([547.6815], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([547.4592], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([547.2228], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([547.1280], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([547.0270], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([546.6343], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([546.6154], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([543.6336], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([543.5613], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([543.4802], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([543.2488], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([543.1771], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([542.3550], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([542.1465], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([542.0777], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([541.7906], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([541.5917], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([541.3420], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([541.3084], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([540.6735], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([540.5929], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([540.4412], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([540.3556], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([539.9433], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([539.8067], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([539.7550], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([539.2310], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([539.1649], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([538.3732], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([538.3539], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([538.0586], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([537.9648], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([537.7787], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([537.7003], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([537.4344], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([537.2554], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([537.0761], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([536.8573], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([536.7715], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([536.6216], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([536.5728], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([536.0424], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([535.8933], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([535.7798], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([535.7137], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([535.4008], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([535.2310], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([535.1703], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([535.], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([534.6887], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([534.4725], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([534.3759], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([534.2724], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([534.0796], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([533.9869], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([533.5289], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([533.4686], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([533.2661], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([533.0444], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([532.9168], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([532.8586], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([532.7144], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([532.5241], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([532.2811], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([532.1633], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([532.0713], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([531.7394], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([531.7041], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([531.2814], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([531.0963], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([531.0132], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([530.9750], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([530.0497], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([529.9755], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([529.4282], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([529.3505], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([528.8523], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([528.7668], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295\n",
      " ---------------------- loss: tensor([528.5157], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([528.3259], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([528.2402], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([528.1826], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([528.0937], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([527.6710], grad_fn=<DivBackward0>)\n",
      "Epoch 301\n",
      " ---------------------- loss: tensor([527.6380], grad_fn=<DivBackward0>)\n",
      "Epoch 302\n",
      " ---------------------- loss: tensor([526.4041], grad_fn=<DivBackward0>)\n",
      "Epoch 303\n",
      " ---------------------- loss: tensor([526.3333], grad_fn=<DivBackward0>)\n",
      "Epoch 304\n",
      " ---------------------- loss: tensor([526.1110], grad_fn=<DivBackward0>)\n",
      "Epoch 305\n",
      " ---------------------- loss: tensor([525.9675], grad_fn=<DivBackward0>)\n",
      "Epoch 306\n",
      " ---------------------- loss: tensor([525.8191], grad_fn=<DivBackward0>)\n",
      "Epoch 307\n",
      " ---------------------- loss: tensor([525.6602], grad_fn=<DivBackward0>)\n",
      "Epoch 308\n",
      " ---------------------- loss: tensor([525.5795], grad_fn=<DivBackward0>)\n",
      "Epoch 309\n",
      " ---------------------- loss: tensor([525.4004], grad_fn=<DivBackward0>)\n",
      "Epoch 310\n",
      " ---------------------- loss: tensor([525.2123], grad_fn=<DivBackward0>)\n",
      "Epoch 311\n",
      " ---------------------- loss: tensor([525.1508], grad_fn=<DivBackward0>)\n",
      "Epoch 312\n",
      " ---------------------- loss: tensor([525.0370], grad_fn=<DivBackward0>)\n",
      "Epoch 313\n",
      " ---------------------- loss: tensor([524.8814], grad_fn=<DivBackward0>)\n",
      "Epoch 314\n",
      " ---------------------- loss: tensor([524.5902], grad_fn=<DivBackward0>)\n",
      "Epoch 315\n",
      " ---------------------- loss: tensor([524.5100], grad_fn=<DivBackward0>)\n",
      "Epoch 316\n",
      " ---------------------- loss: tensor([524.2623], grad_fn=<DivBackward0>)\n",
      "Epoch 317\n",
      " ---------------------- loss: tensor([524.1161], grad_fn=<DivBackward0>)\n",
      "Epoch 318\n",
      " ---------------------- loss: tensor([523.8759], grad_fn=<DivBackward0>)\n",
      "Epoch 319\n",
      " ---------------------- loss: tensor([523.8625], grad_fn=<DivBackward0>)\n",
      "Epoch 320\n",
      " ---------------------- loss: tensor([523.0161], grad_fn=<DivBackward0>)\n",
      "Epoch 321\n",
      " ---------------------- loss: tensor([522.9473], grad_fn=<DivBackward0>)\n",
      "Epoch 322\n",
      " ---------------------- loss: tensor([522.7897], grad_fn=<DivBackward0>)\n",
      "Epoch 323\n",
      " ---------------------- loss: tensor([522.5432], grad_fn=<DivBackward0>)\n",
      "Epoch 324\n",
      " ---------------------- loss: tensor([522.5150], grad_fn=<DivBackward0>)\n",
      "Epoch 325\n",
      " ---------------------- loss: tensor([522.3353], grad_fn=<DivBackward0>)\n",
      "Epoch 326\n",
      " ---------------------- loss: tensor([522.2284], grad_fn=<DivBackward0>)\n",
      "Epoch 327\n",
      " ---------------------- loss: tensor([522.1041], grad_fn=<DivBackward0>)\n",
      "Epoch 328\n",
      " ---------------------- loss: tensor([522.0368], grad_fn=<DivBackward0>)\n",
      "Epoch 329\n",
      " ---------------------- loss: tensor([521.9029], grad_fn=<DivBackward0>)\n",
      "Epoch 330\n",
      " ---------------------- loss: tensor([521.6370], grad_fn=<DivBackward0>)\n",
      "Epoch 331\n",
      " ---------------------- loss: tensor([521.6372], grad_fn=<DivBackward0>)\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([5926.3652], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([5926.3438], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([5926.0649], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([5925.6963], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([5925.2065], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([5924.4854], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([5923.2017], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([5918.9346], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([468.3244], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([468.0874], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([467.7523], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([467.6827], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([467.6894], grad_fn=<DivBackward0>)\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([5927.3291], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([5927.2104], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([5927.2095], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([5927.1738], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([5927.0771], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([5926.9443], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([5926.6064], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([5923.5078], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([5922.1543], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([2570.1182], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([2398.6338], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([2259.9990], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([2142.9468], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([2031.9934], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([1916.6836], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([1760.6840], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([968174.4375], grad_fn=<DivBackward0>)\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([5926.0791], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([5926.8862], grad_fn=<DivBackward0>)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "upper_r = 6\n",
    "lower_r = -6\n",
    "steps = 200\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "epoch = 1000\n",
    "lrs = [1e-1, 2e-2, 5e-3, 1e-3, 8e-4, 2e-4, 8e-5]\n",
    "Phis_t = []\n",
    "Es = []\n",
    "lss = []\n",
    "\n",
    "for lr in lrs:\n",
    "    model = NeuralNetwork().to(device)\n",
    "    initialize_weights(model)\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)\n",
    "    loss_prev = 100000\n",
    "    for t in range(epoch):\n",
    "        loss = loss_fn(R_train.to(device))\n",
    "        print(f\"Epoch {t+1}\\n ---------------------- loss: {loss}\")\n",
    "        if loss > loss_prev:\n",
    "            break\n",
    "        loss_prev = loss\n",
    "        training(R_train, loss_fn, optimizer)\n",
    "    Phis_t.append(Phi_t(R_train).detach().numpy())\n",
    "    Es.append(E.detach().numpy())\n",
    "    lss.append(loss_prev)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1813e0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = np.linspace(lower_r, upper_r, steps)[:,None]\n",
    "fig, axs = plt.subplots(3,3,figsize=(15,10))\n",
    "\n",
    "fil = 0\n",
    "col = 0\n",
    "for i in range(0,7):\n",
    "    yy = Phis_t[i]\n",
    "    axs[fil,col].plot(rr, yy.squeeze(), \".\", label=f\"Learning rate {lrs[i]}\")\n",
    "    axs[fil,col].set_xlabel(\"$r$\")\n",
    "    axs[fil,col].set_ylabel(\"$\\phi(x)$\")\n",
    "    axs[fil,col].legend(loc=\"best\")\n",
    "    axs[fil,col].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    if col == 2:\n",
    "       col = 0\n",
    "       fil = fil+1\n",
    "    else:\n",
    "       col = col+1\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192ff3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.162228 ,  3.001355 ,  7.2589974,  2.3377512,  2.8406398,\n",
       "       12.906568 ,  1.0043344], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(Es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb28bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e590ab90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------- loss: tensor([5927.6948], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([5926.1289], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([5926.0762], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([5926.0488], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([5926.0244], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([5926.0024], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([5925.9795], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([5925.9590], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([5925.9370], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([5925.9126], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([5925.8862], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([5925.8638], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([5925.8369], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([5925.8101], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([5925.7822], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([5925.7529], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([5925.7241], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([5925.6909], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([5925.6611], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([5925.6270], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([5925.5947], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([5925.5591], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([5925.5220], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([5925.4863], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([5925.4487], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([5925.4102], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([5925.3687], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([5925.3271], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([5925.2847], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([5925.2407], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([5925.1948], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([5925.1479], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([5925.1011], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([5925.0513], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([5925.0005], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([5924.9487], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([5924.8916], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([5924.8374], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([5924.7793], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([5924.7183], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([5924.6543], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([5924.5903], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([5924.5234], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([5924.4526], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([5924.3799], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([5924.3037], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([5924.2231], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([5924.1392], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([5924.0532], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([5923.9624], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([5923.8643], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([5923.7627], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([5923.6538], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([5923.5391], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([5923.4165], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([5923.2856], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([5923.1450], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([5922.9937], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([5922.8296], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([5922.6494], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([5922.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([5922.2349], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([5921.9907], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([5921.7153], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([5921.3984], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([5921.0303], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([5920.5903], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([5920.0518], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([5919.3672], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([5918.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([5917.1196], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([5914.9248], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([5910.2803], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([5890.7153], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([5943.3037], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([5631.9653], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([5947.6377], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([5938.3545], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([5934.4731], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([5932.4478], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([5931.2119], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([5930.3813], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([5929.7856], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([5929.3379], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([5928.9902], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([5928.7114], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([5928.4834], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([5928.2954], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([5928.1353], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([5927.9976], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([5927.8794], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([5927.7749], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([5927.6821], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([5927.6016], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([5927.5283], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([5927.4629], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([5927.4033], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([5927.3477], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([5927.2964], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([5927.2505], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([5927.2070], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([5927.1680], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([5927.1294], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([5927.0933], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([5927.0586], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([5927.0278], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([5926.9971], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([5926.9683], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([5926.9409], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([5926.9131], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([5926.8857], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([5926.8618], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([5926.8374], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([5926.8135], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([5926.7905], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([5926.7666], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([5926.7451], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([5926.7217], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([5926.7002], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([5926.6797], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([5926.6567], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([5926.6362], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([5926.6162], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([5926.5962], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([5926.5742], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([5926.5557], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([5926.5337], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([5926.5142], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([5926.4937], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([5926.4741], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([5926.4536], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([5926.4341], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([5926.4146], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([5926.3936], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([5926.3745], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([5926.3545], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([5926.3350], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([5926.3145], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([5926.2944], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([5926.2749], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([5926.2529], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([5926.2339], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([5926.2144], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([5926.1934], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([5926.1729], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([5926.1523], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([5926.1328], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148\n",
      " ---------------------- loss: tensor([5926.1128], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([5926.0918], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([5926.0723], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([5926.0513], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([5926.0303], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([5926.0093], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([5925.9883], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([5925.9683], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([5925.9463], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([5925.9268], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([5925.9043], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([5925.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([5925.8618], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([5925.8413], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([5925.8198], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([5925.7988], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([5925.7764], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([5925.7549], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([5925.7344], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([5925.7139], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([5925.6904], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([5925.6680], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([5925.6465], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([5925.6245], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([5925.6030], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([5925.5806], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([5925.5596], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([5925.5371], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([5925.5137], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([5925.4927], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([5925.4697], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([5925.4478], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([5925.4233], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([5925.4028], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([5925.3794], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([5925.3560], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([5925.3340], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([5925.3110], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([5925.2876], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([5925.2642], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([5925.2407], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([5925.2183], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([5925.1948], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([5925.1714], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([5925.1479], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([5925.1245], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([5925.1016], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([5925.0786], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([5925.0537], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([5925.0298], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([5925.0068], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([5924.9824], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([5924.9595], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([5924.9351], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([5924.9106], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([5924.8862], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([5924.8623], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([5924.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([5924.8130], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([5924.7886], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([5924.7646], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([5924.7402], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([5924.7144], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([5924.6899], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([5924.6650], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([5924.6406], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([5924.6147], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([5924.5898], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([5924.5645], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([5924.5410], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([5924.5151], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([5924.4902], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([5924.4648], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([5924.4390], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([5924.4136], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([5924.3877], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([5924.3618], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([5924.3369], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([5924.3096], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([5924.2852], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([5924.2588], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([5924.2329], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([5924.2065], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([5924.1807], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([5924.1543], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([5924.1274], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([5924.1011], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([5924.0747], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([5924.0483], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([5924.0220], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([5923.9932], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([5923.9683], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([5923.9409], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([5923.9146], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([5923.8882], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([5923.8604], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([5923.8340], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([5923.8066], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([5923.7788], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([5923.7515], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([5923.7246], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([5923.6973], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([5923.6699], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([5923.6416], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252\n",
      " ---------------------- loss: tensor([5923.6143], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([5923.5854], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([5923.5576], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([5923.5288], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([5923.5020], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([5923.4736], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([5923.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([5923.4170], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([5923.3901], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([5923.3608], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([5923.3325], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([5923.3032], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([5923.2749], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([5923.2466], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([5923.2178], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([5923.1870], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([5923.1597], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([5923.1309], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([5923.1016], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([5923.0723], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([5923.0435], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([5923.0137], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([5922.9834], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([5922.9551], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([5922.9243], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([5922.8960], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([5922.8652], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([5922.8374], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([5922.8052], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([5922.7764], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([5922.7466], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([5922.7144], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([5922.6851], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([5922.6567], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([5922.6255], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([5922.5938], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([5922.5635], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([5922.5337], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([5922.5024], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([5922.4712], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([5922.4399], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([5922.4087], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([5922.3779], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([5922.3462], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([5922.3159], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([5922.2861], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([5922.2524], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([5922.2217], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([5922.1909], grad_fn=<DivBackward0>)\n",
      "Epoch 301\n",
      " ---------------------- loss: tensor([5922.1597], grad_fn=<DivBackward0>)\n",
      "Epoch 302\n",
      " ---------------------- loss: tensor([5922.1274], grad_fn=<DivBackward0>)\n",
      "Epoch 303\n",
      " ---------------------- loss: tensor([5922.0952], grad_fn=<DivBackward0>)\n",
      "Epoch 304\n",
      " ---------------------- loss: tensor([5922.0625], grad_fn=<DivBackward0>)\n",
      "Epoch 305\n",
      " ---------------------- loss: tensor([5922.0308], grad_fn=<DivBackward0>)\n",
      "Epoch 306\n",
      " ---------------------- loss: tensor([5921.9990], grad_fn=<DivBackward0>)\n",
      "Epoch 307\n",
      " ---------------------- loss: tensor([5921.9658], grad_fn=<DivBackward0>)\n",
      "Epoch 308\n",
      " ---------------------- loss: tensor([5921.9331], grad_fn=<DivBackward0>)\n",
      "Epoch 309\n",
      " ---------------------- loss: tensor([5921.9004], grad_fn=<DivBackward0>)\n",
      "Epoch 310\n",
      " ---------------------- loss: tensor([5921.8691], grad_fn=<DivBackward0>)\n",
      "Epoch 311\n",
      " ---------------------- loss: tensor([5921.8369], grad_fn=<DivBackward0>)\n",
      "Epoch 312\n",
      " ---------------------- loss: tensor([5921.8042], grad_fn=<DivBackward0>)\n",
      "Epoch 313\n",
      " ---------------------- loss: tensor([5921.7710], grad_fn=<DivBackward0>)\n",
      "Epoch 314\n",
      " ---------------------- loss: tensor([5921.7383], grad_fn=<DivBackward0>)\n",
      "Epoch 315\n",
      " ---------------------- loss: tensor([5921.7051], grad_fn=<DivBackward0>)\n",
      "Epoch 316\n",
      " ---------------------- loss: tensor([5921.6724], grad_fn=<DivBackward0>)\n",
      "Epoch 317\n",
      " ---------------------- loss: tensor([5921.6392], grad_fn=<DivBackward0>)\n",
      "Epoch 318\n",
      " ---------------------- loss: tensor([5921.6050], grad_fn=<DivBackward0>)\n",
      "Epoch 319\n",
      " ---------------------- loss: tensor([5921.5708], grad_fn=<DivBackward0>)\n",
      "Epoch 320\n",
      " ---------------------- loss: tensor([5921.5381], grad_fn=<DivBackward0>)\n",
      "Epoch 321\n",
      " ---------------------- loss: tensor([5921.5059], grad_fn=<DivBackward0>)\n",
      "Epoch 322\n",
      " ---------------------- loss: tensor([5921.4722], grad_fn=<DivBackward0>)\n",
      "Epoch 323\n",
      " ---------------------- loss: tensor([5921.4375], grad_fn=<DivBackward0>)\n",
      "Epoch 324\n",
      " ---------------------- loss: tensor([5921.4043], grad_fn=<DivBackward0>)\n",
      "Epoch 325\n",
      " ---------------------- loss: tensor([5921.3701], grad_fn=<DivBackward0>)\n",
      "Epoch 326\n",
      " ---------------------- loss: tensor([5921.3364], grad_fn=<DivBackward0>)\n",
      "Epoch 327\n",
      " ---------------------- loss: tensor([5921.3018], grad_fn=<DivBackward0>)\n",
      "Epoch 328\n",
      " ---------------------- loss: tensor([5921.2681], grad_fn=<DivBackward0>)\n",
      "Epoch 329\n",
      " ---------------------- loss: tensor([5921.2339], grad_fn=<DivBackward0>)\n",
      "Epoch 330\n",
      " ---------------------- loss: tensor([5921.1987], grad_fn=<DivBackward0>)\n",
      "Epoch 331\n",
      " ---------------------- loss: tensor([5921.1646], grad_fn=<DivBackward0>)\n",
      "Epoch 332\n",
      " ---------------------- loss: tensor([5921.1299], grad_fn=<DivBackward0>)\n",
      "Epoch 333\n",
      " ---------------------- loss: tensor([5921.0957], grad_fn=<DivBackward0>)\n",
      "Epoch 334\n",
      " ---------------------- loss: tensor([5921.0601], grad_fn=<DivBackward0>)\n",
      "Epoch 335\n",
      " ---------------------- loss: tensor([5921.0254], grad_fn=<DivBackward0>)\n",
      "Epoch 336\n",
      " ---------------------- loss: tensor([5920.9907], grad_fn=<DivBackward0>)\n",
      "Epoch 337\n",
      " ---------------------- loss: tensor([5920.9561], grad_fn=<DivBackward0>)\n",
      "Epoch 338\n",
      " ---------------------- loss: tensor([5920.9209], grad_fn=<DivBackward0>)\n",
      "Epoch 339\n",
      " ---------------------- loss: tensor([5920.8848], grad_fn=<DivBackward0>)\n",
      "Epoch 340\n",
      " ---------------------- loss: tensor([5920.8496], grad_fn=<DivBackward0>)\n",
      "Epoch 341\n",
      " ---------------------- loss: tensor([5920.8145], grad_fn=<DivBackward0>)\n",
      "Epoch 342\n",
      " ---------------------- loss: tensor([5920.7788], grad_fn=<DivBackward0>)\n",
      "Epoch 343\n",
      " ---------------------- loss: tensor([5920.7432], grad_fn=<DivBackward0>)\n",
      "Epoch 344\n",
      " ---------------------- loss: tensor([5920.7065], grad_fn=<DivBackward0>)\n",
      "Epoch 345\n",
      " ---------------------- loss: tensor([5920.6694], grad_fn=<DivBackward0>)\n",
      "Epoch 346\n",
      " ---------------------- loss: tensor([5920.6333], grad_fn=<DivBackward0>)\n",
      "Epoch 347\n",
      " ---------------------- loss: tensor([5920.5981], grad_fn=<DivBackward0>)\n",
      "Epoch 348\n",
      " ---------------------- loss: tensor([5920.5625], grad_fn=<DivBackward0>)\n",
      "Epoch 349\n",
      " ---------------------- loss: tensor([5920.5249], grad_fn=<DivBackward0>)\n",
      "Epoch 350\n",
      " ---------------------- loss: tensor([5920.4873], grad_fn=<DivBackward0>)\n",
      "Epoch 351\n",
      " ---------------------- loss: tensor([5920.4517], grad_fn=<DivBackward0>)\n",
      "Epoch 352\n",
      " ---------------------- loss: tensor([5920.4150], grad_fn=<DivBackward0>)\n",
      "Epoch 353\n",
      " ---------------------- loss: tensor([5920.3784], grad_fn=<DivBackward0>)\n",
      "Epoch 354\n",
      " ---------------------- loss: tensor([5920.3403], grad_fn=<DivBackward0>)\n",
      "Epoch 355\n",
      " ---------------------- loss: tensor([5920.3042], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356\n",
      " ---------------------- loss: tensor([5920.2661], grad_fn=<DivBackward0>)\n",
      "Epoch 357\n",
      " ---------------------- loss: tensor([5920.2285], grad_fn=<DivBackward0>)\n",
      "Epoch 358\n",
      " ---------------------- loss: tensor([5920.1919], grad_fn=<DivBackward0>)\n",
      "Epoch 359\n",
      " ---------------------- loss: tensor([5920.1543], grad_fn=<DivBackward0>)\n",
      "Epoch 360\n",
      " ---------------------- loss: tensor([5920.1157], grad_fn=<DivBackward0>)\n",
      "Epoch 361\n",
      " ---------------------- loss: tensor([5920.0781], grad_fn=<DivBackward0>)\n",
      "Epoch 362\n",
      " ---------------------- loss: tensor([5920.0400], grad_fn=<DivBackward0>)\n",
      "Epoch 363\n",
      " ---------------------- loss: tensor([5920.0020], grad_fn=<DivBackward0>)\n",
      "Epoch 364\n",
      " ---------------------- loss: tensor([5919.9653], grad_fn=<DivBackward0>)\n",
      "Epoch 365\n",
      " ---------------------- loss: tensor([5919.9253], grad_fn=<DivBackward0>)\n",
      "Epoch 366\n",
      " ---------------------- loss: tensor([5919.8872], grad_fn=<DivBackward0>)\n",
      "Epoch 367\n",
      " ---------------------- loss: tensor([5919.8481], grad_fn=<DivBackward0>)\n",
      "Epoch 368\n",
      " ---------------------- loss: tensor([5919.8105], grad_fn=<DivBackward0>)\n",
      "Epoch 369\n",
      " ---------------------- loss: tensor([5919.7715], grad_fn=<DivBackward0>)\n",
      "Epoch 370\n",
      " ---------------------- loss: tensor([5919.7324], grad_fn=<DivBackward0>)\n",
      "Epoch 371\n",
      " ---------------------- loss: tensor([5919.6924], grad_fn=<DivBackward0>)\n",
      "Epoch 372\n",
      " ---------------------- loss: tensor([5919.6533], grad_fn=<DivBackward0>)\n",
      "Epoch 373\n",
      " ---------------------- loss: tensor([5919.6143], grad_fn=<DivBackward0>)\n",
      "Epoch 374\n",
      " ---------------------- loss: tensor([5919.5747], grad_fn=<DivBackward0>)\n",
      "Epoch 375\n",
      " ---------------------- loss: tensor([5919.5347], grad_fn=<DivBackward0>)\n",
      "Epoch 376\n",
      " ---------------------- loss: tensor([5919.4951], grad_fn=<DivBackward0>)\n",
      "Epoch 377\n",
      " ---------------------- loss: tensor([5919.4556], grad_fn=<DivBackward0>)\n",
      "Epoch 378\n",
      " ---------------------- loss: tensor([5919.4155], grad_fn=<DivBackward0>)\n",
      "Epoch 379\n",
      " ---------------------- loss: tensor([5919.3745], grad_fn=<DivBackward0>)\n",
      "Epoch 380\n",
      " ---------------------- loss: tensor([5919.3359], grad_fn=<DivBackward0>)\n",
      "Epoch 381\n",
      " ---------------------- loss: tensor([5919.2944], grad_fn=<DivBackward0>)\n",
      "Epoch 382\n",
      " ---------------------- loss: tensor([5919.2544], grad_fn=<DivBackward0>)\n",
      "Epoch 383\n",
      " ---------------------- loss: tensor([5919.2124], grad_fn=<DivBackward0>)\n",
      "Epoch 384\n",
      " ---------------------- loss: tensor([5919.1709], grad_fn=<DivBackward0>)\n",
      "Epoch 385\n",
      " ---------------------- loss: tensor([5919.1309], grad_fn=<DivBackward0>)\n",
      "Epoch 386\n",
      " ---------------------- loss: tensor([5919.0898], grad_fn=<DivBackward0>)\n",
      "Epoch 387\n",
      " ---------------------- loss: tensor([5919.0474], grad_fn=<DivBackward0>)\n",
      "Epoch 388\n",
      " ---------------------- loss: tensor([5919.0068], grad_fn=<DivBackward0>)\n",
      "Epoch 389\n",
      " ---------------------- loss: tensor([5918.9648], grad_fn=<DivBackward0>)\n",
      "Epoch 390\n",
      " ---------------------- loss: tensor([5918.9229], grad_fn=<DivBackward0>)\n",
      "Epoch 391\n",
      " ---------------------- loss: tensor([5918.8823], grad_fn=<DivBackward0>)\n",
      "Epoch 392\n",
      " ---------------------- loss: tensor([5918.8394], grad_fn=<DivBackward0>)\n",
      "Epoch 393\n",
      " ---------------------- loss: tensor([5918.7974], grad_fn=<DivBackward0>)\n",
      "Epoch 394\n",
      " ---------------------- loss: tensor([5918.7549], grad_fn=<DivBackward0>)\n",
      "Epoch 395\n",
      " ---------------------- loss: tensor([5918.7109], grad_fn=<DivBackward0>)\n",
      "Epoch 396\n",
      " ---------------------- loss: tensor([5918.6694], grad_fn=<DivBackward0>)\n",
      "Epoch 397\n",
      " ---------------------- loss: tensor([5918.6255], grad_fn=<DivBackward0>)\n",
      "Epoch 398\n",
      " ---------------------- loss: tensor([5918.5825], grad_fn=<DivBackward0>)\n",
      "Epoch 399\n",
      " ---------------------- loss: tensor([5918.5400], grad_fn=<DivBackward0>)\n",
      "Epoch 400\n",
      " ---------------------- loss: tensor([5918.4966], grad_fn=<DivBackward0>)\n",
      "Epoch 401\n",
      " ---------------------- loss: tensor([5918.4541], grad_fn=<DivBackward0>)\n",
      "Epoch 402\n",
      " ---------------------- loss: tensor([5918.4082], grad_fn=<DivBackward0>)\n",
      "Epoch 403\n",
      " ---------------------- loss: tensor([5918.3657], grad_fn=<DivBackward0>)\n",
      "Epoch 404\n",
      " ---------------------- loss: tensor([5918.3208], grad_fn=<DivBackward0>)\n",
      "Epoch 405\n",
      " ---------------------- loss: tensor([5918.2788], grad_fn=<DivBackward0>)\n",
      "Epoch 406\n",
      " ---------------------- loss: tensor([5918.2324], grad_fn=<DivBackward0>)\n",
      "Epoch 407\n",
      " ---------------------- loss: tensor([5918.1875], grad_fn=<DivBackward0>)\n",
      "Epoch 408\n",
      " ---------------------- loss: tensor([5918.1436], grad_fn=<DivBackward0>)\n",
      "Epoch 409\n",
      " ---------------------- loss: tensor([5918.0981], grad_fn=<DivBackward0>)\n",
      "Epoch 410\n",
      " ---------------------- loss: tensor([5918.0532], grad_fn=<DivBackward0>)\n",
      "Epoch 411\n",
      " ---------------------- loss: tensor([5918.0078], grad_fn=<DivBackward0>)\n",
      "Epoch 412\n",
      " ---------------------- loss: tensor([5917.9619], grad_fn=<DivBackward0>)\n",
      "Epoch 413\n",
      " ---------------------- loss: tensor([5917.9165], grad_fn=<DivBackward0>)\n",
      "Epoch 414\n",
      " ---------------------- loss: tensor([5917.8716], grad_fn=<DivBackward0>)\n",
      "Epoch 415\n",
      " ---------------------- loss: tensor([5917.8252], grad_fn=<DivBackward0>)\n",
      "Epoch 416\n",
      " ---------------------- loss: tensor([5917.7783], grad_fn=<DivBackward0>)\n",
      "Epoch 417\n",
      " ---------------------- loss: tensor([5917.7319], grad_fn=<DivBackward0>)\n",
      "Epoch 418\n",
      " ---------------------- loss: tensor([5917.6860], grad_fn=<DivBackward0>)\n",
      "Epoch 419\n",
      " ---------------------- loss: tensor([5917.6392], grad_fn=<DivBackward0>)\n",
      "Epoch 420\n",
      " ---------------------- loss: tensor([5917.5923], grad_fn=<DivBackward0>)\n",
      "Epoch 421\n",
      " ---------------------- loss: tensor([5917.5454], grad_fn=<DivBackward0>)\n",
      "Epoch 422\n",
      " ---------------------- loss: tensor([5917.4980], grad_fn=<DivBackward0>)\n",
      "Epoch 423\n",
      " ---------------------- loss: tensor([5917.4507], grad_fn=<DivBackward0>)\n",
      "Epoch 424\n",
      " ---------------------- loss: tensor([5917.4023], grad_fn=<DivBackward0>)\n",
      "Epoch 425\n",
      " ---------------------- loss: tensor([5917.3550], grad_fn=<DivBackward0>)\n",
      "Epoch 426\n",
      " ---------------------- loss: tensor([5917.3081], grad_fn=<DivBackward0>)\n",
      "Epoch 427\n",
      " ---------------------- loss: tensor([5917.2578], grad_fn=<DivBackward0>)\n",
      "Epoch 428\n",
      " ---------------------- loss: tensor([5917.2095], grad_fn=<DivBackward0>)\n",
      "Epoch 429\n",
      " ---------------------- loss: tensor([5917.1597], grad_fn=<DivBackward0>)\n",
      "Epoch 430\n",
      " ---------------------- loss: tensor([5917.1113], grad_fn=<DivBackward0>)\n",
      "Epoch 431\n",
      " ---------------------- loss: tensor([5917.0635], grad_fn=<DivBackward0>)\n",
      "Epoch 432\n",
      " ---------------------- loss: tensor([5917.0137], grad_fn=<DivBackward0>)\n",
      "Epoch 433\n",
      " ---------------------- loss: tensor([5916.9634], grad_fn=<DivBackward0>)\n",
      "Epoch 434\n",
      " ---------------------- loss: tensor([5916.9136], grad_fn=<DivBackward0>)\n",
      "Epoch 435\n",
      " ---------------------- loss: tensor([5916.8628], grad_fn=<DivBackward0>)\n",
      "Epoch 436\n",
      " ---------------------- loss: tensor([5916.8130], grad_fn=<DivBackward0>)\n",
      "Epoch 437\n",
      " ---------------------- loss: tensor([5916.7622], grad_fn=<DivBackward0>)\n",
      "Epoch 438\n",
      " ---------------------- loss: tensor([5916.7119], grad_fn=<DivBackward0>)\n",
      "Epoch 439\n",
      " ---------------------- loss: tensor([5916.6616], grad_fn=<DivBackward0>)\n",
      "Epoch 440\n",
      " ---------------------- loss: tensor([5916.6094], grad_fn=<DivBackward0>)\n",
      "Epoch 441\n",
      " ---------------------- loss: tensor([5916.5586], grad_fn=<DivBackward0>)\n",
      "Epoch 442\n",
      " ---------------------- loss: tensor([5916.5063], grad_fn=<DivBackward0>)\n",
      "Epoch 443\n",
      " ---------------------- loss: tensor([5916.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 444\n",
      " ---------------------- loss: tensor([5916.4023], grad_fn=<DivBackward0>)\n",
      "Epoch 445\n",
      " ---------------------- loss: tensor([5916.3501], grad_fn=<DivBackward0>)\n",
      "Epoch 446\n",
      " ---------------------- loss: tensor([5916.2969], grad_fn=<DivBackward0>)\n",
      "Epoch 447\n",
      " ---------------------- loss: tensor([5916.2437], grad_fn=<DivBackward0>)\n",
      "Epoch 448\n",
      " ---------------------- loss: tensor([5916.1914], grad_fn=<DivBackward0>)\n",
      "Epoch 449\n",
      " ---------------------- loss: tensor([5916.1372], grad_fn=<DivBackward0>)\n",
      "Epoch 450\n",
      " ---------------------- loss: tensor([5916.0830], grad_fn=<DivBackward0>)\n",
      "Epoch 451\n",
      " ---------------------- loss: tensor([5916.0312], grad_fn=<DivBackward0>)\n",
      "Epoch 452\n",
      " ---------------------- loss: tensor([5915.9756], grad_fn=<DivBackward0>)\n",
      "Epoch 453\n",
      " ---------------------- loss: tensor([5915.9209], grad_fn=<DivBackward0>)\n",
      "Epoch 454\n",
      " ---------------------- loss: tensor([5915.8662], grad_fn=<DivBackward0>)\n",
      "Epoch 455\n",
      " ---------------------- loss: tensor([5915.8115], grad_fn=<DivBackward0>)\n",
      "Epoch 456\n",
      " ---------------------- loss: tensor([5915.7563], grad_fn=<DivBackward0>)\n",
      "Epoch 457\n",
      " ---------------------- loss: tensor([5915.6992], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458\n",
      " ---------------------- loss: tensor([5915.6445], grad_fn=<DivBackward0>)\n",
      "Epoch 459\n",
      " ---------------------- loss: tensor([5915.5879], grad_fn=<DivBackward0>)\n",
      "Epoch 460\n",
      " ---------------------- loss: tensor([5915.5317], grad_fn=<DivBackward0>)\n",
      "Epoch 461\n",
      " ---------------------- loss: tensor([5915.4741], grad_fn=<DivBackward0>)\n",
      "Epoch 462\n",
      " ---------------------- loss: tensor([5915.4180], grad_fn=<DivBackward0>)\n",
      "Epoch 463\n",
      " ---------------------- loss: tensor([5915.3613], grad_fn=<DivBackward0>)\n",
      "Epoch 464\n",
      " ---------------------- loss: tensor([5915.3042], grad_fn=<DivBackward0>)\n",
      "Epoch 465\n",
      " ---------------------- loss: tensor([5915.2461], grad_fn=<DivBackward0>)\n",
      "Epoch 466\n",
      " ---------------------- loss: tensor([5915.1875], grad_fn=<DivBackward0>)\n",
      "Epoch 467\n",
      " ---------------------- loss: tensor([5915.1270], grad_fn=<DivBackward0>)\n",
      "Epoch 468\n",
      " ---------------------- loss: tensor([5915.0698], grad_fn=<DivBackward0>)\n",
      "Epoch 469\n",
      " ---------------------- loss: tensor([5915.0103], grad_fn=<DivBackward0>)\n",
      "Epoch 470\n",
      " ---------------------- loss: tensor([5914.9521], grad_fn=<DivBackward0>)\n",
      "Epoch 471\n",
      " ---------------------- loss: tensor([5914.8911], grad_fn=<DivBackward0>)\n",
      "Epoch 472\n",
      " ---------------------- loss: tensor([5914.8296], grad_fn=<DivBackward0>)\n",
      "Epoch 473\n",
      " ---------------------- loss: tensor([5914.7700], grad_fn=<DivBackward0>)\n",
      "Epoch 474\n",
      " ---------------------- loss: tensor([5914.7095], grad_fn=<DivBackward0>)\n",
      "Epoch 475\n",
      " ---------------------- loss: tensor([5914.6484], grad_fn=<DivBackward0>)\n",
      "Epoch 476\n",
      " ---------------------- loss: tensor([5914.5859], grad_fn=<DivBackward0>)\n",
      "Epoch 477\n",
      " ---------------------- loss: tensor([5914.5259], grad_fn=<DivBackward0>)\n",
      "Epoch 478\n",
      " ---------------------- loss: tensor([5914.4634], grad_fn=<DivBackward0>)\n",
      "Epoch 479\n",
      " ---------------------- loss: tensor([5914.4004], grad_fn=<DivBackward0>)\n",
      "Epoch 480\n",
      " ---------------------- loss: tensor([5914.3369], grad_fn=<DivBackward0>)\n",
      "Epoch 481\n",
      " ---------------------- loss: tensor([5914.2739], grad_fn=<DivBackward0>)\n",
      "Epoch 482\n",
      " ---------------------- loss: tensor([5914.2104], grad_fn=<DivBackward0>)\n",
      "Epoch 483\n",
      " ---------------------- loss: tensor([5914.1470], grad_fn=<DivBackward0>)\n",
      "Epoch 484\n",
      " ---------------------- loss: tensor([5914.0840], grad_fn=<DivBackward0>)\n",
      "Epoch 485\n",
      " ---------------------- loss: tensor([5914.0181], grad_fn=<DivBackward0>)\n",
      "Epoch 486\n",
      " ---------------------- loss: tensor([5913.9526], grad_fn=<DivBackward0>)\n",
      "Epoch 487\n",
      " ---------------------- loss: tensor([5913.8872], grad_fn=<DivBackward0>)\n",
      "Epoch 488\n",
      " ---------------------- loss: tensor([5913.8218], grad_fn=<DivBackward0>)\n",
      "Epoch 489\n",
      " ---------------------- loss: tensor([5913.7554], grad_fn=<DivBackward0>)\n",
      "Epoch 490\n",
      " ---------------------- loss: tensor([5913.6880], grad_fn=<DivBackward0>)\n",
      "Epoch 491\n",
      " ---------------------- loss: tensor([5913.6206], grad_fn=<DivBackward0>)\n",
      "Epoch 492\n",
      " ---------------------- loss: tensor([5913.5542], grad_fn=<DivBackward0>)\n",
      "Epoch 493\n",
      " ---------------------- loss: tensor([5913.4858], grad_fn=<DivBackward0>)\n",
      "Epoch 494\n",
      " ---------------------- loss: tensor([5913.4175], grad_fn=<DivBackward0>)\n",
      "Epoch 495\n",
      " ---------------------- loss: tensor([5913.3477], grad_fn=<DivBackward0>)\n",
      "Epoch 496\n",
      " ---------------------- loss: tensor([5913.2798], grad_fn=<DivBackward0>)\n",
      "Epoch 497\n",
      " ---------------------- loss: tensor([5913.2095], grad_fn=<DivBackward0>)\n",
      "Epoch 498\n",
      " ---------------------- loss: tensor([5913.1401], grad_fn=<DivBackward0>)\n",
      "Epoch 499\n",
      " ---------------------- loss: tensor([5913.0693], grad_fn=<DivBackward0>)\n",
      "Epoch 500\n",
      " ---------------------- loss: tensor([5912.9985], grad_fn=<DivBackward0>)\n",
      "Epoch 501\n",
      " ---------------------- loss: tensor([5912.9263], grad_fn=<DivBackward0>)\n",
      "Epoch 502\n",
      " ---------------------- loss: tensor([5912.8550], grad_fn=<DivBackward0>)\n",
      "Epoch 503\n",
      " ---------------------- loss: tensor([5912.7832], grad_fn=<DivBackward0>)\n",
      "Epoch 504\n",
      " ---------------------- loss: tensor([5912.7095], grad_fn=<DivBackward0>)\n",
      "Epoch 505\n",
      " ---------------------- loss: tensor([5912.6348], grad_fn=<DivBackward0>)\n",
      "Epoch 506\n",
      " ---------------------- loss: tensor([5912.5625], grad_fn=<DivBackward0>)\n",
      "Epoch 507\n",
      " ---------------------- loss: tensor([5912.4888], grad_fn=<DivBackward0>)\n",
      "Epoch 508\n",
      " ---------------------- loss: tensor([5912.4136], grad_fn=<DivBackward0>)\n",
      "Epoch 509\n",
      " ---------------------- loss: tensor([5912.3374], grad_fn=<DivBackward0>)\n",
      "Epoch 510\n",
      " ---------------------- loss: tensor([5912.2637], grad_fn=<DivBackward0>)\n",
      "Epoch 511\n",
      " ---------------------- loss: tensor([5912.1865], grad_fn=<DivBackward0>)\n",
      "Epoch 512\n",
      " ---------------------- loss: tensor([5912.1104], grad_fn=<DivBackward0>)\n",
      "Epoch 513\n",
      " ---------------------- loss: tensor([5912.0322], grad_fn=<DivBackward0>)\n",
      "Epoch 514\n",
      " ---------------------- loss: tensor([5911.9531], grad_fn=<DivBackward0>)\n",
      "Epoch 515\n",
      " ---------------------- loss: tensor([5911.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 516\n",
      " ---------------------- loss: tensor([5911.7944], grad_fn=<DivBackward0>)\n",
      "Epoch 517\n",
      " ---------------------- loss: tensor([5911.7163], grad_fn=<DivBackward0>)\n",
      "Epoch 518\n",
      " ---------------------- loss: tensor([5911.6372], grad_fn=<DivBackward0>)\n",
      "Epoch 519\n",
      " ---------------------- loss: tensor([5911.5552], grad_fn=<DivBackward0>)\n",
      "Epoch 520\n",
      " ---------------------- loss: tensor([5911.4746], grad_fn=<DivBackward0>)\n",
      "Epoch 521\n",
      " ---------------------- loss: tensor([5911.3926], grad_fn=<DivBackward0>)\n",
      "Epoch 522\n",
      " ---------------------- loss: tensor([5911.3101], grad_fn=<DivBackward0>)\n",
      "Epoch 523\n",
      " ---------------------- loss: tensor([5911.2261], grad_fn=<DivBackward0>)\n",
      "Epoch 524\n",
      " ---------------------- loss: tensor([5911.1426], grad_fn=<DivBackward0>)\n",
      "Epoch 525\n",
      " ---------------------- loss: tensor([5911.0586], grad_fn=<DivBackward0>)\n",
      "Epoch 526\n",
      " ---------------------- loss: tensor([5910.9731], grad_fn=<DivBackward0>)\n",
      "Epoch 527\n",
      " ---------------------- loss: tensor([5910.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 528\n",
      " ---------------------- loss: tensor([5910.8027], grad_fn=<DivBackward0>)\n",
      "Epoch 529\n",
      " ---------------------- loss: tensor([5910.7139], grad_fn=<DivBackward0>)\n",
      "Epoch 530\n",
      " ---------------------- loss: tensor([5910.6274], grad_fn=<DivBackward0>)\n",
      "Epoch 531\n",
      " ---------------------- loss: tensor([5910.5381], grad_fn=<DivBackward0>)\n",
      "Epoch 532\n",
      " ---------------------- loss: tensor([5910.4487], grad_fn=<DivBackward0>)\n",
      "Epoch 533\n",
      " ---------------------- loss: tensor([5910.3589], grad_fn=<DivBackward0>)\n",
      "Epoch 534\n",
      " ---------------------- loss: tensor([5910.2705], grad_fn=<DivBackward0>)\n",
      "Epoch 535\n",
      " ---------------------- loss: tensor([5910.1777], grad_fn=<DivBackward0>)\n",
      "Epoch 536\n",
      " ---------------------- loss: tensor([5910.0850], grad_fn=<DivBackward0>)\n",
      "Epoch 537\n",
      " ---------------------- loss: tensor([5909.9941], grad_fn=<DivBackward0>)\n",
      "Epoch 538\n",
      " ---------------------- loss: tensor([5909.8999], grad_fn=<DivBackward0>)\n",
      "Epoch 539\n",
      " ---------------------- loss: tensor([5909.8071], grad_fn=<DivBackward0>)\n",
      "Epoch 540\n",
      " ---------------------- loss: tensor([5909.7109], grad_fn=<DivBackward0>)\n",
      "Epoch 541\n",
      " ---------------------- loss: tensor([5909.6147], grad_fn=<DivBackward0>)\n",
      "Epoch 542\n",
      " ---------------------- loss: tensor([5909.5186], grad_fn=<DivBackward0>)\n",
      "Epoch 543\n",
      " ---------------------- loss: tensor([5909.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 544\n",
      " ---------------------- loss: tensor([5909.3232], grad_fn=<DivBackward0>)\n",
      "Epoch 545\n",
      " ---------------------- loss: tensor([5909.2241], grad_fn=<DivBackward0>)\n",
      "Epoch 546\n",
      " ---------------------- loss: tensor([5909.1245], grad_fn=<DivBackward0>)\n",
      "Epoch 547\n",
      " ---------------------- loss: tensor([5909.0234], grad_fn=<DivBackward0>)\n",
      "Epoch 548\n",
      " ---------------------- loss: tensor([5908.9229], grad_fn=<DivBackward0>)\n",
      "Epoch 549\n",
      " ---------------------- loss: tensor([5908.8213], grad_fn=<DivBackward0>)\n",
      "Epoch 550\n",
      " ---------------------- loss: tensor([5908.7168], grad_fn=<DivBackward0>)\n",
      "Epoch 551\n",
      " ---------------------- loss: tensor([5908.6123], grad_fn=<DivBackward0>)\n",
      "Epoch 552\n",
      " ---------------------- loss: tensor([5908.5073], grad_fn=<DivBackward0>)\n",
      "Epoch 553\n",
      " ---------------------- loss: tensor([5908.4023], grad_fn=<DivBackward0>)\n",
      "Epoch 554\n",
      " ---------------------- loss: tensor([5908.2949], grad_fn=<DivBackward0>)\n",
      "Epoch 555\n",
      " ---------------------- loss: tensor([5908.1860], grad_fn=<DivBackward0>)\n",
      "Epoch 556\n",
      " ---------------------- loss: tensor([5908.0771], grad_fn=<DivBackward0>)\n",
      "Epoch 557\n",
      " ---------------------- loss: tensor([5907.9673], grad_fn=<DivBackward0>)\n",
      "Epoch 558\n",
      " ---------------------- loss: tensor([5907.8560], grad_fn=<DivBackward0>)\n",
      "Epoch 559\n",
      " ---------------------- loss: tensor([5907.7446], grad_fn=<DivBackward0>)\n",
      "Epoch 560\n",
      " ---------------------- loss: tensor([5907.6328], grad_fn=<DivBackward0>)\n",
      "Epoch 561\n",
      " ---------------------- loss: tensor([5907.5166], grad_fn=<DivBackward0>)\n",
      "Epoch 562\n",
      " ---------------------- loss: tensor([5907.4014], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 563\n",
      " ---------------------- loss: tensor([5907.2866], grad_fn=<DivBackward0>)\n",
      "Epoch 564\n",
      " ---------------------- loss: tensor([5907.1689], grad_fn=<DivBackward0>)\n",
      "Epoch 565\n",
      " ---------------------- loss: tensor([5907.0493], grad_fn=<DivBackward0>)\n",
      "Epoch 566\n",
      " ---------------------- loss: tensor([5906.9302], grad_fn=<DivBackward0>)\n",
      "Epoch 567\n",
      " ---------------------- loss: tensor([5906.8081], grad_fn=<DivBackward0>)\n",
      "Epoch 568\n",
      " ---------------------- loss: tensor([5906.6865], grad_fn=<DivBackward0>)\n",
      "Epoch 569\n",
      " ---------------------- loss: tensor([5906.5635], grad_fn=<DivBackward0>)\n",
      "Epoch 570\n",
      " ---------------------- loss: tensor([5906.4395], grad_fn=<DivBackward0>)\n",
      "Epoch 571\n",
      " ---------------------- loss: tensor([5906.3135], grad_fn=<DivBackward0>)\n",
      "Epoch 572\n",
      " ---------------------- loss: tensor([5906.1860], grad_fn=<DivBackward0>)\n",
      "Epoch 573\n",
      " ---------------------- loss: tensor([5906.0581], grad_fn=<DivBackward0>)\n",
      "Epoch 574\n",
      " ---------------------- loss: tensor([5905.9282], grad_fn=<DivBackward0>)\n",
      "Epoch 575\n",
      " ---------------------- loss: tensor([5905.7974], grad_fn=<DivBackward0>)\n",
      "Epoch 576\n",
      " ---------------------- loss: tensor([5905.6650], grad_fn=<DivBackward0>)\n",
      "Epoch 577\n",
      " ---------------------- loss: tensor([5905.5298], grad_fn=<DivBackward0>)\n",
      "Epoch 578\n",
      " ---------------------- loss: tensor([5905.3960], grad_fn=<DivBackward0>)\n",
      "Epoch 579\n",
      " ---------------------- loss: tensor([5905.2578], grad_fn=<DivBackward0>)\n",
      "Epoch 580\n",
      " ---------------------- loss: tensor([5905.1201], grad_fn=<DivBackward0>)\n",
      "Epoch 581\n",
      " ---------------------- loss: tensor([5904.9800], grad_fn=<DivBackward0>)\n",
      "Epoch 582\n",
      " ---------------------- loss: tensor([5904.8394], grad_fn=<DivBackward0>)\n",
      "Epoch 583\n",
      " ---------------------- loss: tensor([5904.6953], grad_fn=<DivBackward0>)\n",
      "Epoch 584\n",
      " ---------------------- loss: tensor([5904.5527], grad_fn=<DivBackward0>)\n",
      "Epoch 585\n",
      " ---------------------- loss: tensor([5904.4067], grad_fn=<DivBackward0>)\n",
      "Epoch 586\n",
      " ---------------------- loss: tensor([5904.2593], grad_fn=<DivBackward0>)\n",
      "Epoch 587\n",
      " ---------------------- loss: tensor([5904.1089], grad_fn=<DivBackward0>)\n",
      "Epoch 588\n",
      " ---------------------- loss: tensor([5903.9585], grad_fn=<DivBackward0>)\n",
      "Epoch 589\n",
      " ---------------------- loss: tensor([5903.8071], grad_fn=<DivBackward0>)\n",
      "Epoch 590\n",
      " ---------------------- loss: tensor([5903.6519], grad_fn=<DivBackward0>)\n",
      "Epoch 591\n",
      " ---------------------- loss: tensor([5903.4971], grad_fn=<DivBackward0>)\n",
      "Epoch 592\n",
      " ---------------------- loss: tensor([5903.3384], grad_fn=<DivBackward0>)\n",
      "Epoch 593\n",
      " ---------------------- loss: tensor([5903.1787], grad_fn=<DivBackward0>)\n",
      "Epoch 594\n",
      " ---------------------- loss: tensor([5903.0171], grad_fn=<DivBackward0>)\n",
      "Epoch 595\n",
      " ---------------------- loss: tensor([5902.8525], grad_fn=<DivBackward0>)\n",
      "Epoch 596\n",
      " ---------------------- loss: tensor([5902.6875], grad_fn=<DivBackward0>)\n",
      "Epoch 597\n",
      " ---------------------- loss: tensor([5902.5200], grad_fn=<DivBackward0>)\n",
      "Epoch 598\n",
      " ---------------------- loss: tensor([5902.3491], grad_fn=<DivBackward0>)\n",
      "Epoch 599\n",
      " ---------------------- loss: tensor([5902.1777], grad_fn=<DivBackward0>)\n",
      "Epoch 600\n",
      " ---------------------- loss: tensor([5902.0044], grad_fn=<DivBackward0>)\n",
      "Epoch 601\n",
      " ---------------------- loss: tensor([5901.8276], grad_fn=<DivBackward0>)\n",
      "Epoch 602\n",
      " ---------------------- loss: tensor([5901.6514], grad_fn=<DivBackward0>)\n",
      "Epoch 603\n",
      " ---------------------- loss: tensor([5901.4688], grad_fn=<DivBackward0>)\n",
      "Epoch 604\n",
      " ---------------------- loss: tensor([5901.2861], grad_fn=<DivBackward0>)\n",
      "Epoch 605\n",
      " ---------------------- loss: tensor([5901.1016], grad_fn=<DivBackward0>)\n",
      "Epoch 606\n",
      " ---------------------- loss: tensor([5900.9136], grad_fn=<DivBackward0>)\n",
      "Epoch 607\n",
      " ---------------------- loss: tensor([5900.7241], grad_fn=<DivBackward0>)\n",
      "Epoch 608\n",
      " ---------------------- loss: tensor([5900.5312], grad_fn=<DivBackward0>)\n",
      "Epoch 609\n",
      " ---------------------- loss: tensor([5900.3354], grad_fn=<DivBackward0>)\n",
      "Epoch 610\n",
      " ---------------------- loss: tensor([5900.1372], grad_fn=<DivBackward0>)\n",
      "Epoch 611\n",
      " ---------------------- loss: tensor([5899.9370], grad_fn=<DivBackward0>)\n",
      "Epoch 612\n",
      " ---------------------- loss: tensor([5899.7344], grad_fn=<DivBackward0>)\n",
      "Epoch 613\n",
      " ---------------------- loss: tensor([5899.5278], grad_fn=<DivBackward0>)\n",
      "Epoch 614\n",
      " ---------------------- loss: tensor([5899.3188], grad_fn=<DivBackward0>)\n",
      "Epoch 615\n",
      " ---------------------- loss: tensor([5899.1069], grad_fn=<DivBackward0>)\n",
      "Epoch 616\n",
      " ---------------------- loss: tensor([5898.8911], grad_fn=<DivBackward0>)\n",
      "Epoch 617\n",
      " ---------------------- loss: tensor([5898.6748], grad_fn=<DivBackward0>)\n",
      "Epoch 618\n",
      " ---------------------- loss: tensor([5898.4536], grad_fn=<DivBackward0>)\n",
      "Epoch 619\n",
      " ---------------------- loss: tensor([5898.2295], grad_fn=<DivBackward0>)\n",
      "Epoch 620\n",
      " ---------------------- loss: tensor([5898.0010], grad_fn=<DivBackward0>)\n",
      "Epoch 621\n",
      " ---------------------- loss: tensor([5897.7705], grad_fn=<DivBackward0>)\n",
      "Epoch 622\n",
      " ---------------------- loss: tensor([5897.5361], grad_fn=<DivBackward0>)\n",
      "Epoch 623\n",
      " ---------------------- loss: tensor([5897.2979], grad_fn=<DivBackward0>)\n",
      "Epoch 624\n",
      " ---------------------- loss: tensor([5897.0562], grad_fn=<DivBackward0>)\n",
      "Epoch 625\n",
      " ---------------------- loss: tensor([5896.8115], grad_fn=<DivBackward0>)\n",
      "Epoch 626\n",
      " ---------------------- loss: tensor([5896.5635], grad_fn=<DivBackward0>)\n",
      "Epoch 627\n",
      " ---------------------- loss: tensor([5896.3096], grad_fn=<DivBackward0>)\n",
      "Epoch 628\n",
      " ---------------------- loss: tensor([5896.0532], grad_fn=<DivBackward0>)\n",
      "Epoch 629\n",
      " ---------------------- loss: tensor([5895.7915], grad_fn=<DivBackward0>)\n",
      "Epoch 630\n",
      " ---------------------- loss: tensor([5895.5283], grad_fn=<DivBackward0>)\n",
      "Epoch 631\n",
      " ---------------------- loss: tensor([5895.2568], grad_fn=<DivBackward0>)\n",
      "Epoch 632\n",
      " ---------------------- loss: tensor([5894.9834], grad_fn=<DivBackward0>)\n",
      "Epoch 633\n",
      " ---------------------- loss: tensor([5894.7046], grad_fn=<DivBackward0>)\n",
      "Epoch 634\n",
      " ---------------------- loss: tensor([5894.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 635\n",
      " ---------------------- loss: tensor([5894.1343], grad_fn=<DivBackward0>)\n",
      "Epoch 636\n",
      " ---------------------- loss: tensor([5893.8413], grad_fn=<DivBackward0>)\n",
      "Epoch 637\n",
      " ---------------------- loss: tensor([5893.5444], grad_fn=<DivBackward0>)\n",
      "Epoch 638\n",
      " ---------------------- loss: tensor([5893.2412], grad_fn=<DivBackward0>)\n",
      "Epoch 639\n",
      " ---------------------- loss: tensor([5892.9331], grad_fn=<DivBackward0>)\n",
      "Epoch 640\n",
      " ---------------------- loss: tensor([5892.6191], grad_fn=<DivBackward0>)\n",
      "Epoch 641\n",
      " ---------------------- loss: tensor([5892.3008], grad_fn=<DivBackward0>)\n",
      "Epoch 642\n",
      " ---------------------- loss: tensor([5891.9756], grad_fn=<DivBackward0>)\n",
      "Epoch 643\n",
      " ---------------------- loss: tensor([5891.6445], grad_fn=<DivBackward0>)\n",
      "Epoch 644\n",
      " ---------------------- loss: tensor([5891.3052], grad_fn=<DivBackward0>)\n",
      "Epoch 645\n",
      " ---------------------- loss: tensor([5890.9629], grad_fn=<DivBackward0>)\n",
      "Epoch 646\n",
      " ---------------------- loss: tensor([5890.6123], grad_fn=<DivBackward0>)\n",
      "Epoch 647\n",
      " ---------------------- loss: tensor([5890.2559], grad_fn=<DivBackward0>)\n",
      "Epoch 648\n",
      " ---------------------- loss: tensor([5889.8896], grad_fn=<DivBackward0>)\n",
      "Epoch 649\n",
      " ---------------------- loss: tensor([5889.5190], grad_fn=<DivBackward0>)\n",
      "Epoch 650\n",
      " ---------------------- loss: tensor([5889.1406], grad_fn=<DivBackward0>)\n",
      "Epoch 651\n",
      " ---------------------- loss: tensor([5888.7554], grad_fn=<DivBackward0>)\n",
      "Epoch 652\n",
      " ---------------------- loss: tensor([5888.3618], grad_fn=<DivBackward0>)\n",
      "Epoch 653\n",
      " ---------------------- loss: tensor([5887.9595], grad_fn=<DivBackward0>)\n",
      "Epoch 654\n",
      " ---------------------- loss: tensor([5887.5474], grad_fn=<DivBackward0>)\n",
      "Epoch 655\n",
      " ---------------------- loss: tensor([5887.1294], grad_fn=<DivBackward0>)\n",
      "Epoch 656\n",
      " ---------------------- loss: tensor([5886.7012], grad_fn=<DivBackward0>)\n",
      "Epoch 657\n",
      " ---------------------- loss: tensor([5886.2632], grad_fn=<DivBackward0>)\n",
      "Epoch 658\n",
      " ---------------------- loss: tensor([5885.8154], grad_fn=<DivBackward0>)\n",
      "Epoch 659\n",
      " ---------------------- loss: tensor([5885.3589], grad_fn=<DivBackward0>)\n",
      "Epoch 660\n",
      " ---------------------- loss: tensor([5884.8911], grad_fn=<DivBackward0>)\n",
      "Epoch 661\n",
      " ---------------------- loss: tensor([5884.4121], grad_fn=<DivBackward0>)\n",
      "Epoch 662\n",
      " ---------------------- loss: tensor([5883.9224], grad_fn=<DivBackward0>)\n",
      "Epoch 663\n",
      " ---------------------- loss: tensor([5883.4209], grad_fn=<DivBackward0>)\n",
      "Epoch 664\n",
      " ---------------------- loss: tensor([5882.9058], grad_fn=<DivBackward0>)\n",
      "Epoch 665\n",
      " ---------------------- loss: tensor([5882.3799], grad_fn=<DivBackward0>)\n",
      "Epoch 666\n",
      " ---------------------- loss: tensor([5881.8398], grad_fn=<DivBackward0>)\n",
      "Epoch 667\n",
      " ---------------------- loss: tensor([5881.2856], grad_fn=<DivBackward0>)\n",
      "Epoch 668\n",
      " ---------------------- loss: tensor([5880.7178], grad_fn=<DivBackward0>)\n",
      "Epoch 669\n",
      " ---------------------- loss: tensor([5880.1362], grad_fn=<DivBackward0>)\n",
      "Epoch 670\n",
      " ---------------------- loss: tensor([5879.5381], grad_fn=<DivBackward0>)\n",
      "Epoch 671\n",
      " ---------------------- loss: tensor([5878.9233], grad_fn=<DivBackward0>)\n",
      "Epoch 672\n",
      " ---------------------- loss: tensor([5878.2900], grad_fn=<DivBackward0>)\n",
      "Epoch 673\n",
      " ---------------------- loss: tensor([5877.6416], grad_fn=<DivBackward0>)\n",
      "Epoch 674\n",
      " ---------------------- loss: tensor([5876.9727], grad_fn=<DivBackward0>)\n",
      "Epoch 675\n",
      " ---------------------- loss: tensor([5876.2852], grad_fn=<DivBackward0>)\n",
      "Epoch 676\n",
      " ---------------------- loss: tensor([5875.5762], grad_fn=<DivBackward0>)\n",
      "Epoch 677\n",
      " ---------------------- loss: tensor([5874.8472], grad_fn=<DivBackward0>)\n",
      "Epoch 678\n",
      " ---------------------- loss: tensor([5874.0947], grad_fn=<DivBackward0>)\n",
      "Epoch 679\n",
      " ---------------------- loss: tensor([5873.3164], grad_fn=<DivBackward0>)\n",
      "Epoch 680\n",
      " ---------------------- loss: tensor([5872.5142], grad_fn=<DivBackward0>)\n",
      "Epoch 681\n",
      " ---------------------- loss: tensor([5871.6846], grad_fn=<DivBackward0>)\n",
      "Epoch 682\n",
      " ---------------------- loss: tensor([5870.8271], grad_fn=<DivBackward0>)\n",
      "Epoch 683\n",
      " ---------------------- loss: tensor([5869.9395], grad_fn=<DivBackward0>)\n",
      "Epoch 684\n",
      " ---------------------- loss: tensor([5869.0190], grad_fn=<DivBackward0>)\n",
      "Epoch 685\n",
      " ---------------------- loss: tensor([5868.0654], grad_fn=<DivBackward0>)\n",
      "Epoch 686\n",
      " ---------------------- loss: tensor([5867.0762], grad_fn=<DivBackward0>)\n",
      "Epoch 687\n",
      " ---------------------- loss: tensor([5866.0474], grad_fn=<DivBackward0>)\n",
      "Epoch 688\n",
      " ---------------------- loss: tensor([5864.9780], grad_fn=<DivBackward0>)\n",
      "Epoch 689\n",
      " ---------------------- loss: tensor([5863.8652], grad_fn=<DivBackward0>)\n",
      "Epoch 690\n",
      " ---------------------- loss: tensor([5862.7051], grad_fn=<DivBackward0>)\n",
      "Epoch 691\n",
      " ---------------------- loss: tensor([5861.4937], grad_fn=<DivBackward0>)\n",
      "Epoch 692\n",
      " ---------------------- loss: tensor([5860.2285], grad_fn=<DivBackward0>)\n",
      "Epoch 693\n",
      " ---------------------- loss: tensor([5858.9048], grad_fn=<DivBackward0>)\n",
      "Epoch 694\n",
      " ---------------------- loss: tensor([5857.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 695\n",
      " ---------------------- loss: tensor([5856.0591], grad_fn=<DivBackward0>)\n",
      "Epoch 696\n",
      " ---------------------- loss: tensor([5854.5264], grad_fn=<DivBackward0>)\n",
      "Epoch 697\n",
      " ---------------------- loss: tensor([5852.9111], grad_fn=<DivBackward0>)\n",
      "Epoch 698\n",
      " ---------------------- loss: tensor([5851.2070], grad_fn=<DivBackward0>)\n",
      "Epoch 699\n",
      " ---------------------- loss: tensor([5849.3994], grad_fn=<DivBackward0>)\n",
      "Epoch 700\n",
      " ---------------------- loss: tensor([5847.4863], grad_fn=<DivBackward0>)\n",
      "Epoch 701\n",
      " ---------------------- loss: tensor([5845.4482], grad_fn=<DivBackward0>)\n",
      "Epoch 702\n",
      " ---------------------- loss: tensor([5843.2759], grad_fn=<DivBackward0>)\n",
      "Epoch 703\n",
      " ---------------------- loss: tensor([5840.9507], grad_fn=<DivBackward0>)\n",
      "Epoch 704\n",
      " ---------------------- loss: tensor([5838.4536], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 705\n",
      " ---------------------- loss: tensor([5835.7607], grad_fn=<DivBackward0>)\n",
      "Epoch 706\n",
      " ---------------------- loss: tensor([5832.8447], grad_fn=<DivBackward0>)\n",
      "Epoch 707\n",
      " ---------------------- loss: tensor([5829.6733], grad_fn=<DivBackward0>)\n",
      "Epoch 708\n",
      " ---------------------- loss: tensor([5826.2036], grad_fn=<DivBackward0>)\n",
      "Epoch 709\n",
      " ---------------------- loss: tensor([5822.3853], grad_fn=<DivBackward0>)\n",
      "Epoch 710\n",
      " ---------------------- loss: tensor([5818.1519], grad_fn=<DivBackward0>)\n",
      "Epoch 711\n",
      " ---------------------- loss: tensor([5813.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 712\n",
      " ---------------------- loss: tensor([5808.0864], grad_fn=<DivBackward0>)\n",
      "Epoch 713\n",
      " ---------------------- loss: tensor([5802.0015], grad_fn=<DivBackward0>)\n",
      "Epoch 714\n",
      " ---------------------- loss: tensor([5794.9683], grad_fn=<DivBackward0>)\n",
      "Epoch 715\n",
      " ---------------------- loss: tensor([5786.7070], grad_fn=<DivBackward0>)\n",
      "Epoch 716\n",
      " ---------------------- loss: tensor([5776.8130], grad_fn=<DivBackward0>)\n",
      "Epoch 717\n",
      " ---------------------- loss: tensor([5764.6616], grad_fn=<DivBackward0>)\n",
      "Epoch 718\n",
      " ---------------------- loss: tensor([5749.2461], grad_fn=<DivBackward0>)\n",
      "Epoch 719\n",
      " ---------------------- loss: tensor([5728.8149], grad_fn=<DivBackward0>)\n",
      "Epoch 720\n",
      " ---------------------- loss: tensor([5699.9863], grad_fn=<DivBackward0>)\n",
      "Epoch 721\n",
      " ---------------------- loss: tensor([5655.2388], grad_fn=<DivBackward0>)\n",
      "Epoch 722\n",
      " ---------------------- loss: tensor([5573.3970], grad_fn=<DivBackward0>)\n",
      "Epoch 723\n",
      " ---------------------- loss: tensor([5361.4917], grad_fn=<DivBackward0>)\n",
      "Epoch 724\n",
      " ---------------------- loss: tensor([3439.4167], grad_fn=<DivBackward0>)\n",
      "Epoch 725\n",
      " ---------------------- loss: tensor([5975.5654], grad_fn=<DivBackward0>)\n",
      "Epoch 726\n",
      " ---------------------- loss: tensor([5983.0337], grad_fn=<DivBackward0>)\n",
      "Epoch 727\n",
      " ---------------------- loss: tensor([5965.6562], grad_fn=<DivBackward0>)\n",
      "Epoch 728\n",
      " ---------------------- loss: tensor([5954.3105], grad_fn=<DivBackward0>)\n",
      "Epoch 729\n",
      " ---------------------- loss: tensor([5946.7793], grad_fn=<DivBackward0>)\n",
      "Epoch 730\n",
      " ---------------------- loss: tensor([5941.4941], grad_fn=<DivBackward0>)\n",
      "Epoch 731\n",
      " ---------------------- loss: tensor([5937.6079], grad_fn=<DivBackward0>)\n",
      "Epoch 732\n",
      " ---------------------- loss: tensor([5934.6440], grad_fn=<DivBackward0>)\n",
      "Epoch 733\n",
      " ---------------------- loss: tensor([5932.3164], grad_fn=<DivBackward0>)\n",
      "Epoch 734\n",
      " ---------------------- loss: tensor([5930.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 735\n",
      " ---------------------- loss: tensor([5928.9150], grad_fn=<DivBackward0>)\n",
      "Epoch 736\n",
      " ---------------------- loss: tensor([5927.6436], grad_fn=<DivBackward0>)\n",
      "Epoch 737\n",
      " ---------------------- loss: tensor([5926.5718], grad_fn=<DivBackward0>)\n",
      "Epoch 738\n",
      " ---------------------- loss: tensor([5925.6582], grad_fn=<DivBackward0>)\n",
      "Epoch 739\n",
      " ---------------------- loss: tensor([5924.8730], grad_fn=<DivBackward0>)\n",
      "Epoch 740\n",
      " ---------------------- loss: tensor([5924.1929], grad_fn=<DivBackward0>)\n",
      "Epoch 741\n",
      " ---------------------- loss: tensor([5923.5981], grad_fn=<DivBackward0>)\n",
      "Epoch 742\n",
      " ---------------------- loss: tensor([5923.0762], grad_fn=<DivBackward0>)\n",
      "Epoch 743\n",
      " ---------------------- loss: tensor([5922.6128], grad_fn=<DivBackward0>)\n",
      "Epoch 744\n",
      " ---------------------- loss: tensor([5922.2012], grad_fn=<DivBackward0>)\n",
      "Epoch 745\n",
      " ---------------------- loss: tensor([5921.8320], grad_fn=<DivBackward0>)\n",
      "Epoch 746\n",
      " ---------------------- loss: tensor([5921.5015], grad_fn=<DivBackward0>)\n",
      "Epoch 747\n",
      " ---------------------- loss: tensor([5921.2031], grad_fn=<DivBackward0>)\n",
      "Epoch 748\n",
      " ---------------------- loss: tensor([5920.9312], grad_fn=<DivBackward0>)\n",
      "Epoch 749\n",
      " ---------------------- loss: tensor([5920.6851], grad_fn=<DivBackward0>)\n",
      "Epoch 750\n",
      " ---------------------- loss: tensor([5920.4580], grad_fn=<DivBackward0>)\n",
      "Epoch 751\n",
      " ---------------------- loss: tensor([5920.2524], grad_fn=<DivBackward0>)\n",
      "Epoch 752\n",
      " ---------------------- loss: tensor([5920.0586], grad_fn=<DivBackward0>)\n",
      "Epoch 753\n",
      " ---------------------- loss: tensor([5919.8838], grad_fn=<DivBackward0>)\n",
      "Epoch 754\n",
      " ---------------------- loss: tensor([5919.7192], grad_fn=<DivBackward0>)\n",
      "Epoch 755\n",
      " ---------------------- loss: tensor([5919.5649], grad_fn=<DivBackward0>)\n",
      "Epoch 756\n",
      " ---------------------- loss: tensor([5919.4224], grad_fn=<DivBackward0>)\n",
      "Epoch 757\n",
      " ---------------------- loss: tensor([5919.2866], grad_fn=<DivBackward0>)\n",
      "Epoch 758\n",
      " ---------------------- loss: tensor([5919.1616], grad_fn=<DivBackward0>)\n",
      "Epoch 759\n",
      " ---------------------- loss: tensor([5919.0400], grad_fn=<DivBackward0>)\n",
      "Epoch 760\n",
      " ---------------------- loss: tensor([5918.9258], grad_fn=<DivBackward0>)\n",
      "Epoch 761\n",
      " ---------------------- loss: tensor([5918.8169], grad_fn=<DivBackward0>)\n",
      "Epoch 762\n",
      " ---------------------- loss: tensor([5918.7148], grad_fn=<DivBackward0>)\n",
      "Epoch 763\n",
      " ---------------------- loss: tensor([5918.6157], grad_fn=<DivBackward0>)\n",
      "Epoch 764\n",
      " ---------------------- loss: tensor([5918.5195], grad_fn=<DivBackward0>)\n",
      "Epoch 765\n",
      " ---------------------- loss: tensor([5918.4277], grad_fn=<DivBackward0>)\n",
      "Epoch 766\n",
      " ---------------------- loss: tensor([5918.3379], grad_fn=<DivBackward0>)\n",
      "Epoch 767\n",
      " ---------------------- loss: tensor([5918.2524], grad_fn=<DivBackward0>)\n",
      "Epoch 768\n",
      " ---------------------- loss: tensor([5918.1685], grad_fn=<DivBackward0>)\n",
      "Epoch 769\n",
      " ---------------------- loss: tensor([5918.0874], grad_fn=<DivBackward0>)\n",
      "Epoch 770\n",
      " ---------------------- loss: tensor([5918.0083], grad_fn=<DivBackward0>)\n",
      "Epoch 771\n",
      " ---------------------- loss: tensor([5917.9302], grad_fn=<DivBackward0>)\n",
      "Epoch 772\n",
      " ---------------------- loss: tensor([5917.8540], grad_fn=<DivBackward0>)\n",
      "Epoch 773\n",
      " ---------------------- loss: tensor([5917.7788], grad_fn=<DivBackward0>)\n",
      "Epoch 774\n",
      " ---------------------- loss: tensor([5917.7061], grad_fn=<DivBackward0>)\n",
      "Epoch 775\n",
      " ---------------------- loss: tensor([5917.6343], grad_fn=<DivBackward0>)\n",
      "Epoch 776\n",
      " ---------------------- loss: tensor([5917.5620], grad_fn=<DivBackward0>)\n",
      "Epoch 777\n",
      " ---------------------- loss: tensor([5917.4922], grad_fn=<DivBackward0>)\n",
      "Epoch 778\n",
      " ---------------------- loss: tensor([5917.4209], grad_fn=<DivBackward0>)\n",
      "Epoch 779\n",
      " ---------------------- loss: tensor([5917.3521], grad_fn=<DivBackward0>)\n",
      "Epoch 780\n",
      " ---------------------- loss: tensor([5917.2832], grad_fn=<DivBackward0>)\n",
      "Epoch 781\n",
      " ---------------------- loss: tensor([5917.2168], grad_fn=<DivBackward0>)\n",
      "Epoch 782\n",
      " ---------------------- loss: tensor([5917.1484], grad_fn=<DivBackward0>)\n",
      "Epoch 783\n",
      " ---------------------- loss: tensor([5917.0815], grad_fn=<DivBackward0>)\n",
      "Epoch 784\n",
      " ---------------------- loss: tensor([5917.0137], grad_fn=<DivBackward0>)\n",
      "Epoch 785\n",
      " ---------------------- loss: tensor([5916.9497], grad_fn=<DivBackward0>)\n",
      "Epoch 786\n",
      " ---------------------- loss: tensor([5916.8823], grad_fn=<DivBackward0>)\n",
      "Epoch 787\n",
      " ---------------------- loss: tensor([5916.8188], grad_fn=<DivBackward0>)\n",
      "Epoch 788\n",
      " ---------------------- loss: tensor([5916.7524], grad_fn=<DivBackward0>)\n",
      "Epoch 789\n",
      " ---------------------- loss: tensor([5916.6860], grad_fn=<DivBackward0>)\n",
      "Epoch 790\n",
      " ---------------------- loss: tensor([5916.6216], grad_fn=<DivBackward0>)\n",
      "Epoch 791\n",
      " ---------------------- loss: tensor([5916.5562], grad_fn=<DivBackward0>)\n",
      "Epoch 792\n",
      " ---------------------- loss: tensor([5916.4902], grad_fn=<DivBackward0>)\n",
      "Epoch 793\n",
      " ---------------------- loss: tensor([5916.4272], grad_fn=<DivBackward0>)\n",
      "Epoch 794\n",
      " ---------------------- loss: tensor([5916.3643], grad_fn=<DivBackward0>)\n",
      "Epoch 795\n",
      " ---------------------- loss: tensor([5916.2983], grad_fn=<DivBackward0>)\n",
      "Epoch 796\n",
      " ---------------------- loss: tensor([5916.2324], grad_fn=<DivBackward0>)\n",
      "Epoch 797\n",
      " ---------------------- loss: tensor([5916.1675], grad_fn=<DivBackward0>)\n",
      "Epoch 798\n",
      " ---------------------- loss: tensor([5916.1035], grad_fn=<DivBackward0>)\n",
      "Epoch 799\n",
      " ---------------------- loss: tensor([5916.0386], grad_fn=<DivBackward0>)\n",
      "Epoch 800\n",
      " ---------------------- loss: tensor([5915.9746], grad_fn=<DivBackward0>)\n",
      "Epoch 801\n",
      " ---------------------- loss: tensor([5915.9102], grad_fn=<DivBackward0>)\n",
      "Epoch 802\n",
      " ---------------------- loss: tensor([5915.8452], grad_fn=<DivBackward0>)\n",
      "Epoch 803\n",
      " ---------------------- loss: tensor([5915.7808], grad_fn=<DivBackward0>)\n",
      "Epoch 804\n",
      " ---------------------- loss: tensor([5915.7158], grad_fn=<DivBackward0>)\n",
      "Epoch 805\n",
      " ---------------------- loss: tensor([5915.6514], grad_fn=<DivBackward0>)\n",
      "Epoch 806\n",
      " ---------------------- loss: tensor([5915.5874], grad_fn=<DivBackward0>)\n",
      "Epoch 807\n",
      " ---------------------- loss: tensor([5915.5215], grad_fn=<DivBackward0>)\n",
      "Epoch 808\n",
      " ---------------------- loss: tensor([5915.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 809\n",
      " ---------------------- loss: tensor([5915.3936], grad_fn=<DivBackward0>)\n",
      "Epoch 810\n",
      " ---------------------- loss: tensor([5915.3281], grad_fn=<DivBackward0>)\n",
      "Epoch 811\n",
      " ---------------------- loss: tensor([5915.2627], grad_fn=<DivBackward0>)\n",
      "Epoch 812\n",
      " ---------------------- loss: tensor([5915.1982], grad_fn=<DivBackward0>)\n",
      "Epoch 813\n",
      " ---------------------- loss: tensor([5915.1333], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814\n",
      " ---------------------- loss: tensor([5915.0679], grad_fn=<DivBackward0>)\n",
      "Epoch 815\n",
      " ---------------------- loss: tensor([5915.0024], grad_fn=<DivBackward0>)\n",
      "Epoch 816\n",
      " ---------------------- loss: tensor([5914.9360], grad_fn=<DivBackward0>)\n",
      "Epoch 817\n",
      " ---------------------- loss: tensor([5914.8716], grad_fn=<DivBackward0>)\n",
      "Epoch 818\n",
      " ---------------------- loss: tensor([5914.8052], grad_fn=<DivBackward0>)\n",
      "Epoch 819\n",
      " ---------------------- loss: tensor([5914.7402], grad_fn=<DivBackward0>)\n",
      "Epoch 820\n",
      " ---------------------- loss: tensor([5914.6748], grad_fn=<DivBackward0>)\n",
      "Epoch 821\n",
      " ---------------------- loss: tensor([5914.6089], grad_fn=<DivBackward0>)\n",
      "Epoch 822\n",
      " ---------------------- loss: tensor([5914.5439], grad_fn=<DivBackward0>)\n",
      "Epoch 823\n",
      " ---------------------- loss: tensor([5914.4756], grad_fn=<DivBackward0>)\n",
      "Epoch 824\n",
      " ---------------------- loss: tensor([5914.4116], grad_fn=<DivBackward0>)\n",
      "Epoch 825\n",
      " ---------------------- loss: tensor([5914.3452], grad_fn=<DivBackward0>)\n",
      "Epoch 826\n",
      " ---------------------- loss: tensor([5914.2769], grad_fn=<DivBackward0>)\n",
      "Epoch 827\n",
      " ---------------------- loss: tensor([5914.2124], grad_fn=<DivBackward0>)\n",
      "Epoch 828\n",
      " ---------------------- loss: tensor([5914.1465], grad_fn=<DivBackward0>)\n",
      "Epoch 829\n",
      " ---------------------- loss: tensor([5914.0796], grad_fn=<DivBackward0>)\n",
      "Epoch 830\n",
      " ---------------------- loss: tensor([5914.0132], grad_fn=<DivBackward0>)\n",
      "Epoch 831\n",
      " ---------------------- loss: tensor([5913.9458], grad_fn=<DivBackward0>)\n",
      "Epoch 832\n",
      " ---------------------- loss: tensor([5913.8799], grad_fn=<DivBackward0>)\n",
      "Epoch 833\n",
      " ---------------------- loss: tensor([5913.8130], grad_fn=<DivBackward0>)\n",
      "Epoch 834\n",
      " ---------------------- loss: tensor([5913.7456], grad_fn=<DivBackward0>)\n",
      "Epoch 835\n",
      " ---------------------- loss: tensor([5913.6777], grad_fn=<DivBackward0>)\n",
      "Epoch 836\n",
      " ---------------------- loss: tensor([5913.6123], grad_fn=<DivBackward0>)\n",
      "Epoch 837\n",
      " ---------------------- loss: tensor([5913.5444], grad_fn=<DivBackward0>)\n",
      "Epoch 838\n",
      " ---------------------- loss: tensor([5913.4775], grad_fn=<DivBackward0>)\n",
      "Epoch 839\n",
      " ---------------------- loss: tensor([5913.4102], grad_fn=<DivBackward0>)\n",
      "Epoch 840\n",
      " ---------------------- loss: tensor([5913.3418], grad_fn=<DivBackward0>)\n",
      "Epoch 841\n",
      " ---------------------- loss: tensor([5913.2744], grad_fn=<DivBackward0>)\n",
      "Epoch 842\n",
      " ---------------------- loss: tensor([5913.2080], grad_fn=<DivBackward0>)\n",
      "Epoch 843\n",
      " ---------------------- loss: tensor([5913.1396], grad_fn=<DivBackward0>)\n",
      "Epoch 844\n",
      " ---------------------- loss: tensor([5913.0713], grad_fn=<DivBackward0>)\n",
      "Epoch 845\n",
      " ---------------------- loss: tensor([5913.0034], grad_fn=<DivBackward0>)\n",
      "Epoch 846\n",
      " ---------------------- loss: tensor([5912.9351], grad_fn=<DivBackward0>)\n",
      "Epoch 847\n",
      " ---------------------- loss: tensor([5912.8682], grad_fn=<DivBackward0>)\n",
      "Epoch 848\n",
      " ---------------------- loss: tensor([5912.7993], grad_fn=<DivBackward0>)\n",
      "Epoch 849\n",
      " ---------------------- loss: tensor([5912.7314], grad_fn=<DivBackward0>)\n",
      "Epoch 850\n",
      " ---------------------- loss: tensor([5912.6611], grad_fn=<DivBackward0>)\n",
      "Epoch 851\n",
      " ---------------------- loss: tensor([5912.5933], grad_fn=<DivBackward0>)\n",
      "Epoch 852\n",
      " ---------------------- loss: tensor([5912.5244], grad_fn=<DivBackward0>)\n",
      "Epoch 853\n",
      " ---------------------- loss: tensor([5912.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 854\n",
      " ---------------------- loss: tensor([5912.3882], grad_fn=<DivBackward0>)\n",
      "Epoch 855\n",
      " ---------------------- loss: tensor([5912.3184], grad_fn=<DivBackward0>)\n",
      "Epoch 856\n",
      " ---------------------- loss: tensor([5912.2495], grad_fn=<DivBackward0>)\n",
      "Epoch 857\n",
      " ---------------------- loss: tensor([5912.1792], grad_fn=<DivBackward0>)\n",
      "Epoch 858\n",
      " ---------------------- loss: tensor([5912.1118], grad_fn=<DivBackward0>)\n",
      "Epoch 859\n",
      " ---------------------- loss: tensor([5912.0415], grad_fn=<DivBackward0>)\n",
      "Epoch 860\n",
      " ---------------------- loss: tensor([5911.9717], grad_fn=<DivBackward0>)\n",
      "Epoch 861\n",
      " ---------------------- loss: tensor([5911.9028], grad_fn=<DivBackward0>)\n",
      "Epoch 862\n",
      " ---------------------- loss: tensor([5911.8335], grad_fn=<DivBackward0>)\n",
      "Epoch 863\n",
      " ---------------------- loss: tensor([5911.7632], grad_fn=<DivBackward0>)\n",
      "Epoch 864\n",
      " ---------------------- loss: tensor([5911.6938], grad_fn=<DivBackward0>)\n",
      "Epoch 865\n",
      " ---------------------- loss: tensor([5911.6235], grad_fn=<DivBackward0>)\n",
      "Epoch 866\n",
      " ---------------------- loss: tensor([5911.5527], grad_fn=<DivBackward0>)\n",
      "Epoch 867\n",
      " ---------------------- loss: tensor([5911.4839], grad_fn=<DivBackward0>)\n",
      "Epoch 868\n",
      " ---------------------- loss: tensor([5911.4126], grad_fn=<DivBackward0>)\n",
      "Epoch 869\n",
      " ---------------------- loss: tensor([5911.3418], grad_fn=<DivBackward0>)\n",
      "Epoch 870\n",
      " ---------------------- loss: tensor([5911.2720], grad_fn=<DivBackward0>)\n",
      "Epoch 871\n",
      " ---------------------- loss: tensor([5911.2012], grad_fn=<DivBackward0>)\n",
      "Epoch 872\n",
      " ---------------------- loss: tensor([5911.1299], grad_fn=<DivBackward0>)\n",
      "Epoch 873\n",
      " ---------------------- loss: tensor([5911.0596], grad_fn=<DivBackward0>)\n",
      "Epoch 874\n",
      " ---------------------- loss: tensor([5910.9883], grad_fn=<DivBackward0>)\n",
      "Epoch 875\n",
      " ---------------------- loss: tensor([5910.9180], grad_fn=<DivBackward0>)\n",
      "Epoch 876\n",
      " ---------------------- loss: tensor([5910.8462], grad_fn=<DivBackward0>)\n",
      "Epoch 877\n",
      " ---------------------- loss: tensor([5910.7749], grad_fn=<DivBackward0>)\n",
      "Epoch 878\n",
      " ---------------------- loss: tensor([5910.7036], grad_fn=<DivBackward0>)\n",
      "Epoch 879\n",
      " ---------------------- loss: tensor([5910.6343], grad_fn=<DivBackward0>)\n",
      "Epoch 880\n",
      " ---------------------- loss: tensor([5910.5605], grad_fn=<DivBackward0>)\n",
      "Epoch 881\n",
      " ---------------------- loss: tensor([5910.4883], grad_fn=<DivBackward0>)\n",
      "Epoch 882\n",
      " ---------------------- loss: tensor([5910.4175], grad_fn=<DivBackward0>)\n",
      "Epoch 883\n",
      " ---------------------- loss: tensor([5910.3447], grad_fn=<DivBackward0>)\n",
      "Epoch 884\n",
      " ---------------------- loss: tensor([5910.2729], grad_fn=<DivBackward0>)\n",
      "Epoch 885\n",
      " ---------------------- loss: tensor([5910.2021], grad_fn=<DivBackward0>)\n",
      "Epoch 886\n",
      " ---------------------- loss: tensor([5910.1294], grad_fn=<DivBackward0>)\n",
      "Epoch 887\n",
      " ---------------------- loss: tensor([5910.0566], grad_fn=<DivBackward0>)\n",
      "Epoch 888\n",
      " ---------------------- loss: tensor([5909.9849], grad_fn=<DivBackward0>)\n",
      "Epoch 889\n",
      " ---------------------- loss: tensor([5909.9131], grad_fn=<DivBackward0>)\n",
      "Epoch 890\n",
      " ---------------------- loss: tensor([5909.8394], grad_fn=<DivBackward0>)\n",
      "Epoch 891\n",
      " ---------------------- loss: tensor([5909.7661], grad_fn=<DivBackward0>)\n",
      "Epoch 892\n",
      " ---------------------- loss: tensor([5909.6929], grad_fn=<DivBackward0>)\n",
      "Epoch 893\n",
      " ---------------------- loss: tensor([5909.6201], grad_fn=<DivBackward0>)\n",
      "Epoch 894\n",
      " ---------------------- loss: tensor([5909.5479], grad_fn=<DivBackward0>)\n",
      "Epoch 895\n",
      " ---------------------- loss: tensor([5909.4751], grad_fn=<DivBackward0>)\n",
      "Epoch 896\n",
      " ---------------------- loss: tensor([5909.4019], grad_fn=<DivBackward0>)\n",
      "Epoch 897\n",
      " ---------------------- loss: tensor([5909.3286], grad_fn=<DivBackward0>)\n",
      "Epoch 898\n",
      " ---------------------- loss: tensor([5909.2524], grad_fn=<DivBackward0>)\n",
      "Epoch 899\n",
      " ---------------------- loss: tensor([5909.1816], grad_fn=<DivBackward0>)\n",
      "Epoch 900\n",
      " ---------------------- loss: tensor([5909.1060], grad_fn=<DivBackward0>)\n",
      "Epoch 901\n",
      " ---------------------- loss: tensor([5909.0332], grad_fn=<DivBackward0>)\n",
      "Epoch 902\n",
      " ---------------------- loss: tensor([5908.9590], grad_fn=<DivBackward0>)\n",
      "Epoch 903\n",
      " ---------------------- loss: tensor([5908.8853], grad_fn=<DivBackward0>)\n",
      "Epoch 904\n",
      " ---------------------- loss: tensor([5908.8115], grad_fn=<DivBackward0>)\n",
      "Epoch 905\n",
      " ---------------------- loss: tensor([5908.7358], grad_fn=<DivBackward0>)\n",
      "Epoch 906\n",
      " ---------------------- loss: tensor([5908.6616], grad_fn=<DivBackward0>)\n",
      "Epoch 907\n",
      " ---------------------- loss: tensor([5908.5869], grad_fn=<DivBackward0>)\n",
      "Epoch 908\n",
      " ---------------------- loss: tensor([5908.5132], grad_fn=<DivBackward0>)\n",
      "Epoch 909\n",
      " ---------------------- loss: tensor([5908.4365], grad_fn=<DivBackward0>)\n",
      "Epoch 910\n",
      " ---------------------- loss: tensor([5908.3623], grad_fn=<DivBackward0>)\n",
      "Epoch 911\n",
      " ---------------------- loss: tensor([5908.2866], grad_fn=<DivBackward0>)\n",
      "Epoch 912\n",
      " ---------------------- loss: tensor([5908.2124], grad_fn=<DivBackward0>)\n",
      "Epoch 913\n",
      " ---------------------- loss: tensor([5908.1372], grad_fn=<DivBackward0>)\n",
      "Epoch 914\n",
      " ---------------------- loss: tensor([5908.0605], grad_fn=<DivBackward0>)\n",
      "Epoch 915\n",
      " ---------------------- loss: tensor([5907.9849], grad_fn=<DivBackward0>)\n",
      "Epoch 916\n",
      " ---------------------- loss: tensor([5907.9111], grad_fn=<DivBackward0>)\n",
      "Epoch 917\n",
      " ---------------------- loss: tensor([5907.8345], grad_fn=<DivBackward0>)\n",
      "Epoch 918\n",
      " ---------------------- loss: tensor([5907.7588], grad_fn=<DivBackward0>)\n",
      "Epoch 919\n",
      " ---------------------- loss: tensor([5907.6826], grad_fn=<DivBackward0>)\n",
      "Epoch 920\n",
      " ---------------------- loss: tensor([5907.6094], grad_fn=<DivBackward0>)\n",
      "Epoch 921\n",
      " ---------------------- loss: tensor([5907.5303], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 922\n",
      " ---------------------- loss: tensor([5907.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 923\n",
      " ---------------------- loss: tensor([5907.3774], grad_fn=<DivBackward0>)\n",
      "Epoch 924\n",
      " ---------------------- loss: tensor([5907.3008], grad_fn=<DivBackward0>)\n",
      "Epoch 925\n",
      " ---------------------- loss: tensor([5907.2251], grad_fn=<DivBackward0>)\n",
      "Epoch 926\n",
      " ---------------------- loss: tensor([5907.1475], grad_fn=<DivBackward0>)\n",
      "Epoch 927\n",
      " ---------------------- loss: tensor([5907.0713], grad_fn=<DivBackward0>)\n",
      "Epoch 928\n",
      " ---------------------- loss: tensor([5906.9932], grad_fn=<DivBackward0>)\n",
      "Epoch 929\n",
      " ---------------------- loss: tensor([5906.9170], grad_fn=<DivBackward0>)\n",
      "Epoch 930\n",
      " ---------------------- loss: tensor([5906.8389], grad_fn=<DivBackward0>)\n",
      "Epoch 931\n",
      " ---------------------- loss: tensor([5906.7617], grad_fn=<DivBackward0>)\n",
      "Epoch 932\n",
      " ---------------------- loss: tensor([5906.6846], grad_fn=<DivBackward0>)\n",
      "Epoch 933\n",
      " ---------------------- loss: tensor([5906.6055], grad_fn=<DivBackward0>)\n",
      "Epoch 934\n",
      " ---------------------- loss: tensor([5906.5278], grad_fn=<DivBackward0>)\n",
      "Epoch 935\n",
      " ---------------------- loss: tensor([5906.4502], grad_fn=<DivBackward0>)\n",
      "Epoch 936\n",
      " ---------------------- loss: tensor([5906.3726], grad_fn=<DivBackward0>)\n",
      "Epoch 937\n",
      " ---------------------- loss: tensor([5906.2944], grad_fn=<DivBackward0>)\n",
      "Epoch 938\n",
      " ---------------------- loss: tensor([5906.2163], grad_fn=<DivBackward0>)\n",
      "Epoch 939\n",
      " ---------------------- loss: tensor([5906.1382], grad_fn=<DivBackward0>)\n",
      "Epoch 940\n",
      " ---------------------- loss: tensor([5906.0596], grad_fn=<DivBackward0>)\n",
      "Epoch 941\n",
      " ---------------------- loss: tensor([5905.9805], grad_fn=<DivBackward0>)\n",
      "Epoch 942\n",
      " ---------------------- loss: tensor([5905.9023], grad_fn=<DivBackward0>)\n",
      "Epoch 943\n",
      " ---------------------- loss: tensor([5905.8223], grad_fn=<DivBackward0>)\n",
      "Epoch 944\n",
      " ---------------------- loss: tensor([5905.7437], grad_fn=<DivBackward0>)\n",
      "Epoch 945\n",
      " ---------------------- loss: tensor([5905.6641], grad_fn=<DivBackward0>)\n",
      "Epoch 946\n",
      " ---------------------- loss: tensor([5905.5850], grad_fn=<DivBackward0>)\n",
      "Epoch 947\n",
      " ---------------------- loss: tensor([5905.5054], grad_fn=<DivBackward0>)\n",
      "Epoch 948\n",
      " ---------------------- loss: tensor([5905.4263], grad_fn=<DivBackward0>)\n",
      "Epoch 949\n",
      " ---------------------- loss: tensor([5905.3481], grad_fn=<DivBackward0>)\n",
      "Epoch 950\n",
      " ---------------------- loss: tensor([5905.2646], grad_fn=<DivBackward0>)\n",
      "Epoch 951\n",
      " ---------------------- loss: tensor([5905.1865], grad_fn=<DivBackward0>)\n",
      "Epoch 952\n",
      " ---------------------- loss: tensor([5905.1055], grad_fn=<DivBackward0>)\n",
      "Epoch 953\n",
      " ---------------------- loss: tensor([5905.0269], grad_fn=<DivBackward0>)\n",
      "Epoch 954\n",
      " ---------------------- loss: tensor([5904.9468], grad_fn=<DivBackward0>)\n",
      "Epoch 955\n",
      " ---------------------- loss: tensor([5904.8652], grad_fn=<DivBackward0>)\n",
      "Epoch 956\n",
      " ---------------------- loss: tensor([5904.7852], grad_fn=<DivBackward0>)\n",
      "Epoch 957\n",
      " ---------------------- loss: tensor([5904.7041], grad_fn=<DivBackward0>)\n",
      "Epoch 958\n",
      " ---------------------- loss: tensor([5904.6221], grad_fn=<DivBackward0>)\n",
      "Epoch 959\n",
      " ---------------------- loss: tensor([5904.5415], grad_fn=<DivBackward0>)\n",
      "Epoch 960\n",
      " ---------------------- loss: tensor([5904.4595], grad_fn=<DivBackward0>)\n",
      "Epoch 961\n",
      " ---------------------- loss: tensor([5904.3794], grad_fn=<DivBackward0>)\n",
      "Epoch 962\n",
      " ---------------------- loss: tensor([5904.2979], grad_fn=<DivBackward0>)\n",
      "Epoch 963\n",
      " ---------------------- loss: tensor([5904.2163], grad_fn=<DivBackward0>)\n",
      "Epoch 964\n",
      " ---------------------- loss: tensor([5904.1353], grad_fn=<DivBackward0>)\n",
      "Epoch 965\n",
      " ---------------------- loss: tensor([5904.0522], grad_fn=<DivBackward0>)\n",
      "Epoch 966\n",
      " ---------------------- loss: tensor([5903.9707], grad_fn=<DivBackward0>)\n",
      "Epoch 967\n",
      " ---------------------- loss: tensor([5903.8892], grad_fn=<DivBackward0>)\n",
      "Epoch 968\n",
      " ---------------------- loss: tensor([5903.8052], grad_fn=<DivBackward0>)\n",
      "Epoch 969\n",
      " ---------------------- loss: tensor([5903.7227], grad_fn=<DivBackward0>)\n",
      "Epoch 970\n",
      " ---------------------- loss: tensor([5903.6406], grad_fn=<DivBackward0>)\n",
      "Epoch 971\n",
      " ---------------------- loss: tensor([5903.5571], grad_fn=<DivBackward0>)\n",
      "Epoch 972\n",
      " ---------------------- loss: tensor([5903.4756], grad_fn=<DivBackward0>)\n",
      "Epoch 973\n",
      " ---------------------- loss: tensor([5903.3901], grad_fn=<DivBackward0>)\n",
      "Epoch 974\n",
      " ---------------------- loss: tensor([5903.3101], grad_fn=<DivBackward0>)\n",
      "Epoch 975\n",
      " ---------------------- loss: tensor([5903.2256], grad_fn=<DivBackward0>)\n",
      "Epoch 976\n",
      " ---------------------- loss: tensor([5903.1406], grad_fn=<DivBackward0>)\n",
      "Epoch 977\n",
      " ---------------------- loss: tensor([5903.0596], grad_fn=<DivBackward0>)\n",
      "Epoch 978\n",
      " ---------------------- loss: tensor([5902.9746], grad_fn=<DivBackward0>)\n",
      "Epoch 979\n",
      " ---------------------- loss: tensor([5902.8916], grad_fn=<DivBackward0>)\n",
      "Epoch 980\n",
      " ---------------------- loss: tensor([5902.8071], grad_fn=<DivBackward0>)\n",
      "Epoch 981\n",
      " ---------------------- loss: tensor([5902.7241], grad_fn=<DivBackward0>)\n",
      "Epoch 982\n",
      " ---------------------- loss: tensor([5902.6396], grad_fn=<DivBackward0>)\n",
      "Epoch 983\n",
      " ---------------------- loss: tensor([5902.5532], grad_fn=<DivBackward0>)\n",
      "Epoch 984\n",
      " ---------------------- loss: tensor([5902.4688], grad_fn=<DivBackward0>)\n",
      "Epoch 985\n",
      " ---------------------- loss: tensor([5902.3853], grad_fn=<DivBackward0>)\n",
      "Epoch 986\n",
      " ---------------------- loss: tensor([5902.2998], grad_fn=<DivBackward0>)\n",
      "Epoch 987\n",
      " ---------------------- loss: tensor([5902.2163], grad_fn=<DivBackward0>)\n",
      "Epoch 988\n",
      " ---------------------- loss: tensor([5902.1294], grad_fn=<DivBackward0>)\n",
      "Epoch 989\n",
      " ---------------------- loss: tensor([5902.0449], grad_fn=<DivBackward0>)\n",
      "Epoch 990\n",
      " ---------------------- loss: tensor([5901.9575], grad_fn=<DivBackward0>)\n",
      "Epoch 991\n",
      " ---------------------- loss: tensor([5901.8730], grad_fn=<DivBackward0>)\n",
      "Epoch 992\n",
      " ---------------------- loss: tensor([5901.7881], grad_fn=<DivBackward0>)\n",
      "Epoch 993\n",
      " ---------------------- loss: tensor([5901.7021], grad_fn=<DivBackward0>)\n",
      "Epoch 994\n",
      " ---------------------- loss: tensor([5901.6157], grad_fn=<DivBackward0>)\n",
      "Epoch 995\n",
      " ---------------------- loss: tensor([5901.5288], grad_fn=<DivBackward0>)\n",
      "Epoch 996\n",
      " ---------------------- loss: tensor([5901.4429], grad_fn=<DivBackward0>)\n",
      "Epoch 997\n",
      " ---------------------- loss: tensor([5901.3555], grad_fn=<DivBackward0>)\n",
      "Epoch 998\n",
      " ---------------------- loss: tensor([5901.2695], grad_fn=<DivBackward0>)\n",
      "Epoch 999\n",
      " ---------------------- loss: tensor([5901.1821], grad_fn=<DivBackward0>)\n",
      "Epoch 1000\n",
      " ---------------------- loss: tensor([5901.0977], grad_fn=<DivBackward0>)\n",
      "Epoch 1001\n",
      " ---------------------- loss: tensor([5901.0093], grad_fn=<DivBackward0>)\n",
      "Epoch 1002\n",
      " ---------------------- loss: tensor([5900.9219], grad_fn=<DivBackward0>)\n",
      "Epoch 1003\n",
      " ---------------------- loss: tensor([5900.8340], grad_fn=<DivBackward0>)\n",
      "Epoch 1004\n",
      " ---------------------- loss: tensor([5900.7476], grad_fn=<DivBackward0>)\n",
      "Epoch 1005\n",
      " ---------------------- loss: tensor([5900.6602], grad_fn=<DivBackward0>)\n",
      "Epoch 1006\n",
      " ---------------------- loss: tensor([5900.5718], grad_fn=<DivBackward0>)\n",
      "Epoch 1007\n",
      " ---------------------- loss: tensor([5900.4839], grad_fn=<DivBackward0>)\n",
      "Epoch 1008\n",
      " ---------------------- loss: tensor([5900.3955], grad_fn=<DivBackward0>)\n",
      "Epoch 1009\n",
      " ---------------------- loss: tensor([5900.3076], grad_fn=<DivBackward0>)\n",
      "Epoch 1010\n",
      " ---------------------- loss: tensor([5900.2183], grad_fn=<DivBackward0>)\n",
      "Epoch 1011\n",
      " ---------------------- loss: tensor([5900.1289], grad_fn=<DivBackward0>)\n",
      "Epoch 1012\n",
      " ---------------------- loss: tensor([5900.0405], grad_fn=<DivBackward0>)\n",
      "Epoch 1013\n",
      " ---------------------- loss: tensor([5899.9517], grad_fn=<DivBackward0>)\n",
      "Epoch 1014\n",
      " ---------------------- loss: tensor([5899.8628], grad_fn=<DivBackward0>)\n",
      "Epoch 1015\n",
      " ---------------------- loss: tensor([5899.7725], grad_fn=<DivBackward0>)\n",
      "Epoch 1016\n",
      " ---------------------- loss: tensor([5899.6846], grad_fn=<DivBackward0>)\n",
      "Epoch 1017\n",
      " ---------------------- loss: tensor([5899.5957], grad_fn=<DivBackward0>)\n",
      "Epoch 1018\n",
      " ---------------------- loss: tensor([5899.5029], grad_fn=<DivBackward0>)\n",
      "Epoch 1019\n",
      " ---------------------- loss: tensor([5899.4146], grad_fn=<DivBackward0>)\n",
      "Epoch 1020\n",
      " ---------------------- loss: tensor([5899.3242], grad_fn=<DivBackward0>)\n",
      "Epoch 1021\n",
      " ---------------------- loss: tensor([5899.2339], grad_fn=<DivBackward0>)\n",
      "Epoch 1022\n",
      " ---------------------- loss: tensor([5899.1436], grad_fn=<DivBackward0>)\n",
      "Epoch 1023\n",
      " ---------------------- loss: tensor([5899.0532], grad_fn=<DivBackward0>)\n",
      "Epoch 1024\n",
      " ---------------------- loss: tensor([5898.9624], grad_fn=<DivBackward0>)\n",
      "Epoch 1025\n",
      " ---------------------- loss: tensor([5898.8711], grad_fn=<DivBackward0>)\n",
      "Epoch 1026\n",
      " ---------------------- loss: tensor([5898.7798], grad_fn=<DivBackward0>)\n",
      "Epoch 1027\n",
      " ---------------------- loss: tensor([5898.6870], grad_fn=<DivBackward0>)\n",
      "Epoch 1028\n",
      " ---------------------- loss: tensor([5898.5977], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1029\n",
      " ---------------------- loss: tensor([5898.5044], grad_fn=<DivBackward0>)\n",
      "Epoch 1030\n",
      " ---------------------- loss: tensor([5898.4150], grad_fn=<DivBackward0>)\n",
      "Epoch 1031\n",
      " ---------------------- loss: tensor([5898.3223], grad_fn=<DivBackward0>)\n",
      "Epoch 1032\n",
      " ---------------------- loss: tensor([5898.2300], grad_fn=<DivBackward0>)\n",
      "Epoch 1033\n",
      " ---------------------- loss: tensor([5898.1372], grad_fn=<DivBackward0>)\n",
      "Epoch 1034\n",
      " ---------------------- loss: tensor([5898.0444], grad_fn=<DivBackward0>)\n",
      "Epoch 1035\n",
      " ---------------------- loss: tensor([5897.9521], grad_fn=<DivBackward0>)\n",
      "Epoch 1036\n",
      " ---------------------- loss: tensor([5897.8604], grad_fn=<DivBackward0>)\n",
      "Epoch 1037\n",
      " ---------------------- loss: tensor([5897.7676], grad_fn=<DivBackward0>)\n",
      "Epoch 1038\n",
      " ---------------------- loss: tensor([5897.6738], grad_fn=<DivBackward0>)\n",
      "Epoch 1039\n",
      " ---------------------- loss: tensor([5897.5801], grad_fn=<DivBackward0>)\n",
      "Epoch 1040\n",
      " ---------------------- loss: tensor([5897.4868], grad_fn=<DivBackward0>)\n",
      "Epoch 1041\n",
      " ---------------------- loss: tensor([5897.3936], grad_fn=<DivBackward0>)\n",
      "Epoch 1042\n",
      " ---------------------- loss: tensor([5897.2998], grad_fn=<DivBackward0>)\n",
      "Epoch 1043\n",
      " ---------------------- loss: tensor([5897.2061], grad_fn=<DivBackward0>)\n",
      "Epoch 1044\n",
      " ---------------------- loss: tensor([5897.1104], grad_fn=<DivBackward0>)\n",
      "Epoch 1045\n",
      " ---------------------- loss: tensor([5897.0161], grad_fn=<DivBackward0>)\n",
      "Epoch 1046\n",
      " ---------------------- loss: tensor([5896.9199], grad_fn=<DivBackward0>)\n",
      "Epoch 1047\n",
      " ---------------------- loss: tensor([5896.8281], grad_fn=<DivBackward0>)\n",
      "Epoch 1048\n",
      " ---------------------- loss: tensor([5896.7324], grad_fn=<DivBackward0>)\n",
      "Epoch 1049\n",
      " ---------------------- loss: tensor([5896.6372], grad_fn=<DivBackward0>)\n",
      "Epoch 1050\n",
      " ---------------------- loss: tensor([5896.5420], grad_fn=<DivBackward0>)\n",
      "Epoch 1051\n",
      " ---------------------- loss: tensor([5896.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 1052\n",
      " ---------------------- loss: tensor([5896.3511], grad_fn=<DivBackward0>)\n",
      "Epoch 1053\n",
      " ---------------------- loss: tensor([5896.2559], grad_fn=<DivBackward0>)\n",
      "Epoch 1054\n",
      " ---------------------- loss: tensor([5896.1587], grad_fn=<DivBackward0>)\n",
      "Epoch 1055\n",
      " ---------------------- loss: tensor([5896.0630], grad_fn=<DivBackward0>)\n",
      "Epoch 1056\n",
      " ---------------------- loss: tensor([5895.9658], grad_fn=<DivBackward0>)\n",
      "Epoch 1057\n",
      " ---------------------- loss: tensor([5895.8711], grad_fn=<DivBackward0>)\n",
      "Epoch 1058\n",
      " ---------------------- loss: tensor([5895.7734], grad_fn=<DivBackward0>)\n",
      "Epoch 1059\n",
      " ---------------------- loss: tensor([5895.6753], grad_fn=<DivBackward0>)\n",
      "Epoch 1060\n",
      " ---------------------- loss: tensor([5895.5781], grad_fn=<DivBackward0>)\n",
      "Epoch 1061\n",
      " ---------------------- loss: tensor([5895.4814], grad_fn=<DivBackward0>)\n",
      "Epoch 1062\n",
      " ---------------------- loss: tensor([5895.3823], grad_fn=<DivBackward0>)\n",
      "Epoch 1063\n",
      " ---------------------- loss: tensor([5895.2856], grad_fn=<DivBackward0>)\n",
      "Epoch 1064\n",
      " ---------------------- loss: tensor([5895.1895], grad_fn=<DivBackward0>)\n",
      "Epoch 1065\n",
      " ---------------------- loss: tensor([5895.0903], grad_fn=<DivBackward0>)\n",
      "Epoch 1066\n",
      " ---------------------- loss: tensor([5894.9927], grad_fn=<DivBackward0>)\n",
      "Epoch 1067\n",
      " ---------------------- loss: tensor([5894.8940], grad_fn=<DivBackward0>)\n",
      "Epoch 1068\n",
      " ---------------------- loss: tensor([5894.7954], grad_fn=<DivBackward0>)\n",
      "Epoch 1069\n",
      " ---------------------- loss: tensor([5894.6968], grad_fn=<DivBackward0>)\n",
      "Epoch 1070\n",
      " ---------------------- loss: tensor([5894.5977], grad_fn=<DivBackward0>)\n",
      "Epoch 1071\n",
      " ---------------------- loss: tensor([5894.4980], grad_fn=<DivBackward0>)\n",
      "Epoch 1072\n",
      " ---------------------- loss: tensor([5894.3994], grad_fn=<DivBackward0>)\n",
      "Epoch 1073\n",
      " ---------------------- loss: tensor([5894.2993], grad_fn=<DivBackward0>)\n",
      "Epoch 1074\n",
      " ---------------------- loss: tensor([5894.1992], grad_fn=<DivBackward0>)\n",
      "Epoch 1075\n",
      " ---------------------- loss: tensor([5894.0996], grad_fn=<DivBackward0>)\n",
      "Epoch 1076\n",
      " ---------------------- loss: tensor([5893.9985], grad_fn=<DivBackward0>)\n",
      "Epoch 1077\n",
      " ---------------------- loss: tensor([5893.8989], grad_fn=<DivBackward0>)\n",
      "Epoch 1078\n",
      " ---------------------- loss: tensor([5893.7979], grad_fn=<DivBackward0>)\n",
      "Epoch 1079\n",
      " ---------------------- loss: tensor([5893.6978], grad_fn=<DivBackward0>)\n",
      "Epoch 1080\n",
      " ---------------------- loss: tensor([5893.5967], grad_fn=<DivBackward0>)\n",
      "Epoch 1081\n",
      " ---------------------- loss: tensor([5893.4951], grad_fn=<DivBackward0>)\n",
      "Epoch 1082\n",
      " ---------------------- loss: tensor([5893.3936], grad_fn=<DivBackward0>)\n",
      "Epoch 1083\n",
      " ---------------------- loss: tensor([5893.2920], grad_fn=<DivBackward0>)\n",
      "Epoch 1084\n",
      " ---------------------- loss: tensor([5893.1904], grad_fn=<DivBackward0>)\n",
      "Epoch 1085\n",
      " ---------------------- loss: tensor([5893.0879], grad_fn=<DivBackward0>)\n",
      "Epoch 1086\n",
      " ---------------------- loss: tensor([5892.9858], grad_fn=<DivBackward0>)\n",
      "Epoch 1087\n",
      " ---------------------- loss: tensor([5892.8818], grad_fn=<DivBackward0>)\n",
      "Epoch 1088\n",
      " ---------------------- loss: tensor([5892.7803], grad_fn=<DivBackward0>)\n",
      "Epoch 1089\n",
      " ---------------------- loss: tensor([5892.6782], grad_fn=<DivBackward0>)\n",
      "Epoch 1090\n",
      " ---------------------- loss: tensor([5892.5752], grad_fn=<DivBackward0>)\n",
      "Epoch 1091\n",
      " ---------------------- loss: tensor([5892.4731], grad_fn=<DivBackward0>)\n",
      "Epoch 1092\n",
      " ---------------------- loss: tensor([5892.3687], grad_fn=<DivBackward0>)\n",
      "Epoch 1093\n",
      " ---------------------- loss: tensor([5892.2651], grad_fn=<DivBackward0>)\n",
      "Epoch 1094\n",
      " ---------------------- loss: tensor([5892.1606], grad_fn=<DivBackward0>)\n",
      "Epoch 1095\n",
      " ---------------------- loss: tensor([5892.0566], grad_fn=<DivBackward0>)\n",
      "Epoch 1096\n",
      " ---------------------- loss: tensor([5891.9526], grad_fn=<DivBackward0>)\n",
      "Epoch 1097\n",
      " ---------------------- loss: tensor([5891.8472], grad_fn=<DivBackward0>)\n",
      "Epoch 1098\n",
      " ---------------------- loss: tensor([5891.7437], grad_fn=<DivBackward0>)\n",
      "Epoch 1099\n",
      " ---------------------- loss: tensor([5891.6387], grad_fn=<DivBackward0>)\n",
      "Epoch 1100\n",
      " ---------------------- loss: tensor([5891.5332], grad_fn=<DivBackward0>)\n",
      "Epoch 1101\n",
      " ---------------------- loss: tensor([5891.4277], grad_fn=<DivBackward0>)\n",
      "Epoch 1102\n",
      " ---------------------- loss: tensor([5891.3228], grad_fn=<DivBackward0>)\n",
      "Epoch 1103\n",
      " ---------------------- loss: tensor([5891.2163], grad_fn=<DivBackward0>)\n",
      "Epoch 1104\n",
      " ---------------------- loss: tensor([5891.1099], grad_fn=<DivBackward0>)\n",
      "Epoch 1105\n",
      " ---------------------- loss: tensor([5891.0049], grad_fn=<DivBackward0>)\n",
      "Epoch 1106\n",
      " ---------------------- loss: tensor([5890.8984], grad_fn=<DivBackward0>)\n",
      "Epoch 1107\n",
      " ---------------------- loss: tensor([5890.7910], grad_fn=<DivBackward0>)\n",
      "Epoch 1108\n",
      " ---------------------- loss: tensor([5890.6846], grad_fn=<DivBackward0>)\n",
      "Epoch 1109\n",
      " ---------------------- loss: tensor([5890.5776], grad_fn=<DivBackward0>)\n",
      "Epoch 1110\n",
      " ---------------------- loss: tensor([5890.4683], grad_fn=<DivBackward0>)\n",
      "Epoch 1111\n",
      " ---------------------- loss: tensor([5890.3613], grad_fn=<DivBackward0>)\n",
      "Epoch 1112\n",
      " ---------------------- loss: tensor([5890.2544], grad_fn=<DivBackward0>)\n",
      "Epoch 1113\n",
      " ---------------------- loss: tensor([5890.1455], grad_fn=<DivBackward0>)\n",
      "Epoch 1114\n",
      " ---------------------- loss: tensor([5890.0376], grad_fn=<DivBackward0>)\n",
      "Epoch 1115\n",
      " ---------------------- loss: tensor([5889.9287], grad_fn=<DivBackward0>)\n",
      "Epoch 1116\n",
      " ---------------------- loss: tensor([5889.8213], grad_fn=<DivBackward0>)\n",
      "Epoch 1117\n",
      " ---------------------- loss: tensor([5889.7109], grad_fn=<DivBackward0>)\n",
      "Epoch 1118\n",
      " ---------------------- loss: tensor([5889.6016], grad_fn=<DivBackward0>)\n",
      "Epoch 1119\n",
      " ---------------------- loss: tensor([5889.4932], grad_fn=<DivBackward0>)\n",
      "Epoch 1120\n",
      " ---------------------- loss: tensor([5889.3843], grad_fn=<DivBackward0>)\n",
      "Epoch 1121\n",
      " ---------------------- loss: tensor([5889.2725], grad_fn=<DivBackward0>)\n",
      "Epoch 1122\n",
      " ---------------------- loss: tensor([5889.1641], grad_fn=<DivBackward0>)\n",
      "Epoch 1123\n",
      " ---------------------- loss: tensor([5889.0518], grad_fn=<DivBackward0>)\n",
      "Epoch 1124\n",
      " ---------------------- loss: tensor([5888.9434], grad_fn=<DivBackward0>)\n",
      "Epoch 1125\n",
      " ---------------------- loss: tensor([5888.8320], grad_fn=<DivBackward0>)\n",
      "Epoch 1126\n",
      " ---------------------- loss: tensor([5888.7217], grad_fn=<DivBackward0>)\n",
      "Epoch 1127\n",
      " ---------------------- loss: tensor([5888.6104], grad_fn=<DivBackward0>)\n",
      "Epoch 1128\n",
      " ---------------------- loss: tensor([5888.4985], grad_fn=<DivBackward0>)\n",
      "Epoch 1129\n",
      " ---------------------- loss: tensor([5888.3862], grad_fn=<DivBackward0>)\n",
      "Epoch 1130\n",
      " ---------------------- loss: tensor([5888.2739], grad_fn=<DivBackward0>)\n",
      "Epoch 1131\n",
      " ---------------------- loss: tensor([5888.1621], grad_fn=<DivBackward0>)\n",
      "Epoch 1132\n",
      " ---------------------- loss: tensor([5888.0498], grad_fn=<DivBackward0>)\n",
      "Epoch 1133\n",
      " ---------------------- loss: tensor([5887.9370], grad_fn=<DivBackward0>)\n",
      "Epoch 1134\n",
      " ---------------------- loss: tensor([5887.8247], grad_fn=<DivBackward0>)\n",
      "Epoch 1135\n",
      " ---------------------- loss: tensor([5887.7114], grad_fn=<DivBackward0>)\n",
      "Epoch 1136\n",
      " ---------------------- loss: tensor([5887.5967], grad_fn=<DivBackward0>)\n",
      "Epoch 1137\n",
      " ---------------------- loss: tensor([5887.4834], grad_fn=<DivBackward0>)\n",
      "Epoch 1138\n",
      " ---------------------- loss: tensor([5887.3696], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1139\n",
      " ---------------------- loss: tensor([5887.2549], grad_fn=<DivBackward0>)\n",
      "Epoch 1140\n",
      " ---------------------- loss: tensor([5887.1411], grad_fn=<DivBackward0>)\n",
      "Epoch 1141\n",
      " ---------------------- loss: tensor([5887.0264], grad_fn=<DivBackward0>)\n",
      "Epoch 1142\n",
      " ---------------------- loss: tensor([5886.9102], grad_fn=<DivBackward0>)\n",
      "Epoch 1143\n",
      " ---------------------- loss: tensor([5886.7954], grad_fn=<DivBackward0>)\n",
      "Epoch 1144\n",
      " ---------------------- loss: tensor([5886.6816], grad_fn=<DivBackward0>)\n",
      "Epoch 1145\n",
      " ---------------------- loss: tensor([5886.5640], grad_fn=<DivBackward0>)\n",
      "Epoch 1146\n",
      " ---------------------- loss: tensor([5886.4487], grad_fn=<DivBackward0>)\n",
      "Epoch 1147\n",
      " ---------------------- loss: tensor([5886.3325], grad_fn=<DivBackward0>)\n",
      "Epoch 1148\n",
      " ---------------------- loss: tensor([5886.2144], grad_fn=<DivBackward0>)\n",
      "Epoch 1149\n",
      " ---------------------- loss: tensor([5886.1001], grad_fn=<DivBackward0>)\n",
      "Epoch 1150\n",
      " ---------------------- loss: tensor([5885.9824], grad_fn=<DivBackward0>)\n",
      "Epoch 1151\n",
      " ---------------------- loss: tensor([5885.8662], grad_fn=<DivBackward0>)\n",
      "Epoch 1152\n",
      " ---------------------- loss: tensor([5885.7471], grad_fn=<DivBackward0>)\n",
      "Epoch 1153\n",
      " ---------------------- loss: tensor([5885.6294], grad_fn=<DivBackward0>)\n",
      "Epoch 1154\n",
      " ---------------------- loss: tensor([5885.5117], grad_fn=<DivBackward0>)\n",
      "Epoch 1155\n",
      " ---------------------- loss: tensor([5885.3940], grad_fn=<DivBackward0>)\n",
      "Epoch 1156\n",
      " ---------------------- loss: tensor([5885.2744], grad_fn=<DivBackward0>)\n",
      "Epoch 1157\n",
      " ---------------------- loss: tensor([5885.1553], grad_fn=<DivBackward0>)\n",
      "Epoch 1158\n",
      " ---------------------- loss: tensor([5885.0356], grad_fn=<DivBackward0>)\n",
      "Epoch 1159\n",
      " ---------------------- loss: tensor([5884.9170], grad_fn=<DivBackward0>)\n",
      "Epoch 1160\n",
      " ---------------------- loss: tensor([5884.7964], grad_fn=<DivBackward0>)\n",
      "Epoch 1161\n",
      " ---------------------- loss: tensor([5884.6763], grad_fn=<DivBackward0>)\n",
      "Epoch 1162\n",
      " ---------------------- loss: tensor([5884.5566], grad_fn=<DivBackward0>)\n",
      "Epoch 1163\n",
      " ---------------------- loss: tensor([5884.4360], grad_fn=<DivBackward0>)\n",
      "Epoch 1164\n",
      " ---------------------- loss: tensor([5884.3154], grad_fn=<DivBackward0>)\n",
      "Epoch 1165\n",
      " ---------------------- loss: tensor([5884.1948], grad_fn=<DivBackward0>)\n",
      "Epoch 1166\n",
      " ---------------------- loss: tensor([5884.0723], grad_fn=<DivBackward0>)\n",
      "Epoch 1167\n",
      " ---------------------- loss: tensor([5883.9531], grad_fn=<DivBackward0>)\n",
      "Epoch 1168\n",
      " ---------------------- loss: tensor([5883.8306], grad_fn=<DivBackward0>)\n",
      "Epoch 1169\n",
      " ---------------------- loss: tensor([5883.7075], grad_fn=<DivBackward0>)\n",
      "Epoch 1170\n",
      " ---------------------- loss: tensor([5883.5864], grad_fn=<DivBackward0>)\n",
      "Epoch 1171\n",
      " ---------------------- loss: tensor([5883.4624], grad_fn=<DivBackward0>)\n",
      "Epoch 1172\n",
      " ---------------------- loss: tensor([5883.3394], grad_fn=<DivBackward0>)\n",
      "Epoch 1173\n",
      " ---------------------- loss: tensor([5883.2158], grad_fn=<DivBackward0>)\n",
      "Epoch 1174\n",
      " ---------------------- loss: tensor([5883.0923], grad_fn=<DivBackward0>)\n",
      "Epoch 1175\n",
      " ---------------------- loss: tensor([5882.9683], grad_fn=<DivBackward0>)\n",
      "Epoch 1176\n",
      " ---------------------- loss: tensor([5882.8447], grad_fn=<DivBackward0>)\n",
      "Epoch 1177\n",
      " ---------------------- loss: tensor([5882.7207], grad_fn=<DivBackward0>)\n",
      "Epoch 1178\n",
      " ---------------------- loss: tensor([5882.5947], grad_fn=<DivBackward0>)\n",
      "Epoch 1179\n",
      " ---------------------- loss: tensor([5882.4712], grad_fn=<DivBackward0>)\n",
      "Epoch 1180\n",
      " ---------------------- loss: tensor([5882.3442], grad_fn=<DivBackward0>)\n",
      "Epoch 1181\n",
      " ---------------------- loss: tensor([5882.2188], grad_fn=<DivBackward0>)\n",
      "Epoch 1182\n",
      " ---------------------- loss: tensor([5882.0933], grad_fn=<DivBackward0>)\n",
      "Epoch 1183\n",
      " ---------------------- loss: tensor([5881.9673], grad_fn=<DivBackward0>)\n",
      "Epoch 1184\n",
      " ---------------------- loss: tensor([5881.8413], grad_fn=<DivBackward0>)\n",
      "Epoch 1185\n",
      " ---------------------- loss: tensor([5881.7124], grad_fn=<DivBackward0>)\n",
      "Epoch 1186\n",
      " ---------------------- loss: tensor([5881.5869], grad_fn=<DivBackward0>)\n",
      "Epoch 1187\n",
      " ---------------------- loss: tensor([5881.4595], grad_fn=<DivBackward0>)\n",
      "Epoch 1188\n",
      " ---------------------- loss: tensor([5881.3311], grad_fn=<DivBackward0>)\n",
      "Epoch 1189\n",
      " ---------------------- loss: tensor([5881.2031], grad_fn=<DivBackward0>)\n",
      "Epoch 1190\n",
      " ---------------------- loss: tensor([5881.0752], grad_fn=<DivBackward0>)\n",
      "Epoch 1191\n",
      " ---------------------- loss: tensor([5880.9458], grad_fn=<DivBackward0>)\n",
      "Epoch 1192\n",
      " ---------------------- loss: tensor([5880.8174], grad_fn=<DivBackward0>)\n",
      "Epoch 1193\n",
      " ---------------------- loss: tensor([5880.6880], grad_fn=<DivBackward0>)\n",
      "Epoch 1194\n",
      " ---------------------- loss: tensor([5880.5581], grad_fn=<DivBackward0>)\n",
      "Epoch 1195\n",
      " ---------------------- loss: tensor([5880.4287], grad_fn=<DivBackward0>)\n",
      "Epoch 1196\n",
      " ---------------------- loss: tensor([5880.2993], grad_fn=<DivBackward0>)\n",
      "Epoch 1197\n",
      " ---------------------- loss: tensor([5880.1680], grad_fn=<DivBackward0>)\n",
      "Epoch 1198\n",
      " ---------------------- loss: tensor([5880.0371], grad_fn=<DivBackward0>)\n",
      "Epoch 1199\n",
      " ---------------------- loss: tensor([5879.9072], grad_fn=<DivBackward0>)\n",
      "Epoch 1200\n",
      " ---------------------- loss: tensor([5879.7744], grad_fn=<DivBackward0>)\n",
      "Epoch 1201\n",
      " ---------------------- loss: tensor([5879.6421], grad_fn=<DivBackward0>)\n",
      "Epoch 1202\n",
      " ---------------------- loss: tensor([5879.5107], grad_fn=<DivBackward0>)\n",
      "Epoch 1203\n",
      " ---------------------- loss: tensor([5879.3779], grad_fn=<DivBackward0>)\n",
      "Epoch 1204\n",
      " ---------------------- loss: tensor([5879.2466], grad_fn=<DivBackward0>)\n",
      "Epoch 1205\n",
      " ---------------------- loss: tensor([5879.1118], grad_fn=<DivBackward0>)\n",
      "Epoch 1206\n",
      " ---------------------- loss: tensor([5878.9771], grad_fn=<DivBackward0>)\n",
      "Epoch 1207\n",
      " ---------------------- loss: tensor([5878.8442], grad_fn=<DivBackward0>)\n",
      "Epoch 1208\n",
      " ---------------------- loss: tensor([5878.7095], grad_fn=<DivBackward0>)\n",
      "Epoch 1209\n",
      " ---------------------- loss: tensor([5878.5767], grad_fn=<DivBackward0>)\n",
      "Epoch 1210\n",
      " ---------------------- loss: tensor([5878.4404], grad_fn=<DivBackward0>)\n",
      "Epoch 1211\n",
      " ---------------------- loss: tensor([5878.3066], grad_fn=<DivBackward0>)\n",
      "Epoch 1212\n",
      " ---------------------- loss: tensor([5878.1719], grad_fn=<DivBackward0>)\n",
      "Epoch 1213\n",
      " ---------------------- loss: tensor([5878.0352], grad_fn=<DivBackward0>)\n",
      "Epoch 1214\n",
      " ---------------------- loss: tensor([5877.8989], grad_fn=<DivBackward0>)\n",
      "Epoch 1215\n",
      " ---------------------- loss: tensor([5877.7637], grad_fn=<DivBackward0>)\n",
      "Epoch 1216\n",
      " ---------------------- loss: tensor([5877.6260], grad_fn=<DivBackward0>)\n",
      "Epoch 1217\n",
      " ---------------------- loss: tensor([5877.4893], grad_fn=<DivBackward0>)\n",
      "Epoch 1218\n",
      " ---------------------- loss: tensor([5877.3506], grad_fn=<DivBackward0>)\n",
      "Epoch 1219\n",
      " ---------------------- loss: tensor([5877.2134], grad_fn=<DivBackward0>)\n",
      "Epoch 1220\n",
      " ---------------------- loss: tensor([5877.0767], grad_fn=<DivBackward0>)\n",
      "Epoch 1221\n",
      " ---------------------- loss: tensor([5876.9375], grad_fn=<DivBackward0>)\n",
      "Epoch 1222\n",
      " ---------------------- loss: tensor([5876.7969], grad_fn=<DivBackward0>)\n",
      "Epoch 1223\n",
      " ---------------------- loss: tensor([5876.6597], grad_fn=<DivBackward0>)\n",
      "Epoch 1224\n",
      " ---------------------- loss: tensor([5876.5200], grad_fn=<DivBackward0>)\n",
      "Epoch 1225\n",
      " ---------------------- loss: tensor([5876.3794], grad_fn=<DivBackward0>)\n",
      "Epoch 1226\n",
      " ---------------------- loss: tensor([5876.2393], grad_fn=<DivBackward0>)\n",
      "Epoch 1227\n",
      " ---------------------- loss: tensor([5876.0991], grad_fn=<DivBackward0>)\n",
      "Epoch 1228\n",
      " ---------------------- loss: tensor([5875.9565], grad_fn=<DivBackward0>)\n",
      "Epoch 1229\n",
      " ---------------------- loss: tensor([5875.8154], grad_fn=<DivBackward0>)\n",
      "Epoch 1230\n",
      " ---------------------- loss: tensor([5875.6748], grad_fn=<DivBackward0>)\n",
      "Epoch 1231\n",
      " ---------------------- loss: tensor([5875.5332], grad_fn=<DivBackward0>)\n",
      "Epoch 1232\n",
      " ---------------------- loss: tensor([5875.3916], grad_fn=<DivBackward0>)\n",
      "Epoch 1233\n",
      " ---------------------- loss: tensor([5875.2471], grad_fn=<DivBackward0>)\n",
      "Epoch 1234\n",
      " ---------------------- loss: tensor([5875.1040], grad_fn=<DivBackward0>)\n",
      "Epoch 1235\n",
      " ---------------------- loss: tensor([5874.9619], grad_fn=<DivBackward0>)\n",
      "Epoch 1236\n",
      " ---------------------- loss: tensor([5874.8174], grad_fn=<DivBackward0>)\n",
      "Epoch 1237\n",
      " ---------------------- loss: tensor([5874.6729], grad_fn=<DivBackward0>)\n",
      "Epoch 1238\n",
      " ---------------------- loss: tensor([5874.5273], grad_fn=<DivBackward0>)\n",
      "Epoch 1239\n",
      " ---------------------- loss: tensor([5874.3828], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1240\n",
      " ---------------------- loss: tensor([5874.2373], grad_fn=<DivBackward0>)\n",
      "Epoch 1241\n",
      " ---------------------- loss: tensor([5874.0908], grad_fn=<DivBackward0>)\n",
      "Epoch 1242\n",
      " ---------------------- loss: tensor([5873.9453], grad_fn=<DivBackward0>)\n",
      "Epoch 1243\n",
      " ---------------------- loss: tensor([5873.7988], grad_fn=<DivBackward0>)\n",
      "Epoch 1244\n",
      " ---------------------- loss: tensor([5873.6509], grad_fn=<DivBackward0>)\n",
      "Epoch 1245\n",
      " ---------------------- loss: tensor([5873.5029], grad_fn=<DivBackward0>)\n",
      "Epoch 1246\n",
      " ---------------------- loss: tensor([5873.3555], grad_fn=<DivBackward0>)\n",
      "Epoch 1247\n",
      " ---------------------- loss: tensor([5873.2100], grad_fn=<DivBackward0>)\n",
      "Epoch 1248\n",
      " ---------------------- loss: tensor([5873.0601], grad_fn=<DivBackward0>)\n",
      "Epoch 1249\n",
      " ---------------------- loss: tensor([5872.9111], grad_fn=<DivBackward0>)\n",
      "Epoch 1250\n",
      " ---------------------- loss: tensor([5872.7627], grad_fn=<DivBackward0>)\n",
      "Epoch 1251\n",
      " ---------------------- loss: tensor([5872.6118], grad_fn=<DivBackward0>)\n",
      "Epoch 1252\n",
      " ---------------------- loss: tensor([5872.4619], grad_fn=<DivBackward0>)\n",
      "Epoch 1253\n",
      " ---------------------- loss: tensor([5872.3110], grad_fn=<DivBackward0>)\n",
      "Epoch 1254\n",
      " ---------------------- loss: tensor([5872.1602], grad_fn=<DivBackward0>)\n",
      "Epoch 1255\n",
      " ---------------------- loss: tensor([5872.0083], grad_fn=<DivBackward0>)\n",
      "Epoch 1256\n",
      " ---------------------- loss: tensor([5871.8569], grad_fn=<DivBackward0>)\n",
      "Epoch 1257\n",
      " ---------------------- loss: tensor([5871.7046], grad_fn=<DivBackward0>)\n",
      "Epoch 1258\n",
      " ---------------------- loss: tensor([5871.5527], grad_fn=<DivBackward0>)\n",
      "Epoch 1259\n",
      " ---------------------- loss: tensor([5871.3989], grad_fn=<DivBackward0>)\n",
      "Epoch 1260\n",
      " ---------------------- loss: tensor([5871.2451], grad_fn=<DivBackward0>)\n",
      "Epoch 1261\n",
      " ---------------------- loss: tensor([5871.0913], grad_fn=<DivBackward0>)\n",
      "Epoch 1262\n",
      " ---------------------- loss: tensor([5870.9390], grad_fn=<DivBackward0>)\n",
      "Epoch 1263\n",
      " ---------------------- loss: tensor([5870.7827], grad_fn=<DivBackward0>)\n",
      "Epoch 1264\n",
      " ---------------------- loss: tensor([5870.6289], grad_fn=<DivBackward0>)\n",
      "Epoch 1265\n",
      " ---------------------- loss: tensor([5870.4727], grad_fn=<DivBackward0>)\n",
      "Epoch 1266\n",
      " ---------------------- loss: tensor([5870.3169], grad_fn=<DivBackward0>)\n",
      "Epoch 1267\n",
      " ---------------------- loss: tensor([5870.1592], grad_fn=<DivBackward0>)\n",
      "Epoch 1268\n",
      " ---------------------- loss: tensor([5870.0034], grad_fn=<DivBackward0>)\n",
      "Epoch 1269\n",
      " ---------------------- loss: tensor([5869.8472], grad_fn=<DivBackward0>)\n",
      "Epoch 1270\n",
      " ---------------------- loss: tensor([5869.6890], grad_fn=<DivBackward0>)\n",
      "Epoch 1271\n",
      " ---------------------- loss: tensor([5869.5308], grad_fn=<DivBackward0>)\n",
      "Epoch 1272\n",
      " ---------------------- loss: tensor([5869.3726], grad_fn=<DivBackward0>)\n",
      "Epoch 1273\n",
      " ---------------------- loss: tensor([5869.2129], grad_fn=<DivBackward0>)\n",
      "Epoch 1274\n",
      " ---------------------- loss: tensor([5869.0547], grad_fn=<DivBackward0>)\n",
      "Epoch 1275\n",
      " ---------------------- loss: tensor([5868.8936], grad_fn=<DivBackward0>)\n",
      "Epoch 1276\n",
      " ---------------------- loss: tensor([5868.7339], grad_fn=<DivBackward0>)\n",
      "Epoch 1277\n",
      " ---------------------- loss: tensor([5868.5728], grad_fn=<DivBackward0>)\n",
      "Epoch 1278\n",
      " ---------------------- loss: tensor([5868.4116], grad_fn=<DivBackward0>)\n",
      "Epoch 1279\n",
      " ---------------------- loss: tensor([5868.2500], grad_fn=<DivBackward0>)\n",
      "Epoch 1280\n",
      " ---------------------- loss: tensor([5868.0879], grad_fn=<DivBackward0>)\n",
      "Epoch 1281\n",
      " ---------------------- loss: tensor([5867.9243], grad_fn=<DivBackward0>)\n",
      "Epoch 1282\n",
      " ---------------------- loss: tensor([5867.7622], grad_fn=<DivBackward0>)\n",
      "Epoch 1283\n",
      " ---------------------- loss: tensor([5867.5981], grad_fn=<DivBackward0>)\n",
      "Epoch 1284\n",
      " ---------------------- loss: tensor([5867.4355], grad_fn=<DivBackward0>)\n",
      "Epoch 1285\n",
      " ---------------------- loss: tensor([5867.2720], grad_fn=<DivBackward0>)\n",
      "Epoch 1286\n",
      " ---------------------- loss: tensor([5867.1060], grad_fn=<DivBackward0>)\n",
      "Epoch 1287\n",
      " ---------------------- loss: tensor([5866.9399], grad_fn=<DivBackward0>)\n",
      "Epoch 1288\n",
      " ---------------------- loss: tensor([5866.7744], grad_fn=<DivBackward0>)\n",
      "Epoch 1289\n",
      " ---------------------- loss: tensor([5866.6079], grad_fn=<DivBackward0>)\n",
      "Epoch 1290\n",
      " ---------------------- loss: tensor([5866.4409], grad_fn=<DivBackward0>)\n",
      "Epoch 1291\n",
      " ---------------------- loss: tensor([5866.2744], grad_fn=<DivBackward0>)\n",
      "Epoch 1292\n",
      " ---------------------- loss: tensor([5866.1055], grad_fn=<DivBackward0>)\n",
      "Epoch 1293\n",
      " ---------------------- loss: tensor([5865.9385], grad_fn=<DivBackward0>)\n",
      "Epoch 1294\n",
      " ---------------------- loss: tensor([5865.7700], grad_fn=<DivBackward0>)\n",
      "Epoch 1295\n",
      " ---------------------- loss: tensor([5865.5981], grad_fn=<DivBackward0>)\n",
      "Epoch 1296\n",
      " ---------------------- loss: tensor([5865.4307], grad_fn=<DivBackward0>)\n",
      "Epoch 1297\n",
      " ---------------------- loss: tensor([5865.2598], grad_fn=<DivBackward0>)\n",
      "Epoch 1298\n",
      " ---------------------- loss: tensor([5865.0894], grad_fn=<DivBackward0>)\n",
      "Epoch 1299\n",
      " ---------------------- loss: tensor([5864.9189], grad_fn=<DivBackward0>)\n",
      "Epoch 1300\n",
      " ---------------------- loss: tensor([5864.7471], grad_fn=<DivBackward0>)\n",
      "Epoch 1301\n",
      " ---------------------- loss: tensor([5864.5742], grad_fn=<DivBackward0>)\n",
      "Epoch 1302\n",
      " ---------------------- loss: tensor([5864.4023], grad_fn=<DivBackward0>)\n",
      "Epoch 1303\n",
      " ---------------------- loss: tensor([5864.2300], grad_fn=<DivBackward0>)\n",
      "Epoch 1304\n",
      " ---------------------- loss: tensor([5864.0547], grad_fn=<DivBackward0>)\n",
      "Epoch 1305\n",
      " ---------------------- loss: tensor([5863.8794], grad_fn=<DivBackward0>)\n",
      "Epoch 1306\n",
      " ---------------------- loss: tensor([5863.7065], grad_fn=<DivBackward0>)\n",
      "Epoch 1307\n",
      " ---------------------- loss: tensor([5863.5317], grad_fn=<DivBackward0>)\n",
      "Epoch 1308\n",
      " ---------------------- loss: tensor([5863.3550], grad_fn=<DivBackward0>)\n",
      "Epoch 1309\n",
      " ---------------------- loss: tensor([5863.1792], grad_fn=<DivBackward0>)\n",
      "Epoch 1310\n",
      " ---------------------- loss: tensor([5863.0024], grad_fn=<DivBackward0>)\n",
      "Epoch 1311\n",
      " ---------------------- loss: tensor([5862.8242], grad_fn=<DivBackward0>)\n",
      "Epoch 1312\n",
      " ---------------------- loss: tensor([5862.6475], grad_fn=<DivBackward0>)\n",
      "Epoch 1313\n",
      " ---------------------- loss: tensor([5862.4683], grad_fn=<DivBackward0>)\n",
      "Epoch 1314\n",
      " ---------------------- loss: tensor([5862.2886], grad_fn=<DivBackward0>)\n",
      "Epoch 1315\n",
      " ---------------------- loss: tensor([5862.1094], grad_fn=<DivBackward0>)\n",
      "Epoch 1316\n",
      " ---------------------- loss: tensor([5861.9297], grad_fn=<DivBackward0>)\n",
      "Epoch 1317\n",
      " ---------------------- loss: tensor([5861.7495], grad_fn=<DivBackward0>)\n",
      "Epoch 1318\n",
      " ---------------------- loss: tensor([5861.5659], grad_fn=<DivBackward0>)\n",
      "Epoch 1319\n",
      " ---------------------- loss: tensor([5861.3867], grad_fn=<DivBackward0>)\n",
      "Epoch 1320\n",
      " ---------------------- loss: tensor([5861.2051], grad_fn=<DivBackward0>)\n",
      "Epoch 1321\n",
      " ---------------------- loss: tensor([5861.0215], grad_fn=<DivBackward0>)\n",
      "Epoch 1322\n",
      " ---------------------- loss: tensor([5860.8389], grad_fn=<DivBackward0>)\n",
      "Epoch 1323\n",
      " ---------------------- loss: tensor([5860.6528], grad_fn=<DivBackward0>)\n",
      "Epoch 1324\n",
      " ---------------------- loss: tensor([5860.4697], grad_fn=<DivBackward0>)\n",
      "Epoch 1325\n",
      " ---------------------- loss: tensor([5860.2856], grad_fn=<DivBackward0>)\n",
      "Epoch 1326\n",
      " ---------------------- loss: tensor([5860.0991], grad_fn=<DivBackward0>)\n",
      "Epoch 1327\n",
      " ---------------------- loss: tensor([5859.9131], grad_fn=<DivBackward0>)\n",
      "Epoch 1328\n",
      " ---------------------- loss: tensor([5859.7275], grad_fn=<DivBackward0>)\n",
      "Epoch 1329\n",
      " ---------------------- loss: tensor([5859.5391], grad_fn=<DivBackward0>)\n",
      "Epoch 1330\n",
      " ---------------------- loss: tensor([5859.3506], grad_fn=<DivBackward0>)\n",
      "Epoch 1331\n",
      " ---------------------- loss: tensor([5859.1631], grad_fn=<DivBackward0>)\n",
      "Epoch 1332\n",
      " ---------------------- loss: tensor([5858.9746], grad_fn=<DivBackward0>)\n",
      "Epoch 1333\n",
      " ---------------------- loss: tensor([5858.7842], grad_fn=<DivBackward0>)\n",
      "Epoch 1334\n",
      " ---------------------- loss: tensor([5858.5928], grad_fn=<DivBackward0>)\n",
      "Epoch 1335\n",
      " ---------------------- loss: tensor([5858.4038], grad_fn=<DivBackward0>)\n",
      "Epoch 1336\n",
      " ---------------------- loss: tensor([5858.2119], grad_fn=<DivBackward0>)\n",
      "Epoch 1337\n",
      " ---------------------- loss: tensor([5858.0190], grad_fn=<DivBackward0>)\n",
      "Epoch 1338\n",
      " ---------------------- loss: tensor([5857.8281], grad_fn=<DivBackward0>)\n",
      "Epoch 1339\n",
      " ---------------------- loss: tensor([5857.6343], grad_fn=<DivBackward0>)\n",
      "Epoch 1340\n",
      " ---------------------- loss: tensor([5857.4404], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1341\n",
      " ---------------------- loss: tensor([5857.2466], grad_fn=<DivBackward0>)\n",
      "Epoch 1342\n",
      " ---------------------- loss: tensor([5857.0513], grad_fn=<DivBackward0>)\n",
      "Epoch 1343\n",
      " ---------------------- loss: tensor([5856.8545], grad_fn=<DivBackward0>)\n",
      "Epoch 1344\n",
      " ---------------------- loss: tensor([5856.6582], grad_fn=<DivBackward0>)\n",
      "Epoch 1345\n",
      " ---------------------- loss: tensor([5856.4595], grad_fn=<DivBackward0>)\n",
      "Epoch 1346\n",
      " ---------------------- loss: tensor([5856.2651], grad_fn=<DivBackward0>)\n",
      "Epoch 1347\n",
      " ---------------------- loss: tensor([5856.0659], grad_fn=<DivBackward0>)\n",
      "Epoch 1348\n",
      " ---------------------- loss: tensor([5855.8672], grad_fn=<DivBackward0>)\n",
      "Epoch 1349\n",
      " ---------------------- loss: tensor([5855.6675], grad_fn=<DivBackward0>)\n",
      "Epoch 1350\n",
      " ---------------------- loss: tensor([5855.4683], grad_fn=<DivBackward0>)\n",
      "Epoch 1351\n",
      " ---------------------- loss: tensor([5855.2671], grad_fn=<DivBackward0>)\n",
      "Epoch 1352\n",
      " ---------------------- loss: tensor([5855.0645], grad_fn=<DivBackward0>)\n",
      "Epoch 1353\n",
      " ---------------------- loss: tensor([5854.8623], grad_fn=<DivBackward0>)\n",
      "Epoch 1354\n",
      " ---------------------- loss: tensor([5854.6606], grad_fn=<DivBackward0>)\n",
      "Epoch 1355\n",
      " ---------------------- loss: tensor([5854.4565], grad_fn=<DivBackward0>)\n",
      "Epoch 1356\n",
      " ---------------------- loss: tensor([5854.2534], grad_fn=<DivBackward0>)\n",
      "Epoch 1357\n",
      " ---------------------- loss: tensor([5854.0488], grad_fn=<DivBackward0>)\n",
      "Epoch 1358\n",
      " ---------------------- loss: tensor([5853.8433], grad_fn=<DivBackward0>)\n",
      "Epoch 1359\n",
      " ---------------------- loss: tensor([5853.6362], grad_fn=<DivBackward0>)\n",
      "Epoch 1360\n",
      " ---------------------- loss: tensor([5853.4302], grad_fn=<DivBackward0>)\n",
      "Epoch 1361\n",
      " ---------------------- loss: tensor([5853.2217], grad_fn=<DivBackward0>)\n",
      "Epoch 1362\n",
      " ---------------------- loss: tensor([5853.0142], grad_fn=<DivBackward0>)\n",
      "Epoch 1363\n",
      " ---------------------- loss: tensor([5852.8047], grad_fn=<DivBackward0>)\n",
      "Epoch 1364\n",
      " ---------------------- loss: tensor([5852.5967], grad_fn=<DivBackward0>)\n",
      "Epoch 1365\n",
      " ---------------------- loss: tensor([5852.3853], grad_fn=<DivBackward0>)\n",
      "Epoch 1366\n",
      " ---------------------- loss: tensor([5852.1753], grad_fn=<DivBackward0>)\n",
      "Epoch 1367\n",
      " ---------------------- loss: tensor([5851.9634], grad_fn=<DivBackward0>)\n",
      "Epoch 1368\n",
      " ---------------------- loss: tensor([5851.7520], grad_fn=<DivBackward0>)\n",
      "Epoch 1369\n",
      " ---------------------- loss: tensor([5851.5396], grad_fn=<DivBackward0>)\n",
      "Epoch 1370\n",
      " ---------------------- loss: tensor([5851.3247], grad_fn=<DivBackward0>)\n",
      "Epoch 1371\n",
      " ---------------------- loss: tensor([5851.1113], grad_fn=<DivBackward0>)\n",
      "Epoch 1372\n",
      " ---------------------- loss: tensor([5850.8950], grad_fn=<DivBackward0>)\n",
      "Epoch 1373\n",
      " ---------------------- loss: tensor([5850.6797], grad_fn=<DivBackward0>)\n",
      "Epoch 1374\n",
      " ---------------------- loss: tensor([5850.4639], grad_fn=<DivBackward0>)\n",
      "Epoch 1375\n",
      " ---------------------- loss: tensor([5850.2466], grad_fn=<DivBackward0>)\n",
      "Epoch 1376\n",
      " ---------------------- loss: tensor([5850.0269], grad_fn=<DivBackward0>)\n",
      "Epoch 1377\n",
      " ---------------------- loss: tensor([5849.8101], grad_fn=<DivBackward0>)\n",
      "Epoch 1378\n",
      " ---------------------- loss: tensor([5849.5898], grad_fn=<DivBackward0>)\n",
      "Epoch 1379\n",
      " ---------------------- loss: tensor([5849.3701], grad_fn=<DivBackward0>)\n",
      "Epoch 1380\n",
      " ---------------------- loss: tensor([5849.1504], grad_fn=<DivBackward0>)\n",
      "Epoch 1381\n",
      " ---------------------- loss: tensor([5848.9268], grad_fn=<DivBackward0>)\n",
      "Epoch 1382\n",
      " ---------------------- loss: tensor([5848.7036], grad_fn=<DivBackward0>)\n",
      "Epoch 1383\n",
      " ---------------------- loss: tensor([5848.4810], grad_fn=<DivBackward0>)\n",
      "Epoch 1384\n",
      " ---------------------- loss: tensor([5848.2568], grad_fn=<DivBackward0>)\n",
      "Epoch 1385\n",
      " ---------------------- loss: tensor([5848.0317], grad_fn=<DivBackward0>)\n",
      "Epoch 1386\n",
      " ---------------------- loss: tensor([5847.8052], grad_fn=<DivBackward0>)\n",
      "Epoch 1387\n",
      " ---------------------- loss: tensor([5847.5796], grad_fn=<DivBackward0>)\n",
      "Epoch 1388\n",
      " ---------------------- loss: tensor([5847.3540], grad_fn=<DivBackward0>)\n",
      "Epoch 1389\n",
      " ---------------------- loss: tensor([5847.1260], grad_fn=<DivBackward0>)\n",
      "Epoch 1390\n",
      " ---------------------- loss: tensor([5846.8970], grad_fn=<DivBackward0>)\n",
      "Epoch 1391\n",
      " ---------------------- loss: tensor([5846.6655], grad_fn=<DivBackward0>)\n",
      "Epoch 1392\n",
      " ---------------------- loss: tensor([5846.4355], grad_fn=<DivBackward0>)\n",
      "Epoch 1393\n",
      " ---------------------- loss: tensor([5846.2046], grad_fn=<DivBackward0>)\n",
      "Epoch 1394\n",
      " ---------------------- loss: tensor([5845.9736], grad_fn=<DivBackward0>)\n",
      "Epoch 1395\n",
      " ---------------------- loss: tensor([5845.7407], grad_fn=<DivBackward0>)\n",
      "Epoch 1396\n",
      " ---------------------- loss: tensor([5845.5059], grad_fn=<DivBackward0>)\n",
      "Epoch 1397\n",
      " ---------------------- loss: tensor([5845.2729], grad_fn=<DivBackward0>)\n",
      "Epoch 1398\n",
      " ---------------------- loss: tensor([5845.0366], grad_fn=<DivBackward0>)\n",
      "Epoch 1399\n",
      " ---------------------- loss: tensor([5844.8013], grad_fn=<DivBackward0>)\n",
      "Epoch 1400\n",
      " ---------------------- loss: tensor([5844.5635], grad_fn=<DivBackward0>)\n",
      "Epoch 1401\n",
      " ---------------------- loss: tensor([5844.3262], grad_fn=<DivBackward0>)\n",
      "Epoch 1402\n",
      " ---------------------- loss: tensor([5844.0864], grad_fn=<DivBackward0>)\n",
      "Epoch 1403\n",
      " ---------------------- loss: tensor([5843.8462], grad_fn=<DivBackward0>)\n",
      "Epoch 1404\n",
      " ---------------------- loss: tensor([5843.6079], grad_fn=<DivBackward0>)\n",
      "Epoch 1405\n",
      " ---------------------- loss: tensor([5843.3672], grad_fn=<DivBackward0>)\n",
      "Epoch 1406\n",
      " ---------------------- loss: tensor([5843.1235], grad_fn=<DivBackward0>)\n",
      "Epoch 1407\n",
      " ---------------------- loss: tensor([5842.8813], grad_fn=<DivBackward0>)\n",
      "Epoch 1408\n",
      " ---------------------- loss: tensor([5842.6367], grad_fn=<DivBackward0>)\n",
      "Epoch 1409\n",
      " ---------------------- loss: tensor([5842.3921], grad_fn=<DivBackward0>)\n",
      "Epoch 1410\n",
      " ---------------------- loss: tensor([5842.1450], grad_fn=<DivBackward0>)\n",
      "Epoch 1411\n",
      " ---------------------- loss: tensor([5841.9009], grad_fn=<DivBackward0>)\n",
      "Epoch 1412\n",
      " ---------------------- loss: tensor([5841.6519], grad_fn=<DivBackward0>)\n",
      "Epoch 1413\n",
      " ---------------------- loss: tensor([5841.4048], grad_fn=<DivBackward0>)\n",
      "Epoch 1414\n",
      " ---------------------- loss: tensor([5841.1567], grad_fn=<DivBackward0>)\n",
      "Epoch 1415\n",
      " ---------------------- loss: tensor([5840.9062], grad_fn=<DivBackward0>)\n",
      "Epoch 1416\n",
      " ---------------------- loss: tensor([5840.6553], grad_fn=<DivBackward0>)\n",
      "Epoch 1417\n",
      " ---------------------- loss: tensor([5840.4019], grad_fn=<DivBackward0>)\n",
      "Epoch 1418\n",
      " ---------------------- loss: tensor([5840.1479], grad_fn=<DivBackward0>)\n",
      "Epoch 1419\n",
      " ---------------------- loss: tensor([5839.8965], grad_fn=<DivBackward0>)\n",
      "Epoch 1420\n",
      " ---------------------- loss: tensor([5839.6401], grad_fn=<DivBackward0>)\n",
      "Epoch 1421\n",
      " ---------------------- loss: tensor([5839.3848], grad_fn=<DivBackward0>)\n",
      "Epoch 1422\n",
      " ---------------------- loss: tensor([5839.1279], grad_fn=<DivBackward0>)\n",
      "Epoch 1423\n",
      " ---------------------- loss: tensor([5838.8706], grad_fn=<DivBackward0>)\n",
      "Epoch 1424\n",
      " ---------------------- loss: tensor([5838.6118], grad_fn=<DivBackward0>)\n",
      "Epoch 1425\n",
      " ---------------------- loss: tensor([5838.3511], grad_fn=<DivBackward0>)\n",
      "Epoch 1426\n",
      " ---------------------- loss: tensor([5838.0918], grad_fn=<DivBackward0>)\n",
      "Epoch 1427\n",
      " ---------------------- loss: tensor([5837.8306], grad_fn=<DivBackward0>)\n",
      "Epoch 1428\n",
      " ---------------------- loss: tensor([5837.5684], grad_fn=<DivBackward0>)\n",
      "Epoch 1429\n",
      " ---------------------- loss: tensor([5837.3047], grad_fn=<DivBackward0>)\n",
      "Epoch 1430\n",
      " ---------------------- loss: tensor([5837.0396], grad_fn=<DivBackward0>)\n",
      "Epoch 1431\n",
      " ---------------------- loss: tensor([5836.7729], grad_fn=<DivBackward0>)\n",
      "Epoch 1432\n",
      " ---------------------- loss: tensor([5836.5083], grad_fn=<DivBackward0>)\n",
      "Epoch 1433\n",
      " ---------------------- loss: tensor([5836.2402], grad_fn=<DivBackward0>)\n",
      "Epoch 1434\n",
      " ---------------------- loss: tensor([5835.9717], grad_fn=<DivBackward0>)\n",
      "Epoch 1435\n",
      " ---------------------- loss: tensor([5835.7031], grad_fn=<DivBackward0>)\n",
      "Epoch 1436\n",
      " ---------------------- loss: tensor([5835.4316], grad_fn=<DivBackward0>)\n",
      "Epoch 1437\n",
      " ---------------------- loss: tensor([5835.1597], grad_fn=<DivBackward0>)\n",
      "Epoch 1438\n",
      " ---------------------- loss: tensor([5834.8877], grad_fn=<DivBackward0>)\n",
      "Epoch 1439\n",
      " ---------------------- loss: tensor([5834.6138], grad_fn=<DivBackward0>)\n",
      "Epoch 1440\n",
      " ---------------------- loss: tensor([5834.3398], grad_fn=<DivBackward0>)\n",
      "Epoch 1441\n",
      " ---------------------- loss: tensor([5834.0635], grad_fn=<DivBackward0>)\n",
      "Epoch 1442\n",
      " ---------------------- loss: tensor([5833.7861], grad_fn=<DivBackward0>)\n",
      "Epoch 1443\n",
      " ---------------------- loss: tensor([5833.5088], grad_fn=<DivBackward0>)\n",
      "Epoch 1444\n",
      " ---------------------- loss: tensor([5833.2295], grad_fn=<DivBackward0>)\n",
      "Epoch 1445\n",
      " ---------------------- loss: tensor([5832.9497], grad_fn=<DivBackward0>)\n",
      "Epoch 1446\n",
      " ---------------------- loss: tensor([5832.6680], grad_fn=<DivBackward0>)\n",
      "Epoch 1447\n",
      " ---------------------- loss: tensor([5832.3857], grad_fn=<DivBackward0>)\n",
      "Epoch 1448\n",
      " ---------------------- loss: tensor([5832.1016], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1449\n",
      " ---------------------- loss: tensor([5831.8174], grad_fn=<DivBackward0>)\n",
      "Epoch 1450\n",
      " ---------------------- loss: tensor([5831.5327], grad_fn=<DivBackward0>)\n",
      "Epoch 1451\n",
      " ---------------------- loss: tensor([5831.2451], grad_fn=<DivBackward0>)\n",
      "Epoch 1452\n",
      " ---------------------- loss: tensor([5830.9580], grad_fn=<DivBackward0>)\n",
      "Epoch 1453\n",
      " ---------------------- loss: tensor([5830.6689], grad_fn=<DivBackward0>)\n",
      "Epoch 1454\n",
      " ---------------------- loss: tensor([5830.3774], grad_fn=<DivBackward0>)\n",
      "Epoch 1455\n",
      " ---------------------- loss: tensor([5830.0879], grad_fn=<DivBackward0>)\n",
      "Epoch 1456\n",
      " ---------------------- loss: tensor([5829.7944], grad_fn=<DivBackward0>)\n",
      "Epoch 1457\n",
      " ---------------------- loss: tensor([5829.4995], grad_fn=<DivBackward0>)\n",
      "Epoch 1458\n",
      " ---------------------- loss: tensor([5829.2056], grad_fn=<DivBackward0>)\n",
      "Epoch 1459\n",
      " ---------------------- loss: tensor([5828.9102], grad_fn=<DivBackward0>)\n",
      "Epoch 1460\n",
      " ---------------------- loss: tensor([5828.6113], grad_fn=<DivBackward0>)\n",
      "Epoch 1461\n",
      " ---------------------- loss: tensor([5828.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 1462\n",
      " ---------------------- loss: tensor([5828.0151], grad_fn=<DivBackward0>)\n",
      "Epoch 1463\n",
      " ---------------------- loss: tensor([5827.7139], grad_fn=<DivBackward0>)\n",
      "Epoch 1464\n",
      " ---------------------- loss: tensor([5827.4111], grad_fn=<DivBackward0>)\n",
      "Epoch 1465\n",
      " ---------------------- loss: tensor([5827.1074], grad_fn=<DivBackward0>)\n",
      "Epoch 1466\n",
      " ---------------------- loss: tensor([5826.8042], grad_fn=<DivBackward0>)\n",
      "Epoch 1467\n",
      " ---------------------- loss: tensor([5826.4985], grad_fn=<DivBackward0>)\n",
      "Epoch 1468\n",
      " ---------------------- loss: tensor([5826.1909], grad_fn=<DivBackward0>)\n",
      "Epoch 1469\n",
      " ---------------------- loss: tensor([5825.8823], grad_fn=<DivBackward0>)\n",
      "Epoch 1470\n",
      " ---------------------- loss: tensor([5825.5728], grad_fn=<DivBackward0>)\n",
      "Epoch 1471\n",
      " ---------------------- loss: tensor([5825.2612], grad_fn=<DivBackward0>)\n",
      "Epoch 1472\n",
      " ---------------------- loss: tensor([5824.9502], grad_fn=<DivBackward0>)\n",
      "Epoch 1473\n",
      " ---------------------- loss: tensor([5824.6367], grad_fn=<DivBackward0>)\n",
      "Epoch 1474\n",
      " ---------------------- loss: tensor([5824.3218], grad_fn=<DivBackward0>)\n",
      "Epoch 1475\n",
      " ---------------------- loss: tensor([5824.0049], grad_fn=<DivBackward0>)\n",
      "Epoch 1476\n",
      " ---------------------- loss: tensor([5823.6885], grad_fn=<DivBackward0>)\n",
      "Epoch 1477\n",
      " ---------------------- loss: tensor([5823.3701], grad_fn=<DivBackward0>)\n",
      "Epoch 1478\n",
      " ---------------------- loss: tensor([5823.0488], grad_fn=<DivBackward0>)\n",
      "Epoch 1479\n",
      " ---------------------- loss: tensor([5822.7285], grad_fn=<DivBackward0>)\n",
      "Epoch 1480\n",
      " ---------------------- loss: tensor([5822.4053], grad_fn=<DivBackward0>)\n",
      "Epoch 1481\n",
      " ---------------------- loss: tensor([5822.0811], grad_fn=<DivBackward0>)\n",
      "Epoch 1482\n",
      " ---------------------- loss: tensor([5821.7559], grad_fn=<DivBackward0>)\n",
      "Epoch 1483\n",
      " ---------------------- loss: tensor([5821.4297], grad_fn=<DivBackward0>)\n",
      "Epoch 1484\n",
      " ---------------------- loss: tensor([5821.1021], grad_fn=<DivBackward0>)\n",
      "Epoch 1485\n",
      " ---------------------- loss: tensor([5820.7705], grad_fn=<DivBackward0>)\n",
      "Epoch 1486\n",
      " ---------------------- loss: tensor([5820.4404], grad_fn=<DivBackward0>)\n",
      "Epoch 1487\n",
      " ---------------------- loss: tensor([5820.1084], grad_fn=<DivBackward0>)\n",
      "Epoch 1488\n",
      " ---------------------- loss: tensor([5819.7734], grad_fn=<DivBackward0>)\n",
      "Epoch 1489\n",
      " ---------------------- loss: tensor([5819.4385], grad_fn=<DivBackward0>)\n",
      "Epoch 1490\n",
      " ---------------------- loss: tensor([5819.1021], grad_fn=<DivBackward0>)\n",
      "Epoch 1491\n",
      " ---------------------- loss: tensor([5818.7642], grad_fn=<DivBackward0>)\n",
      "Epoch 1492\n",
      " ---------------------- loss: tensor([5818.4258], grad_fn=<DivBackward0>)\n",
      "Epoch 1493\n",
      " ---------------------- loss: tensor([5818.0850], grad_fn=<DivBackward0>)\n",
      "Epoch 1494\n",
      " ---------------------- loss: tensor([5817.7422], grad_fn=<DivBackward0>)\n",
      "Epoch 1495\n",
      " ---------------------- loss: tensor([5817.3979], grad_fn=<DivBackward0>)\n",
      "Epoch 1496\n",
      " ---------------------- loss: tensor([5817.0532], grad_fn=<DivBackward0>)\n",
      "Epoch 1497\n",
      " ---------------------- loss: tensor([5816.7061], grad_fn=<DivBackward0>)\n",
      "Epoch 1498\n",
      " ---------------------- loss: tensor([5816.3555], grad_fn=<DivBackward0>)\n",
      "Epoch 1499\n",
      " ---------------------- loss: tensor([5816.0068], grad_fn=<DivBackward0>)\n",
      "Epoch 1500\n",
      " ---------------------- loss: tensor([5815.6543], grad_fn=<DivBackward0>)\n",
      "Epoch 1501\n",
      " ---------------------- loss: tensor([5815.3027], grad_fn=<DivBackward0>)\n",
      "Epoch 1502\n",
      " ---------------------- loss: tensor([5814.9487], grad_fn=<DivBackward0>)\n",
      "Epoch 1503\n",
      " ---------------------- loss: tensor([5814.5913], grad_fn=<DivBackward0>)\n",
      "Epoch 1504\n",
      " ---------------------- loss: tensor([5814.2334], grad_fn=<DivBackward0>)\n",
      "Epoch 1505\n",
      " ---------------------- loss: tensor([5813.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 1506\n",
      " ---------------------- loss: tensor([5813.5132], grad_fn=<DivBackward0>)\n",
      "Epoch 1507\n",
      " ---------------------- loss: tensor([5813.1499], grad_fn=<DivBackward0>)\n",
      "Epoch 1508\n",
      " ---------------------- loss: tensor([5812.7866], grad_fn=<DivBackward0>)\n",
      "Epoch 1509\n",
      " ---------------------- loss: tensor([5812.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 1510\n",
      " ---------------------- loss: tensor([5812.0542], grad_fn=<DivBackward0>)\n",
      "Epoch 1511\n",
      " ---------------------- loss: tensor([5811.6846], grad_fn=<DivBackward0>)\n",
      "Epoch 1512\n",
      " ---------------------- loss: tensor([5811.3140], grad_fn=<DivBackward0>)\n",
      "Epoch 1513\n",
      " ---------------------- loss: tensor([5810.9409], grad_fn=<DivBackward0>)\n",
      "Epoch 1514\n",
      " ---------------------- loss: tensor([5810.5669], grad_fn=<DivBackward0>)\n",
      "Epoch 1515\n",
      " ---------------------- loss: tensor([5810.1899], grad_fn=<DivBackward0>)\n",
      "Epoch 1516\n",
      " ---------------------- loss: tensor([5809.8135], grad_fn=<DivBackward0>)\n",
      "Epoch 1517\n",
      " ---------------------- loss: tensor([5809.4346], grad_fn=<DivBackward0>)\n",
      "Epoch 1518\n",
      " ---------------------- loss: tensor([5809.0532], grad_fn=<DivBackward0>)\n",
      "Epoch 1519\n",
      " ---------------------- loss: tensor([5808.6709], grad_fn=<DivBackward0>)\n",
      "Epoch 1520\n",
      " ---------------------- loss: tensor([5808.2856], grad_fn=<DivBackward0>)\n",
      "Epoch 1521\n",
      " ---------------------- loss: tensor([5807.9004], grad_fn=<DivBackward0>)\n",
      "Epoch 1522\n",
      " ---------------------- loss: tensor([5807.5127], grad_fn=<DivBackward0>)\n",
      "Epoch 1523\n",
      " ---------------------- loss: tensor([5807.1235], grad_fn=<DivBackward0>)\n",
      "Epoch 1524\n",
      " ---------------------- loss: tensor([5806.7314], grad_fn=<DivBackward0>)\n",
      "Epoch 1525\n",
      " ---------------------- loss: tensor([5806.3379], grad_fn=<DivBackward0>)\n",
      "Epoch 1526\n",
      " ---------------------- loss: tensor([5805.9424], grad_fn=<DivBackward0>)\n",
      "Epoch 1527\n",
      " ---------------------- loss: tensor([5805.5449], grad_fn=<DivBackward0>)\n",
      "Epoch 1528\n",
      " ---------------------- loss: tensor([5805.1465], grad_fn=<DivBackward0>)\n",
      "Epoch 1529\n",
      " ---------------------- loss: tensor([5804.7461], grad_fn=<DivBackward0>)\n",
      "Epoch 1530\n",
      " ---------------------- loss: tensor([5804.3428], grad_fn=<DivBackward0>)\n",
      "Epoch 1531\n",
      " ---------------------- loss: tensor([5803.9385], grad_fn=<DivBackward0>)\n",
      "Epoch 1532\n",
      " ---------------------- loss: tensor([5803.5322], grad_fn=<DivBackward0>)\n",
      "Epoch 1533\n",
      " ---------------------- loss: tensor([5803.1235], grad_fn=<DivBackward0>)\n",
      "Epoch 1534\n",
      " ---------------------- loss: tensor([5802.7134], grad_fn=<DivBackward0>)\n",
      "Epoch 1535\n",
      " ---------------------- loss: tensor([5802.3008], grad_fn=<DivBackward0>)\n",
      "Epoch 1536\n",
      " ---------------------- loss: tensor([5801.8892], grad_fn=<DivBackward0>)\n",
      "Epoch 1537\n",
      " ---------------------- loss: tensor([5801.4712], grad_fn=<DivBackward0>)\n",
      "Epoch 1538\n",
      " ---------------------- loss: tensor([5801.0542], grad_fn=<DivBackward0>)\n",
      "Epoch 1539\n",
      " ---------------------- loss: tensor([5800.6323], grad_fn=<DivBackward0>)\n",
      "Epoch 1540\n",
      " ---------------------- loss: tensor([5800.2100], grad_fn=<DivBackward0>)\n",
      "Epoch 1541\n",
      " ---------------------- loss: tensor([5799.7876], grad_fn=<DivBackward0>)\n",
      "Epoch 1542\n",
      " ---------------------- loss: tensor([5799.3618], grad_fn=<DivBackward0>)\n",
      "Epoch 1543\n",
      " ---------------------- loss: tensor([5798.9316], grad_fn=<DivBackward0>)\n",
      "Epoch 1544\n",
      " ---------------------- loss: tensor([5798.5020], grad_fn=<DivBackward0>)\n",
      "Epoch 1545\n",
      " ---------------------- loss: tensor([5798.0698], grad_fn=<DivBackward0>)\n",
      "Epoch 1546\n",
      " ---------------------- loss: tensor([5797.6362], grad_fn=<DivBackward0>)\n",
      "Epoch 1547\n",
      " ---------------------- loss: tensor([5797.1992], grad_fn=<DivBackward0>)\n",
      "Epoch 1548\n",
      " ---------------------- loss: tensor([5796.7593], grad_fn=<DivBackward0>)\n",
      "Epoch 1549\n",
      " ---------------------- loss: tensor([5796.3184], grad_fn=<DivBackward0>)\n",
      "Epoch 1550\n",
      " ---------------------- loss: tensor([5795.8760], grad_fn=<DivBackward0>)\n",
      "Epoch 1551\n",
      " ---------------------- loss: tensor([5795.4307], grad_fn=<DivBackward0>)\n",
      "Epoch 1552\n",
      " ---------------------- loss: tensor([5794.9829], grad_fn=<DivBackward0>)\n",
      "Epoch 1553\n",
      " ---------------------- loss: tensor([5794.5347], grad_fn=<DivBackward0>)\n",
      "Epoch 1554\n",
      " ---------------------- loss: tensor([5794.0820], grad_fn=<DivBackward0>)\n",
      "Epoch 1555\n",
      " ---------------------- loss: tensor([5793.6279], grad_fn=<DivBackward0>)\n",
      "Epoch 1556\n",
      " ---------------------- loss: tensor([5793.1724], grad_fn=<DivBackward0>)\n",
      "Epoch 1557\n",
      " ---------------------- loss: tensor([5792.7124], grad_fn=<DivBackward0>)\n",
      "Epoch 1558\n",
      " ---------------------- loss: tensor([5792.2529], grad_fn=<DivBackward0>)\n",
      "Epoch 1559\n",
      " ---------------------- loss: tensor([5791.7915], grad_fn=<DivBackward0>)\n",
      "Epoch 1560\n",
      " ---------------------- loss: tensor([5791.3232], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1561\n",
      " ---------------------- loss: tensor([5790.8560], grad_fn=<DivBackward0>)\n",
      "Epoch 1562\n",
      " ---------------------- loss: tensor([5790.3862], grad_fn=<DivBackward0>)\n",
      "Epoch 1563\n",
      " ---------------------- loss: tensor([5789.9141], grad_fn=<DivBackward0>)\n",
      "Epoch 1564\n",
      " ---------------------- loss: tensor([5789.4390], grad_fn=<DivBackward0>)\n",
      "Epoch 1565\n",
      " ---------------------- loss: tensor([5788.9604], grad_fn=<DivBackward0>)\n",
      "Epoch 1566\n",
      " ---------------------- loss: tensor([5788.4810], grad_fn=<DivBackward0>)\n",
      "Epoch 1567\n",
      " ---------------------- loss: tensor([5787.9990], grad_fn=<DivBackward0>)\n",
      "Epoch 1568\n",
      " ---------------------- loss: tensor([5787.5146], grad_fn=<DivBackward0>)\n",
      "Epoch 1569\n",
      " ---------------------- loss: tensor([5787.0278], grad_fn=<DivBackward0>)\n",
      "Epoch 1570\n",
      " ---------------------- loss: tensor([5786.5386], grad_fn=<DivBackward0>)\n",
      "Epoch 1571\n",
      " ---------------------- loss: tensor([5786.0454], grad_fn=<DivBackward0>)\n",
      "Epoch 1572\n",
      " ---------------------- loss: tensor([5785.5493], grad_fn=<DivBackward0>)\n",
      "Epoch 1573\n",
      " ---------------------- loss: tensor([5785.0522], grad_fn=<DivBackward0>)\n",
      "Epoch 1574\n",
      " ---------------------- loss: tensor([5784.5527], grad_fn=<DivBackward0>)\n",
      "Epoch 1575\n",
      " ---------------------- loss: tensor([5784.0508], grad_fn=<DivBackward0>)\n",
      "Epoch 1576\n",
      " ---------------------- loss: tensor([5783.5459], grad_fn=<DivBackward0>)\n",
      "Epoch 1577\n",
      " ---------------------- loss: tensor([5783.0381], grad_fn=<DivBackward0>)\n",
      "Epoch 1578\n",
      " ---------------------- loss: tensor([5782.5278], grad_fn=<DivBackward0>)\n",
      "Epoch 1579\n",
      " ---------------------- loss: tensor([5782.0146], grad_fn=<DivBackward0>)\n",
      "Epoch 1580\n",
      " ---------------------- loss: tensor([5781.4980], grad_fn=<DivBackward0>)\n",
      "Epoch 1581\n",
      " ---------------------- loss: tensor([5780.9810], grad_fn=<DivBackward0>)\n",
      "Epoch 1582\n",
      " ---------------------- loss: tensor([5780.4585], grad_fn=<DivBackward0>)\n",
      "Epoch 1583\n",
      " ---------------------- loss: tensor([5779.9346], grad_fn=<DivBackward0>)\n",
      "Epoch 1584\n",
      " ---------------------- loss: tensor([5779.4082], grad_fn=<DivBackward0>)\n",
      "Epoch 1585\n",
      " ---------------------- loss: tensor([5778.8789], grad_fn=<DivBackward0>)\n",
      "Epoch 1586\n",
      " ---------------------- loss: tensor([5778.3462], grad_fn=<DivBackward0>)\n",
      "Epoch 1587\n",
      " ---------------------- loss: tensor([5777.8105], grad_fn=<DivBackward0>)\n",
      "Epoch 1588\n",
      " ---------------------- loss: tensor([5777.2729], grad_fn=<DivBackward0>)\n",
      "Epoch 1589\n",
      " ---------------------- loss: tensor([5776.7314], grad_fn=<DivBackward0>)\n",
      "Epoch 1590\n",
      " ---------------------- loss: tensor([5776.1875], grad_fn=<DivBackward0>)\n",
      "Epoch 1591\n",
      " ---------------------- loss: tensor([5775.6411], grad_fn=<DivBackward0>)\n",
      "Epoch 1592\n",
      " ---------------------- loss: tensor([5775.0898], grad_fn=<DivBackward0>)\n",
      "Epoch 1593\n",
      " ---------------------- loss: tensor([5774.5386], grad_fn=<DivBackward0>)\n",
      "Epoch 1594\n",
      " ---------------------- loss: tensor([5773.9819], grad_fn=<DivBackward0>)\n",
      "Epoch 1595\n",
      " ---------------------- loss: tensor([5773.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 1596\n",
      " ---------------------- loss: tensor([5772.8608], grad_fn=<DivBackward0>)\n",
      "Epoch 1597\n",
      " ---------------------- loss: tensor([5772.2959], grad_fn=<DivBackward0>)\n",
      "Epoch 1598\n",
      " ---------------------- loss: tensor([5771.7290], grad_fn=<DivBackward0>)\n",
      "Epoch 1599\n",
      " ---------------------- loss: tensor([5771.1577], grad_fn=<DivBackward0>)\n",
      "Epoch 1600\n",
      " ---------------------- loss: tensor([5770.5820], grad_fn=<DivBackward0>)\n",
      "Epoch 1601\n",
      " ---------------------- loss: tensor([5770.0059], grad_fn=<DivBackward0>)\n",
      "Epoch 1602\n",
      " ---------------------- loss: tensor([5769.4248], grad_fn=<DivBackward0>)\n",
      "Epoch 1603\n",
      " ---------------------- loss: tensor([5768.8403], grad_fn=<DivBackward0>)\n",
      "Epoch 1604\n",
      " ---------------------- loss: tensor([5768.2529], grad_fn=<DivBackward0>)\n",
      "Epoch 1605\n",
      " ---------------------- loss: tensor([5767.6621], grad_fn=<DivBackward0>)\n",
      "Epoch 1606\n",
      " ---------------------- loss: tensor([5767.0679], grad_fn=<DivBackward0>)\n",
      "Epoch 1607\n",
      " ---------------------- loss: tensor([5766.4702], grad_fn=<DivBackward0>)\n",
      "Epoch 1608\n",
      " ---------------------- loss: tensor([5765.8701], grad_fn=<DivBackward0>)\n",
      "Epoch 1609\n",
      " ---------------------- loss: tensor([5765.2666], grad_fn=<DivBackward0>)\n",
      "Epoch 1610\n",
      " ---------------------- loss: tensor([5764.6577], grad_fn=<DivBackward0>)\n",
      "Epoch 1611\n",
      " ---------------------- loss: tensor([5764.0474], grad_fn=<DivBackward0>)\n",
      "Epoch 1612\n",
      " ---------------------- loss: tensor([5763.4331], grad_fn=<DivBackward0>)\n",
      "Epoch 1613\n",
      " ---------------------- loss: tensor([5762.8154], grad_fn=<DivBackward0>)\n",
      "Epoch 1614\n",
      " ---------------------- loss: tensor([5762.1938], grad_fn=<DivBackward0>)\n",
      "Epoch 1615\n",
      " ---------------------- loss: tensor([5761.5688], grad_fn=<DivBackward0>)\n",
      "Epoch 1616\n",
      " ---------------------- loss: tensor([5760.9404], grad_fn=<DivBackward0>)\n",
      "Epoch 1617\n",
      " ---------------------- loss: tensor([5760.3071], grad_fn=<DivBackward0>)\n",
      "Epoch 1618\n",
      " ---------------------- loss: tensor([5759.6724], grad_fn=<DivBackward0>)\n",
      "Epoch 1619\n",
      " ---------------------- loss: tensor([5759.0322], grad_fn=<DivBackward0>)\n",
      "Epoch 1620\n",
      " ---------------------- loss: tensor([5758.3892], grad_fn=<DivBackward0>)\n",
      "Epoch 1621\n",
      " ---------------------- loss: tensor([5757.7422], grad_fn=<DivBackward0>)\n",
      "Epoch 1622\n",
      " ---------------------- loss: tensor([5757.0918], grad_fn=<DivBackward0>)\n",
      "Epoch 1623\n",
      " ---------------------- loss: tensor([5756.4375], grad_fn=<DivBackward0>)\n",
      "Epoch 1624\n",
      " ---------------------- loss: tensor([5755.7778], grad_fn=<DivBackward0>)\n",
      "Epoch 1625\n",
      " ---------------------- loss: tensor([5755.1147], grad_fn=<DivBackward0>)\n",
      "Epoch 1626\n",
      " ---------------------- loss: tensor([5754.4497], grad_fn=<DivBackward0>)\n",
      "Epoch 1627\n",
      " ---------------------- loss: tensor([5753.7788], grad_fn=<DivBackward0>)\n",
      "Epoch 1628\n",
      " ---------------------- loss: tensor([5753.1040], grad_fn=<DivBackward0>)\n",
      "Epoch 1629\n",
      " ---------------------- loss: tensor([5752.4268], grad_fn=<DivBackward0>)\n",
      "Epoch 1630\n",
      " ---------------------- loss: tensor([5751.7437], grad_fn=<DivBackward0>)\n",
      "Epoch 1631\n",
      " ---------------------- loss: tensor([5751.0581], grad_fn=<DivBackward0>)\n",
      "Epoch 1632\n",
      " ---------------------- loss: tensor([5750.3672], grad_fn=<DivBackward0>)\n",
      "Epoch 1633\n",
      " ---------------------- loss: tensor([5749.6719], grad_fn=<DivBackward0>)\n",
      "Epoch 1634\n",
      " ---------------------- loss: tensor([5748.9731], grad_fn=<DivBackward0>)\n",
      "Epoch 1635\n",
      " ---------------------- loss: tensor([5748.2700], grad_fn=<DivBackward0>)\n",
      "Epoch 1636\n",
      " ---------------------- loss: tensor([5747.5620], grad_fn=<DivBackward0>)\n",
      "Epoch 1637\n",
      " ---------------------- loss: tensor([5746.8511], grad_fn=<DivBackward0>)\n",
      "Epoch 1638\n",
      " ---------------------- loss: tensor([5746.1328], grad_fn=<DivBackward0>)\n",
      "Epoch 1639\n",
      " ---------------------- loss: tensor([5745.4141], grad_fn=<DivBackward0>)\n",
      "Epoch 1640\n",
      " ---------------------- loss: tensor([5744.6890], grad_fn=<DivBackward0>)\n",
      "Epoch 1641\n",
      " ---------------------- loss: tensor([5743.9575], grad_fn=<DivBackward0>)\n",
      "Epoch 1642\n",
      " ---------------------- loss: tensor([5743.2246], grad_fn=<DivBackward0>)\n",
      "Epoch 1643\n",
      " ---------------------- loss: tensor([5742.4858], grad_fn=<DivBackward0>)\n",
      "Epoch 1644\n",
      " ---------------------- loss: tensor([5741.7437], grad_fn=<DivBackward0>)\n",
      "Epoch 1645\n",
      " ---------------------- loss: tensor([5740.9951], grad_fn=<DivBackward0>)\n",
      "Epoch 1646\n",
      " ---------------------- loss: tensor([5740.2437], grad_fn=<DivBackward0>)\n",
      "Epoch 1647\n",
      " ---------------------- loss: tensor([5739.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 1648\n",
      " ---------------------- loss: tensor([5738.7227], grad_fn=<DivBackward0>)\n",
      "Epoch 1649\n",
      " ---------------------- loss: tensor([5737.9561], grad_fn=<DivBackward0>)\n",
      "Epoch 1650\n",
      " ---------------------- loss: tensor([5737.1851], grad_fn=<DivBackward0>)\n",
      "Epoch 1651\n",
      " ---------------------- loss: tensor([5736.4067], grad_fn=<DivBackward0>)\n",
      "Epoch 1652\n",
      " ---------------------- loss: tensor([5735.6274], grad_fn=<DivBackward0>)\n",
      "Epoch 1653\n",
      " ---------------------- loss: tensor([5734.8403], grad_fn=<DivBackward0>)\n",
      "Epoch 1654\n",
      " ---------------------- loss: tensor([5734.0479], grad_fn=<DivBackward0>)\n",
      "Epoch 1655\n",
      " ---------------------- loss: tensor([5733.2524], grad_fn=<DivBackward0>)\n",
      "Epoch 1656\n",
      " ---------------------- loss: tensor([5732.4487], grad_fn=<DivBackward0>)\n",
      "Epoch 1657\n",
      " ---------------------- loss: tensor([5731.6436], grad_fn=<DivBackward0>)\n",
      "Epoch 1658\n",
      " ---------------------- loss: tensor([5730.8301], grad_fn=<DivBackward0>)\n",
      "Epoch 1659\n",
      " ---------------------- loss: tensor([5730.0127], grad_fn=<DivBackward0>)\n",
      "Epoch 1660\n",
      " ---------------------- loss: tensor([5729.1904], grad_fn=<DivBackward0>)\n",
      "Epoch 1661\n",
      " ---------------------- loss: tensor([5728.3618], grad_fn=<DivBackward0>)\n",
      "Epoch 1662\n",
      " ---------------------- loss: tensor([5727.5273], grad_fn=<DivBackward0>)\n",
      "Epoch 1663\n",
      " ---------------------- loss: tensor([5726.6890], grad_fn=<DivBackward0>)\n",
      "Epoch 1664\n",
      " ---------------------- loss: tensor([5725.8442], grad_fn=<DivBackward0>)\n",
      "Epoch 1665\n",
      " ---------------------- loss: tensor([5724.9932], grad_fn=<DivBackward0>)\n",
      "Epoch 1666\n",
      " ---------------------- loss: tensor([5724.1382], grad_fn=<DivBackward0>)\n",
      "Epoch 1667\n",
      " ---------------------- loss: tensor([5723.2749], grad_fn=<DivBackward0>)\n",
      "Epoch 1668\n",
      " ---------------------- loss: tensor([5722.4092], grad_fn=<DivBackward0>)\n",
      "Epoch 1669\n",
      " ---------------------- loss: tensor([5721.5337], grad_fn=<DivBackward0>)\n",
      "Epoch 1670\n",
      " ---------------------- loss: tensor([5720.6543], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1671\n",
      " ---------------------- loss: tensor([5719.7690], grad_fn=<DivBackward0>)\n",
      "Epoch 1672\n",
      " ---------------------- loss: tensor([5718.8794], grad_fn=<DivBackward0>)\n",
      "Epoch 1673\n",
      " ---------------------- loss: tensor([5717.9814], grad_fn=<DivBackward0>)\n",
      "Epoch 1674\n",
      " ---------------------- loss: tensor([5717.0771], grad_fn=<DivBackward0>)\n",
      "Epoch 1675\n",
      " ---------------------- loss: tensor([5716.1665], grad_fn=<DivBackward0>)\n",
      "Epoch 1676\n",
      " ---------------------- loss: tensor([5715.2515], grad_fn=<DivBackward0>)\n",
      "Epoch 1677\n",
      " ---------------------- loss: tensor([5714.3291], grad_fn=<DivBackward0>)\n",
      "Epoch 1678\n",
      " ---------------------- loss: tensor([5713.4014], grad_fn=<DivBackward0>)\n",
      "Epoch 1679\n",
      " ---------------------- loss: tensor([5712.4648], grad_fn=<DivBackward0>)\n",
      "Epoch 1680\n",
      " ---------------------- loss: tensor([5711.5249], grad_fn=<DivBackward0>)\n",
      "Epoch 1681\n",
      " ---------------------- loss: tensor([5710.5752], grad_fn=<DivBackward0>)\n",
      "Epoch 1682\n",
      " ---------------------- loss: tensor([5709.6211], grad_fn=<DivBackward0>)\n",
      "Epoch 1683\n",
      " ---------------------- loss: tensor([5708.6587], grad_fn=<DivBackward0>)\n",
      "Epoch 1684\n",
      " ---------------------- loss: tensor([5707.6914], grad_fn=<DivBackward0>)\n",
      "Epoch 1685\n",
      " ---------------------- loss: tensor([5706.7153], grad_fn=<DivBackward0>)\n",
      "Epoch 1686\n",
      " ---------------------- loss: tensor([5705.7329], grad_fn=<DivBackward0>)\n",
      "Epoch 1687\n",
      " ---------------------- loss: tensor([5704.7437], grad_fn=<DivBackward0>)\n",
      "Epoch 1688\n",
      " ---------------------- loss: tensor([5703.7461], grad_fn=<DivBackward0>)\n",
      "Epoch 1689\n",
      " ---------------------- loss: tensor([5702.7437], grad_fn=<DivBackward0>)\n",
      "Epoch 1690\n",
      " ---------------------- loss: tensor([5701.7319], grad_fn=<DivBackward0>)\n",
      "Epoch 1691\n",
      " ---------------------- loss: tensor([5700.7139], grad_fn=<DivBackward0>)\n",
      "Epoch 1692\n",
      " ---------------------- loss: tensor([5699.6890], grad_fn=<DivBackward0>)\n",
      "Epoch 1693\n",
      " ---------------------- loss: tensor([5698.6548], grad_fn=<DivBackward0>)\n",
      "Epoch 1694\n",
      " ---------------------- loss: tensor([5697.6133], grad_fn=<DivBackward0>)\n",
      "Epoch 1695\n",
      " ---------------------- loss: tensor([5696.5664], grad_fn=<DivBackward0>)\n",
      "Epoch 1696\n",
      " ---------------------- loss: tensor([5695.5107], grad_fn=<DivBackward0>)\n",
      "Epoch 1697\n",
      " ---------------------- loss: tensor([5694.4463], grad_fn=<DivBackward0>)\n",
      "Epoch 1698\n",
      " ---------------------- loss: tensor([5693.3735], grad_fn=<DivBackward0>)\n",
      "Epoch 1699\n",
      " ---------------------- loss: tensor([5692.2944], grad_fn=<DivBackward0>)\n",
      "Epoch 1700\n",
      " ---------------------- loss: tensor([5691.2056], grad_fn=<DivBackward0>)\n",
      "Epoch 1701\n",
      " ---------------------- loss: tensor([5690.1089], grad_fn=<DivBackward0>)\n",
      "Epoch 1702\n",
      " ---------------------- loss: tensor([5689.0049], grad_fn=<DivBackward0>)\n",
      "Epoch 1703\n",
      " ---------------------- loss: tensor([5687.8916], grad_fn=<DivBackward0>)\n",
      "Epoch 1704\n",
      " ---------------------- loss: tensor([5686.7695], grad_fn=<DivBackward0>)\n",
      "Epoch 1705\n",
      " ---------------------- loss: tensor([5685.6406], grad_fn=<DivBackward0>)\n",
      "Epoch 1706\n",
      " ---------------------- loss: tensor([5684.5015], grad_fn=<DivBackward0>)\n",
      "Epoch 1707\n",
      " ---------------------- loss: tensor([5683.3535], grad_fn=<DivBackward0>)\n",
      "Epoch 1708\n",
      " ---------------------- loss: tensor([5682.1958], grad_fn=<DivBackward0>)\n",
      "Epoch 1709\n",
      " ---------------------- loss: tensor([5681.0312], grad_fn=<DivBackward0>)\n",
      "Epoch 1710\n",
      " ---------------------- loss: tensor([5679.8569], grad_fn=<DivBackward0>)\n",
      "Epoch 1711\n",
      " ---------------------- loss: tensor([5678.6724], grad_fn=<DivBackward0>)\n",
      "Epoch 1712\n",
      " ---------------------- loss: tensor([5677.4800], grad_fn=<DivBackward0>)\n",
      "Epoch 1713\n",
      " ---------------------- loss: tensor([5676.2764], grad_fn=<DivBackward0>)\n",
      "Epoch 1714\n",
      " ---------------------- loss: tensor([5675.0645], grad_fn=<DivBackward0>)\n",
      "Epoch 1715\n",
      " ---------------------- loss: tensor([5673.8428], grad_fn=<DivBackward0>)\n",
      "Epoch 1716\n",
      " ---------------------- loss: tensor([5672.6108], grad_fn=<DivBackward0>)\n",
      "Epoch 1717\n",
      " ---------------------- loss: tensor([5671.3687], grad_fn=<DivBackward0>)\n",
      "Epoch 1718\n",
      " ---------------------- loss: tensor([5670.1162], grad_fn=<DivBackward0>)\n",
      "Epoch 1719\n",
      " ---------------------- loss: tensor([5668.8550], grad_fn=<DivBackward0>)\n",
      "Epoch 1720\n",
      " ---------------------- loss: tensor([5667.5815], grad_fn=<DivBackward0>)\n",
      "Epoch 1721\n",
      " ---------------------- loss: tensor([5666.2983], grad_fn=<DivBackward0>)\n",
      "Epoch 1722\n",
      " ---------------------- loss: tensor([5665.0049], grad_fn=<DivBackward0>)\n",
      "Epoch 1723\n",
      " ---------------------- loss: tensor([5663.7007], grad_fn=<DivBackward0>)\n",
      "Epoch 1724\n",
      " ---------------------- loss: tensor([5662.3862], grad_fn=<DivBackward0>)\n",
      "Epoch 1725\n",
      " ---------------------- loss: tensor([5661.0586], grad_fn=<DivBackward0>)\n",
      "Epoch 1726\n",
      " ---------------------- loss: tensor([5659.7231], grad_fn=<DivBackward0>)\n",
      "Epoch 1727\n",
      " ---------------------- loss: tensor([5658.3726], grad_fn=<DivBackward0>)\n",
      "Epoch 1728\n",
      " ---------------------- loss: tensor([5657.0137], grad_fn=<DivBackward0>)\n",
      "Epoch 1729\n",
      " ---------------------- loss: tensor([5655.6411], grad_fn=<DivBackward0>)\n",
      "Epoch 1730\n",
      " ---------------------- loss: tensor([5654.2578], grad_fn=<DivBackward0>)\n",
      "Epoch 1731\n",
      " ---------------------- loss: tensor([5652.8628], grad_fn=<DivBackward0>)\n",
      "Epoch 1732\n",
      " ---------------------- loss: tensor([5651.4541], grad_fn=<DivBackward0>)\n",
      "Epoch 1733\n",
      " ---------------------- loss: tensor([5650.0352], grad_fn=<DivBackward0>)\n",
      "Epoch 1734\n",
      " ---------------------- loss: tensor([5648.6030], grad_fn=<DivBackward0>)\n",
      "Epoch 1735\n",
      " ---------------------- loss: tensor([5647.1562], grad_fn=<DivBackward0>)\n",
      "Epoch 1736\n",
      " ---------------------- loss: tensor([5645.6992], grad_fn=<DivBackward0>)\n",
      "Epoch 1737\n",
      " ---------------------- loss: tensor([5644.2280], grad_fn=<DivBackward0>)\n",
      "Epoch 1738\n",
      " ---------------------- loss: tensor([5642.7437], grad_fn=<DivBackward0>)\n",
      "Epoch 1739\n",
      " ---------------------- loss: tensor([5641.2485], grad_fn=<DivBackward0>)\n",
      "Epoch 1740\n",
      " ---------------------- loss: tensor([5639.7363], grad_fn=<DivBackward0>)\n",
      "Epoch 1741\n",
      " ---------------------- loss: tensor([5638.2109], grad_fn=<DivBackward0>)\n",
      "Epoch 1742\n",
      " ---------------------- loss: tensor([5636.6719], grad_fn=<DivBackward0>)\n",
      "Epoch 1743\n",
      " ---------------------- loss: tensor([5635.1191], grad_fn=<DivBackward0>)\n",
      "Epoch 1744\n",
      " ---------------------- loss: tensor([5633.5518], grad_fn=<DivBackward0>)\n",
      "Epoch 1745\n",
      " ---------------------- loss: tensor([5631.9692], grad_fn=<DivBackward0>)\n",
      "Epoch 1746\n",
      " ---------------------- loss: tensor([5630.3735], grad_fn=<DivBackward0>)\n",
      "Epoch 1747\n",
      " ---------------------- loss: tensor([5628.7617], grad_fn=<DivBackward0>)\n",
      "Epoch 1748\n",
      " ---------------------- loss: tensor([5627.1338], grad_fn=<DivBackward0>)\n",
      "Epoch 1749\n",
      " ---------------------- loss: tensor([5625.4907], grad_fn=<DivBackward0>)\n",
      "Epoch 1750\n",
      " ---------------------- loss: tensor([5623.8320], grad_fn=<DivBackward0>)\n",
      "Epoch 1751\n",
      " ---------------------- loss: tensor([5622.1558], grad_fn=<DivBackward0>)\n",
      "Epoch 1752\n",
      " ---------------------- loss: tensor([5620.4653], grad_fn=<DivBackward0>)\n",
      "Epoch 1753\n",
      " ---------------------- loss: tensor([5618.7583], grad_fn=<DivBackward0>)\n",
      "Epoch 1754\n",
      " ---------------------- loss: tensor([5617.0337], grad_fn=<DivBackward0>)\n",
      "Epoch 1755\n",
      " ---------------------- loss: tensor([5615.2920], grad_fn=<DivBackward0>)\n",
      "Epoch 1756\n",
      " ---------------------- loss: tensor([5613.5332], grad_fn=<DivBackward0>)\n",
      "Epoch 1757\n",
      " ---------------------- loss: tensor([5611.7554], grad_fn=<DivBackward0>)\n",
      "Epoch 1758\n",
      " ---------------------- loss: tensor([5609.9609], grad_fn=<DivBackward0>)\n",
      "Epoch 1759\n",
      " ---------------------- loss: tensor([5608.1475], grad_fn=<DivBackward0>)\n",
      "Epoch 1760\n",
      " ---------------------- loss: tensor([5606.3169], grad_fn=<DivBackward0>)\n",
      "Epoch 1761\n",
      " ---------------------- loss: tensor([5604.4648], grad_fn=<DivBackward0>)\n",
      "Epoch 1762\n",
      " ---------------------- loss: tensor([5602.5952], grad_fn=<DivBackward0>)\n",
      "Epoch 1763\n",
      " ---------------------- loss: tensor([5600.7065], grad_fn=<DivBackward0>)\n",
      "Epoch 1764\n",
      " ---------------------- loss: tensor([5598.7969], grad_fn=<DivBackward0>)\n",
      "Epoch 1765\n",
      " ---------------------- loss: tensor([5596.8657], grad_fn=<DivBackward0>)\n",
      "Epoch 1766\n",
      " ---------------------- loss: tensor([5594.9150], grad_fn=<DivBackward0>)\n",
      "Epoch 1767\n",
      " ---------------------- loss: tensor([5592.9434], grad_fn=<DivBackward0>)\n",
      "Epoch 1768\n",
      " ---------------------- loss: tensor([5590.9497], grad_fn=<DivBackward0>)\n",
      "Epoch 1769\n",
      " ---------------------- loss: tensor([5588.9351], grad_fn=<DivBackward0>)\n",
      "Epoch 1770\n",
      " ---------------------- loss: tensor([5586.8970], grad_fn=<DivBackward0>)\n",
      "Epoch 1771\n",
      " ---------------------- loss: tensor([5584.8354], grad_fn=<DivBackward0>)\n",
      "Epoch 1772\n",
      " ---------------------- loss: tensor([5582.7529], grad_fn=<DivBackward0>)\n",
      "Epoch 1773\n",
      " ---------------------- loss: tensor([5580.6460], grad_fn=<DivBackward0>)\n",
      "Epoch 1774\n",
      " ---------------------- loss: tensor([5578.5132], grad_fn=<DivBackward0>)\n",
      "Epoch 1775\n",
      " ---------------------- loss: tensor([5576.3574], grad_fn=<DivBackward0>)\n",
      "Epoch 1776\n",
      " ---------------------- loss: tensor([5574.1768], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1777\n",
      " ---------------------- loss: tensor([5571.9702], grad_fn=<DivBackward0>)\n",
      "Epoch 1778\n",
      " ---------------------- loss: tensor([5569.7373], grad_fn=<DivBackward0>)\n",
      "Epoch 1779\n",
      " ---------------------- loss: tensor([5567.4771], grad_fn=<DivBackward0>)\n",
      "Epoch 1780\n",
      " ---------------------- loss: tensor([5565.1899], grad_fn=<DivBackward0>)\n",
      "Epoch 1781\n",
      " ---------------------- loss: tensor([5562.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 1782\n",
      " ---------------------- loss: tensor([5560.5308], grad_fn=<DivBackward0>)\n",
      "Epoch 1783\n",
      " ---------------------- loss: tensor([5558.1587], grad_fn=<DivBackward0>)\n",
      "Epoch 1784\n",
      " ---------------------- loss: tensor([5555.7563], grad_fn=<DivBackward0>)\n",
      "Epoch 1785\n",
      " ---------------------- loss: tensor([5553.3232], grad_fn=<DivBackward0>)\n",
      "Epoch 1786\n",
      " ---------------------- loss: tensor([5550.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 1787\n",
      " ---------------------- loss: tensor([5548.3647], grad_fn=<DivBackward0>)\n",
      "Epoch 1788\n",
      " ---------------------- loss: tensor([5545.8359], grad_fn=<DivBackward0>)\n",
      "Epoch 1789\n",
      " ---------------------- loss: tensor([5543.2739], grad_fn=<DivBackward0>)\n",
      "Epoch 1790\n",
      " ---------------------- loss: tensor([5540.6792], grad_fn=<DivBackward0>)\n",
      "Epoch 1791\n",
      " ---------------------- loss: tensor([5538.0479], grad_fn=<DivBackward0>)\n",
      "Epoch 1792\n",
      " ---------------------- loss: tensor([5535.3813], grad_fn=<DivBackward0>)\n",
      "Epoch 1793\n",
      " ---------------------- loss: tensor([5532.6782], grad_fn=<DivBackward0>)\n",
      "Epoch 1794\n",
      " ---------------------- loss: tensor([5529.9375], grad_fn=<DivBackward0>)\n",
      "Epoch 1795\n",
      " ---------------------- loss: tensor([5527.1577], grad_fn=<DivBackward0>)\n",
      "Epoch 1796\n",
      " ---------------------- loss: tensor([5524.3384], grad_fn=<DivBackward0>)\n",
      "Epoch 1797\n",
      " ---------------------- loss: tensor([5521.4795], grad_fn=<DivBackward0>)\n",
      "Epoch 1798\n",
      " ---------------------- loss: tensor([5518.5781], grad_fn=<DivBackward0>)\n",
      "Epoch 1799\n",
      " ---------------------- loss: tensor([5515.6338], grad_fn=<DivBackward0>)\n",
      "Epoch 1800\n",
      " ---------------------- loss: tensor([5512.6465], grad_fn=<DivBackward0>)\n",
      "Epoch 1801\n",
      " ---------------------- loss: tensor([5509.6133], grad_fn=<DivBackward0>)\n",
      "Epoch 1802\n",
      " ---------------------- loss: tensor([5506.5337], grad_fn=<DivBackward0>)\n",
      "Epoch 1803\n",
      " ---------------------- loss: tensor([5503.4062], grad_fn=<DivBackward0>)\n",
      "Epoch 1804\n",
      " ---------------------- loss: tensor([5500.2290], grad_fn=<DivBackward0>)\n",
      "Epoch 1805\n",
      " ---------------------- loss: tensor([5497.0015], grad_fn=<DivBackward0>)\n",
      "Epoch 1806\n",
      " ---------------------- loss: tensor([5493.7212], grad_fn=<DivBackward0>)\n",
      "Epoch 1807\n",
      " ---------------------- loss: tensor([5490.3887], grad_fn=<DivBackward0>)\n",
      "Epoch 1808\n",
      " ---------------------- loss: tensor([5486.9990], grad_fn=<DivBackward0>)\n",
      "Epoch 1809\n",
      " ---------------------- loss: tensor([5483.5537], grad_fn=<DivBackward0>)\n",
      "Epoch 1810\n",
      " ---------------------- loss: tensor([5480.0479], grad_fn=<DivBackward0>)\n",
      "Epoch 1811\n",
      " ---------------------- loss: tensor([5476.4829], grad_fn=<DivBackward0>)\n",
      "Epoch 1812\n",
      " ---------------------- loss: tensor([5472.8540], grad_fn=<DivBackward0>)\n",
      "Epoch 1813\n",
      " ---------------------- loss: tensor([5469.1606], grad_fn=<DivBackward0>)\n",
      "Epoch 1814\n",
      " ---------------------- loss: tensor([5465.3999], grad_fn=<DivBackward0>)\n",
      "Epoch 1815\n",
      " ---------------------- loss: tensor([5461.5708], grad_fn=<DivBackward0>)\n",
      "Epoch 1816\n",
      " ---------------------- loss: tensor([5457.6699], grad_fn=<DivBackward0>)\n",
      "Epoch 1817\n",
      " ---------------------- loss: tensor([5453.6929], grad_fn=<DivBackward0>)\n",
      "Epoch 1818\n",
      " ---------------------- loss: tensor([5449.6387], grad_fn=<DivBackward0>)\n",
      "Epoch 1819\n",
      " ---------------------- loss: tensor([5445.5054], grad_fn=<DivBackward0>)\n",
      "Epoch 1820\n",
      " ---------------------- loss: tensor([5441.2891], grad_fn=<DivBackward0>)\n",
      "Epoch 1821\n",
      " ---------------------- loss: tensor([5436.9858], grad_fn=<DivBackward0>)\n",
      "Epoch 1822\n",
      " ---------------------- loss: tensor([5432.5933], grad_fn=<DivBackward0>)\n",
      "Epoch 1823\n",
      " ---------------------- loss: tensor([5428.1084], grad_fn=<DivBackward0>)\n",
      "Epoch 1824\n",
      " ---------------------- loss: tensor([5423.5269], grad_fn=<DivBackward0>)\n",
      "Epoch 1825\n",
      " ---------------------- loss: tensor([5418.8418], grad_fn=<DivBackward0>)\n",
      "Epoch 1826\n",
      " ---------------------- loss: tensor([5414.0537], grad_fn=<DivBackward0>)\n",
      "Epoch 1827\n",
      " ---------------------- loss: tensor([5409.1548], grad_fn=<DivBackward0>)\n",
      "Epoch 1828\n",
      " ---------------------- loss: tensor([5404.1416], grad_fn=<DivBackward0>)\n",
      "Epoch 1829\n",
      " ---------------------- loss: tensor([5399.0088], grad_fn=<DivBackward0>)\n",
      "Epoch 1830\n",
      " ---------------------- loss: tensor([5393.7490], grad_fn=<DivBackward0>)\n",
      "Epoch 1831\n",
      " ---------------------- loss: tensor([5388.3579], grad_fn=<DivBackward0>)\n",
      "Epoch 1832\n",
      " ---------------------- loss: tensor([5382.8315], grad_fn=<DivBackward0>)\n",
      "Epoch 1833\n",
      " ---------------------- loss: tensor([5377.1602], grad_fn=<DivBackward0>)\n",
      "Epoch 1834\n",
      " ---------------------- loss: tensor([5371.3379], grad_fn=<DivBackward0>)\n",
      "Epoch 1835\n",
      " ---------------------- loss: tensor([5365.3530], grad_fn=<DivBackward0>)\n",
      "Epoch 1836\n",
      " ---------------------- loss: tensor([5359.2036], grad_fn=<DivBackward0>)\n",
      "Epoch 1837\n",
      " ---------------------- loss: tensor([5352.8760], grad_fn=<DivBackward0>)\n",
      "Epoch 1838\n",
      " ---------------------- loss: tensor([5346.3608], grad_fn=<DivBackward0>)\n",
      "Epoch 1839\n",
      " ---------------------- loss: tensor([5339.6504], grad_fn=<DivBackward0>)\n",
      "Epoch 1840\n",
      " ---------------------- loss: tensor([5332.7295], grad_fn=<DivBackward0>)\n",
      "Epoch 1841\n",
      " ---------------------- loss: tensor([5325.5869], grad_fn=<DivBackward0>)\n",
      "Epoch 1842\n",
      " ---------------------- loss: tensor([5318.2095], grad_fn=<DivBackward0>)\n",
      "Epoch 1843\n",
      " ---------------------- loss: tensor([5310.5820], grad_fn=<DivBackward0>)\n",
      "Epoch 1844\n",
      " ---------------------- loss: tensor([5302.6914], grad_fn=<DivBackward0>)\n",
      "Epoch 1845\n",
      " ---------------------- loss: tensor([5294.5127], grad_fn=<DivBackward0>)\n",
      "Epoch 1846\n",
      " ---------------------- loss: tensor([5286.0332], grad_fn=<DivBackward0>)\n",
      "Epoch 1847\n",
      " ---------------------- loss: tensor([5277.2275], grad_fn=<DivBackward0>)\n",
      "Epoch 1848\n",
      " ---------------------- loss: tensor([5268.0732], grad_fn=<DivBackward0>)\n",
      "Epoch 1849\n",
      " ---------------------- loss: tensor([5258.5430], grad_fn=<DivBackward0>)\n",
      "Epoch 1850\n",
      " ---------------------- loss: tensor([5248.6094], grad_fn=<DivBackward0>)\n",
      "Epoch 1851\n",
      " ---------------------- loss: tensor([5238.2363], grad_fn=<DivBackward0>)\n",
      "Epoch 1852\n",
      " ---------------------- loss: tensor([5227.3892], grad_fn=<DivBackward0>)\n",
      "Epoch 1853\n",
      " ---------------------- loss: tensor([5216.0278], grad_fn=<DivBackward0>)\n",
      "Epoch 1854\n",
      " ---------------------- loss: tensor([5204.1045], grad_fn=<DivBackward0>)\n",
      "Epoch 1855\n",
      " ---------------------- loss: tensor([5191.5649], grad_fn=<DivBackward0>)\n",
      "Epoch 1856\n",
      " ---------------------- loss: tensor([5178.3540], grad_fn=<DivBackward0>)\n",
      "Epoch 1857\n",
      " ---------------------- loss: tensor([5164.3989], grad_fn=<DivBackward0>)\n",
      "Epoch 1858\n",
      " ---------------------- loss: tensor([5149.6221], grad_fn=<DivBackward0>)\n",
      "Epoch 1859\n",
      " ---------------------- loss: tensor([5133.9346], grad_fn=<DivBackward0>)\n",
      "Epoch 1860\n",
      " ---------------------- loss: tensor([5117.2295], grad_fn=<DivBackward0>)\n",
      "Epoch 1861\n",
      " ---------------------- loss: tensor([5099.3809], grad_fn=<DivBackward0>)\n",
      "Epoch 1862\n",
      " ---------------------- loss: tensor([5080.2485], grad_fn=<DivBackward0>)\n",
      "Epoch 1863\n",
      " ---------------------- loss: tensor([5059.6543], grad_fn=<DivBackward0>)\n",
      "Epoch 1864\n",
      " ---------------------- loss: tensor([5037.3940], grad_fn=<DivBackward0>)\n",
      "Epoch 1865\n",
      " ---------------------- loss: tensor([5013.2197], grad_fn=<DivBackward0>)\n",
      "Epoch 1866\n",
      " ---------------------- loss: tensor([4986.8203], grad_fn=<DivBackward0>)\n",
      "Epoch 1867\n",
      " ---------------------- loss: tensor([4957.8203], grad_fn=<DivBackward0>)\n",
      "Epoch 1868\n",
      " ---------------------- loss: tensor([4925.7476], grad_fn=<DivBackward0>)\n",
      "Epoch 1869\n",
      " ---------------------- loss: tensor([4890.0015], grad_fn=<DivBackward0>)\n",
      "Epoch 1870\n",
      " ---------------------- loss: tensor([4849.8047], grad_fn=<DivBackward0>)\n",
      "Epoch 1871\n",
      " ---------------------- loss: tensor([4804.1362], grad_fn=<DivBackward0>)\n",
      "Epoch 1872\n",
      " ---------------------- loss: tensor([4751.6245], grad_fn=<DivBackward0>)\n",
      "Epoch 1873\n",
      " ---------------------- loss: tensor([4690.3755], grad_fn=<DivBackward0>)\n",
      "Epoch 1874\n",
      " ---------------------- loss: tensor([4617.6997], grad_fn=<DivBackward0>)\n",
      "Epoch 1875\n",
      " ---------------------- loss: tensor([4529.6382], grad_fn=<DivBackward0>)\n",
      "Epoch 1876\n",
      " ---------------------- loss: tensor([4420.1045], grad_fn=<DivBackward0>)\n",
      "Epoch 1877\n",
      " ---------------------- loss: tensor([4279.2402], grad_fn=<DivBackward0>)\n",
      "Epoch 1878\n",
      " ---------------------- loss: tensor([4089.9773], grad_fn=<DivBackward0>)\n",
      "Epoch 1879\n",
      " ---------------------- loss: tensor([3820.1987], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1880\n",
      " ---------------------- loss: tensor([3402.9727], grad_fn=<DivBackward0>)\n",
      "Epoch 1881\n",
      " ---------------------- loss: tensor([2684.3723], grad_fn=<DivBackward0>)\n",
      "Epoch 1882\n",
      " ---------------------- loss: tensor([1376.0942], grad_fn=<DivBackward0>)\n",
      "Epoch 1883\n",
      " ---------------------- loss: tensor([927.9279], grad_fn=<DivBackward0>)\n",
      "Epoch 1884\n",
      " ---------------------- loss: tensor([2548.9055], grad_fn=<DivBackward0>)\n",
      "Epoch 1885\n",
      " ---------------------- loss: tensor([1736.1509], grad_fn=<DivBackward0>)\n",
      "Epoch 1886\n",
      " ---------------------- loss: tensor([588.2930], grad_fn=<DivBackward0>)\n",
      "Epoch 1887\n",
      " ---------------------- loss: tensor([1168.0599], grad_fn=<DivBackward0>)\n",
      "Epoch 1888\n",
      " ---------------------- loss: tensor([1621.2036], grad_fn=<DivBackward0>)\n",
      "Epoch 1889\n",
      " ---------------------- loss: tensor([1676.2080], grad_fn=<DivBackward0>)\n",
      "Epoch 1890\n",
      " ---------------------- loss: tensor([1401.4266], grad_fn=<DivBackward0>)\n",
      "Epoch 1891\n",
      " ---------------------- loss: tensor([891.6053], grad_fn=<DivBackward0>)\n",
      "Epoch 1892\n",
      " ---------------------- loss: tensor([591.4689], grad_fn=<DivBackward0>)\n",
      "Epoch 1893\n",
      " ---------------------- loss: tensor([1036.4413], grad_fn=<DivBackward0>)\n",
      "Epoch 1894\n",
      " ---------------------- loss: tensor([1220.3502], grad_fn=<DivBackward0>)\n",
      "Epoch 1895\n",
      " ---------------------- loss: tensor([787.9046], grad_fn=<DivBackward0>)\n",
      "Epoch 1896\n",
      " ---------------------- loss: tensor([594.0485], grad_fn=<DivBackward0>)\n",
      "Epoch 1897\n",
      " ---------------------- loss: tensor([787.9421], grad_fn=<DivBackward0>)\n",
      "Epoch 1898\n",
      " ---------------------- loss: tensor([949.9592], grad_fn=<DivBackward0>)\n",
      "Epoch 1899\n",
      " ---------------------- loss: tensor([930.5743], grad_fn=<DivBackward0>)\n",
      "Epoch 1900\n",
      " ---------------------- loss: tensor([765.3183], grad_fn=<DivBackward0>)\n",
      "Epoch 1901\n",
      " ---------------------- loss: tensor([603.8753], grad_fn=<DivBackward0>)\n",
      "Epoch 1902\n",
      " ---------------------- loss: tensor([636.0645], grad_fn=<DivBackward0>)\n",
      "Epoch 1903\n",
      " ---------------------- loss: tensor([785.7907], grad_fn=<DivBackward0>)\n",
      "Epoch 1904\n",
      " ---------------------- loss: tensor([777.3635], grad_fn=<DivBackward0>)\n",
      "Epoch 1905\n",
      " ---------------------- loss: tensor([639.2377], grad_fn=<DivBackward0>)\n",
      "Epoch 1906\n",
      " ---------------------- loss: tensor([589.9898], grad_fn=<DivBackward0>)\n",
      "Epoch 1907\n",
      " ---------------------- loss: tensor([651.8336], grad_fn=<DivBackward0>)\n",
      "Epoch 1908\n",
      " ---------------------- loss: tensor([709.7283], grad_fn=<DivBackward0>)\n",
      "Epoch 1909\n",
      " ---------------------- loss: tensor([699.6542], grad_fn=<DivBackward0>)\n",
      "Epoch 1910\n",
      " ---------------------- loss: tensor([637.8148], grad_fn=<DivBackward0>)\n",
      "Epoch 1911\n",
      " ---------------------- loss: tensor([589.9620], grad_fn=<DivBackward0>)\n",
      "Epoch 1912\n",
      " ---------------------- loss: tensor([607.2704], grad_fn=<DivBackward0>)\n",
      "Epoch 1913\n",
      " ---------------------- loss: tensor([653.5485], grad_fn=<DivBackward0>)\n",
      "Epoch 1914\n",
      " ---------------------- loss: tensor([653.7027], grad_fn=<DivBackward0>)\n",
      "Epoch 1915\n",
      " ---------------------- loss: tensor([611.2119], grad_fn=<DivBackward0>)\n",
      "Epoch 1916\n",
      " ---------------------- loss: tensor([587.6738], grad_fn=<DivBackward0>)\n",
      "Epoch 1917\n",
      " ---------------------- loss: tensor([603.0502], grad_fn=<DivBackward0>)\n",
      "Epoch 1918\n",
      " ---------------------- loss: tensor([625.9869], grad_fn=<DivBackward0>)\n",
      "Epoch 1919\n",
      " ---------------------- loss: tensor([627.2524], grad_fn=<DivBackward0>)\n",
      "Epoch 1920\n",
      " ---------------------- loss: tensor([607.3215], grad_fn=<DivBackward0>)\n",
      "Epoch 1921\n",
      " ---------------------- loss: tensor([589.1082], grad_fn=<DivBackward0>)\n",
      "Epoch 1922\n",
      " ---------------------- loss: tensor([591.6900], grad_fn=<DivBackward0>)\n",
      "Epoch 1923\n",
      " ---------------------- loss: tensor([606.9794], grad_fn=<DivBackward0>)\n",
      "Epoch 1924\n",
      " ---------------------- loss: tensor([611.2309], grad_fn=<DivBackward0>)\n",
      "Epoch 1925\n",
      " ---------------------- loss: tensor([599.1896], grad_fn=<DivBackward0>)\n",
      "Epoch 1926\n",
      " ---------------------- loss: tensor([588.0031], grad_fn=<DivBackward0>)\n",
      "Epoch 1927\n",
      " ---------------------- loss: tensor([589.7143], grad_fn=<DivBackward0>)\n",
      "Epoch 1928\n",
      " ---------------------- loss: tensor([598.0695], grad_fn=<DivBackward0>)\n",
      "Epoch 1929\n",
      " ---------------------- loss: tensor([601.1436], grad_fn=<DivBackward0>)\n",
      "Epoch 1930\n",
      " ---------------------- loss: tensor([595.6528], grad_fn=<DivBackward0>)\n",
      "Epoch 1931\n",
      " ---------------------- loss: tensor([588.4156], grad_fn=<DivBackward0>)\n",
      "Epoch 1932\n",
      " ---------------------- loss: tensor([587.3442], grad_fn=<DivBackward0>)\n",
      "Epoch 1933\n",
      " ---------------------- loss: tensor([592.0295], grad_fn=<DivBackward0>)\n",
      "Epoch 1934\n",
      " ---------------------- loss: tensor([595.0045], grad_fn=<DivBackward0>)\n",
      "Epoch 1935\n",
      " ---------------------- loss: tensor([592.2044], grad_fn=<DivBackward0>)\n",
      "Epoch 1936\n",
      " ---------------------- loss: tensor([587.6576], grad_fn=<DivBackward0>)\n",
      "Epoch 1937\n",
      " ---------------------- loss: tensor([586.7257], grad_fn=<DivBackward0>)\n",
      "Epoch 1938\n",
      " ---------------------- loss: tensor([589.2540], grad_fn=<DivBackward0>)\n",
      "Epoch 1939\n",
      " ---------------------- loss: tensor([591.1635], grad_fn=<DivBackward0>)\n",
      "Epoch 1940\n",
      " ---------------------- loss: tensor([590.0103], grad_fn=<DivBackward0>)\n",
      "Epoch 1941\n",
      " ---------------------- loss: tensor([587.3328], grad_fn=<DivBackward0>)\n",
      "Epoch 1942\n",
      " ---------------------- loss: tensor([586.1960], grad_fn=<DivBackward0>)\n",
      "Epoch 1943\n",
      " ---------------------- loss: tensor([587.3895], grad_fn=<DivBackward0>)\n",
      "Epoch 1944\n",
      " ---------------------- loss: tensor([588.7679], grad_fn=<DivBackward0>)\n",
      "Epoch 1945\n",
      " ---------------------- loss: tensor([588.3322], grad_fn=<DivBackward0>)\n",
      "Epoch 1946\n",
      " ---------------------- loss: tensor([586.7088], grad_fn=<DivBackward0>)\n",
      "Epoch 1947\n",
      " ---------------------- loss: tensor([585.8702], grad_fn=<DivBackward0>)\n",
      "Epoch 1948\n",
      " ---------------------- loss: tensor([586.4419], grad_fn=<DivBackward0>)\n",
      "Epoch 1949\n",
      " ---------------------- loss: tensor([587.2643], grad_fn=<DivBackward0>)\n",
      "Epoch 1950\n",
      " ---------------------- loss: tensor([587.1417], grad_fn=<DivBackward0>)\n",
      "Epoch 1951\n",
      " ---------------------- loss: tensor([586.2220], grad_fn=<DivBackward0>)\n",
      "Epoch 1952\n",
      " ---------------------- loss: tensor([585.5690], grad_fn=<DivBackward0>)\n",
      "Epoch 1953\n",
      " ---------------------- loss: tensor([585.7582], grad_fn=<DivBackward0>)\n",
      "Epoch 1954\n",
      " ---------------------- loss: tensor([586.2593], grad_fn=<DivBackward0>)\n",
      "Epoch 1955\n",
      " ---------------------- loss: tensor([586.2601], grad_fn=<DivBackward0>)\n",
      "Epoch 1956\n",
      " ---------------------- loss: tensor([585.7155], grad_fn=<DivBackward0>)\n",
      "Epoch 1957\n",
      " ---------------------- loss: tensor([585.2599], grad_fn=<DivBackward0>)\n",
      "Epoch 1958\n",
      " ---------------------- loss: tensor([585.2988], grad_fn=<DivBackward0>)\n",
      "Epoch 1959\n",
      " ---------------------- loss: tensor([585.5684], grad_fn=<DivBackward0>)\n",
      "Epoch 1960\n",
      " ---------------------- loss: tensor([585.5891], grad_fn=<DivBackward0>)\n",
      "Epoch 1961\n",
      " ---------------------- loss: tensor([585.2732], grad_fn=<DivBackward0>)\n",
      "Epoch 1962\n",
      " ---------------------- loss: tensor([584.9518], grad_fn=<DivBackward0>)\n",
      "Epoch 1963\n",
      " ---------------------- loss: tensor([584.9067], grad_fn=<DivBackward0>)\n",
      "Epoch 1964\n",
      " ---------------------- loss: tensor([585.0393], grad_fn=<DivBackward0>)\n",
      "Epoch 1965\n",
      " ---------------------- loss: tensor([585.0547], grad_fn=<DivBackward0>)\n",
      "Epoch 1966\n",
      " ---------------------- loss: tensor([584.8584], grad_fn=<DivBackward0>)\n",
      "Epoch 1967\n",
      " ---------------------- loss: tensor([584.6324], grad_fn=<DivBackward0>)\n",
      "Epoch 1968\n",
      " ---------------------- loss: tensor([584.5637], grad_fn=<DivBackward0>)\n",
      "Epoch 1969\n",
      " ---------------------- loss: tensor([584.6116], grad_fn=<DivBackward0>)\n",
      "Epoch 1970\n",
      " ---------------------- loss: tensor([584.6071], grad_fn=<DivBackward0>)\n",
      "Epoch 1971\n",
      " ---------------------- loss: tensor([584.4772], grad_fn=<DivBackward0>)\n",
      "Epoch 1972\n",
      " ---------------------- loss: tensor([584.3143], grad_fn=<DivBackward0>)\n",
      "Epoch 1973\n",
      " ---------------------- loss: tensor([584.2350], grad_fn=<DivBackward0>)\n",
      "Epoch 1974\n",
      " ---------------------- loss: tensor([584.2343], grad_fn=<DivBackward0>)\n",
      "Epoch 1975\n",
      " ---------------------- loss: tensor([584.2138], grad_fn=<DivBackward0>)\n",
      "Epoch 1976\n",
      " ---------------------- loss: tensor([584.1176], grad_fn=<DivBackward0>)\n",
      "Epoch 1977\n",
      " ---------------------- loss: tensor([583.9941], grad_fn=<DivBackward0>)\n",
      "Epoch 1978\n",
      " ---------------------- loss: tensor([583.9164], grad_fn=<DivBackward0>)\n",
      "Epoch 1979\n",
      " ---------------------- loss: tensor([583.8876], grad_fn=<DivBackward0>)\n",
      "Epoch 1980\n",
      " ---------------------- loss: tensor([583.8531], grad_fn=<DivBackward0>)\n",
      "Epoch 1981\n",
      " ---------------------- loss: tensor([583.7748], grad_fn=<DivBackward0>)\n",
      "Epoch 1982\n",
      " ---------------------- loss: tensor([583.6757], grad_fn=<DivBackward0>)\n",
      "Epoch 1983\n",
      " ---------------------- loss: tensor([583.6012], grad_fn=<DivBackward0>)\n",
      "Epoch 1984\n",
      " ---------------------- loss: tensor([583.5568], grad_fn=<DivBackward0>)\n",
      "Epoch 1985\n",
      " ---------------------- loss: tensor([583.5128], grad_fn=<DivBackward0>)\n",
      "Epoch 1986\n",
      " ---------------------- loss: tensor([583.4431], grad_fn=<DivBackward0>)\n",
      "Epoch 1987\n",
      " ---------------------- loss: tensor([583.3588], grad_fn=<DivBackward0>)\n",
      "Epoch 1988\n",
      " ---------------------- loss: tensor([583.2878], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1989\n",
      " ---------------------- loss: tensor([583.2358], grad_fn=<DivBackward0>)\n",
      "Epoch 1990\n",
      " ---------------------- loss: tensor([583.1847], grad_fn=<DivBackward0>)\n",
      "Epoch 1991\n",
      " ---------------------- loss: tensor([583.1197], grad_fn=<DivBackward0>)\n",
      "Epoch 1992\n",
      " ---------------------- loss: tensor([583.0447], grad_fn=<DivBackward0>)\n",
      "Epoch 1993\n",
      " ---------------------- loss: tensor([582.9763], grad_fn=<DivBackward0>)\n",
      "Epoch 1994\n",
      " ---------------------- loss: tensor([582.9194], grad_fn=<DivBackward0>)\n",
      "Epoch 1995\n",
      " ---------------------- loss: tensor([582.8644], grad_fn=<DivBackward0>)\n",
      "Epoch 1996\n",
      " ---------------------- loss: tensor([582.8013], grad_fn=<DivBackward0>)\n",
      "Epoch 1997\n",
      " ---------------------- loss: tensor([582.7316], grad_fn=<DivBackward0>)\n",
      "Epoch 1998\n",
      " ---------------------- loss: tensor([582.6656], grad_fn=<DivBackward0>)\n",
      "Epoch 1999\n",
      " ---------------------- loss: tensor([582.6064], grad_fn=<DivBackward0>)\n",
      "Epoch 2000\n",
      " ---------------------- loss: tensor([582.5489], grad_fn=<DivBackward0>)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "upper_r = 6\n",
    "lower_r = -6\n",
    "steps = 200\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "epoch = 2000\n",
    "lr = 2e-1\n",
    "Phis_t = []\n",
    "Es = []\n",
    "lss = []\n",
    "epochs = []\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "initialize_weights(model)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "for t in range(epoch):\n",
    "    loss = loss_fn(R_train.to(device))\n",
    "    print(f\"Epoch {t+1}\\n ---------------------- loss: {loss}\")\n",
    "    training(R_train, loss_fn, optimizer)\n",
    "    if t%10 == 0:\n",
    "        Phis_t.append(Phi_t(R_train).detach().numpy())\n",
    "        Es.append(E.detach().numpy())\n",
    "        lss.append(loss.detach().numpy())\n",
    "        epochs.append(t)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "caef293a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(1,2,figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, Es, \"r.\", label=\"Energies\")\n",
    "plt.title(\"Eigenvalues of Energy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Energy\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, lss, \"b.\", label=\"Losses\")\n",
    "plt.title(\"Loss per 10 epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83782787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78372496"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.squeeze(Es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b2577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc851ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d539f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c7d749",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      7\u001b[0m     yy \u001b[38;5;241m=\u001b[39m Phis_t[i]\n\u001b[0;32m----> 8\u001b[0m     axs[fil,col]\u001b[38;5;241m.\u001b[39mplot(rr, yy\u001b[38;5;241m.\u001b[39msqueeze(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     axs[fil,col]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$r$\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     axs[fil,col]\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mphi(x)$\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3IAAAJDCAYAAABOhiZdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzC0lEQVR4nO3dX4ik53km7vv5jSJInD8y0SQ4Iw2rLErk2cVa7I5iQv4oa3YjKQdDwAeSQ0xEYBBYIYcWe5AEfJIcBIKx7GEwQvgkOolJlEWxWHZJHHCUaAS2rLGR6cjE6iggKQ5ZsGHF2M/voCtJTatH/fVMVff3lq4LGvr76lXV81Kqm7qnqrqquwMAAMA4/r/jHgAAAIDDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMAcWuap6rKperaoXrnJ5VdXHq2q7qp6vqveufkyAN5NPwBzJJuAoTHlF7vEk97zF5fcmuX3xcy7Jp65/LIBJHo98Aubn8cgmYM0OLHLd/fkk33yLJWeTfKZ3PZPkpqp616oGBLga+QTMkWwCjsIqPiN3KsnLS8c7i3MAx00+AXMkm4DrdsMKrqP2Odf7Lqw6l923EOQd73jH++64444V3DwwF88999zr3X3yuOdYIp+AJLPLJ9kEJLm+bFpFkdtJcuvS8S1JXtlvYXdfSHIhSba2tvrixYsruHlgLqrq7497hj3kE5Bkdvkkm4Ak15dNq3hr5ZNJPrz4C0zvT/Iv3f2PK7hegOsln4A5kk3AdTvwFbmq+qMkdye5uap2kvxOku9Jku4+n+SpJPcl2U7y7SQPrmtYgGXyCZgj2QQchQOLXHc/cMDlneQjK5sIYCL5BMyRbAKOwireWgkAAMARUuQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgJhW5qrqnql6squ2qemSfy3+oqv6sqr5UVZeq6sHVjwpwJdkEzJV8AtbtwCJXVSeSPJrk3iRnkjxQVWf2LPtIkq90951J7k7yB1V144pnBfg3sgmYK/kEHIUpr8jdlWS7u1/q7jeSPJHk7J41neQHqqqSfH+Sbya5vNJJAa4km4C5kk/A2k0pcqeSvLx0vLM4t+wTSd6d5JUkX07yW9393ZVMCLA/2QTMlXwC1m5Kkat9zvWe419K8sUkP5bkvyT5RFX94JuuqOpcVV2sqouvvfbaIUcFuMLKsimRT8BKee4ErN2UIreT5Nal41uy+69Hyx5M8tnetZ3k60nu2HtF3X2hu7e6e+vkyZPXOjNAssJsSuQTsFKeOwFrN6XIPZvk9qq6bfEh3PuTPLlnzTeSfCBJqupHk/xkkpdWOSjAHrIJmCv5BKzdDQct6O7LVfVwkqeTnEjyWHdfqqqHFpefT/KxJI9X1Zez+3aCj3b362ucG3ibk03AXMkn4CgcWOSSpLufSvLUnnPnl35/Jcl/X+1oAG9NNgFzJZ+AdZv0heAAAADMhyIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGM6nIVdU9VfViVW1X1SNXWXN3VX2xqi5V1V+udkyAN5NNwFzJJ2DdbjhoQVWdSPJokv+WZCfJs1X1ZHd/ZWnNTUk+meSe7v5GVf3ImuYFSCKbgPmST8BRmPKK3F1Jtrv7pe5+I8kTSc7uWfOhJJ/t7m8kSXe/utoxAd5ENgFzJZ+AtZtS5E4leXnpeGdxbtlPJHlnVf1FVT1XVR9e1YAAVyGbgLmST8DaHfjWyiS1z7ne53rel+QDSb43yV9X1TPd/bUrrqjqXJJzSXL69OnDTwvw71aWTYl8AlbKcydg7aa8IreT5Nal41uSvLLPms9197e6+/Ukn09y594r6u4L3b3V3VsnT5681pkBkhVmUyKfgJXy3AlYuylF7tkkt1fVbVV1Y5L7kzy5Z82fJvm5qrqhqr4vyU8n+epqRwW4gmwC5ko+AWt34Fsru/tyVT2c5OkkJ5I81t2XquqhxeXnu/urVfW5JM8n+W6ST3f3C+scHHh7k03AXMkn4ChU9963bB+Nra2tvnjx4rHcNrAeVfVcd28d9xzXSz7B5tmEfJJNsHmuJ5smfSE4AAAA86HIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwUwqclV1T1W9WFXbVfXIW6z7qar6TlV9cHUjAuxPNgFzJZ+AdTuwyFXViSSPJrk3yZkkD1TVmaus+/0kT696SIC9ZBMwV/IJOApTXpG7K8l2d7/U3W8keSLJ2X3W/WaSP07y6grnA7ga2QTMlXwC1m5KkTuV5OWl453FuX9TVaeS/EqS86sbDeAtySZgruQTsHZTilztc673HP9hko9293fe8oqqzlXVxaq6+Nprr00cEWBfK8umRD4BK+W5E7B2N0xYs5Pk1qXjW5K8smfNVpInqipJbk5yX1Vd7u4/WV7U3ReSXEiSra2tvYEGcBgry6ZEPgEr5bkTsHZTityzSW6vqtuS/EOS+5N8aHlBd9/2r79X1eNJ/ud+T5QAVkg2AXMln4C1O7DIdfflqno4u39R6USSx7r7UlU9tLjce7uBIyebgLmST8BRmPKKXLr7qSRP7Tm3bwh1969f/1gAB5NNwFzJJ2DdJn0hOAAAAPOhyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMFMKnJVdU9VvVhV21X1yD6X/2pVPb/4+UJV3bn6UQGuJJuAuZJPwLodWOSq6kSSR5Pcm+RMkgeq6syeZV9P8gvd/Z4kH0tyYdWDAiyTTcBcySfgKEx5Re6uJNvd/VJ3v5HkiSRnlxd09xe6+58Xh88kuWW1YwK8iWwC5ko+AWs3pcidSvLy0vHO4tzV/EaSP7+eoQAmkE3AXMknYO1umLCm9jnX+y6s+sXshtHPXuXyc0nOJcnp06cnjgiwr5Vl02KNfAJWxXMnYO2mvCK3k+TWpeNbkryyd1FVvSfJp5Oc7e5/2u+KuvtCd29199bJkyevZV6Af7WybErkE7BSnjsBazelyD2b5Paquq2qbkxyf5InlxdU1ekkn03ya939tdWPCfAmsgmYK/kErN2Bb63s7stV9XCSp5OcSPJYd1+qqocWl59P8ttJfjjJJ6sqSS5399b6xgbe7mQTMFfyCTgK1b3vW7bXbmtrqy9evHgstw2sR1U9twlPROQTbJ5NyCfZBJvnerJp0heCAwAAMB+KHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGMykIldV91TVi1W1XVWP7HN5VdXHF5c/X1XvXf2oAFeSTcBcySdg3Q4sclV1IsmjSe5NcibJA1V1Zs+ye5Pcvvg5l+RTK54T4AqyCZgr+QQchSmvyN2VZLu7X+ruN5I8keTsnjVnk3ymdz2T5KaqeteKZwVYJpuAuZJPwNpNKXKnkry8dLyzOHfYNQCrJJuAuZJPwNrdMGFN7XOur2FNqupcdt8+kCT/r6pemHD7c3ZzktePe4gV2IR92MM8/OQR3tbKsimRTzNlD/OxCfsYMp9k0yxtwh6SzdjHJuzhmrNpSpHbSXLr0vEtSV65hjXp7gtJLiRJVV3s7q1DTTszm7CHZDP2YQ/zUFUXj/DmVpZNiXyaI3uYj03Yx6j5JJvmZxP2kGzGPjZlD9f63055a+WzSW6vqtuq6sYk9yd5cs+aJ5N8ePEXmN6f5F+6+x+vdSiACWQTMFfyCVi7A1+R6+7LVfVwkqeTnEjyWHdfqqqHFpefT/JUkvuSbCf5dpIH1zcygGwC5ks+AUdhylsr091PZTdwls+dX/q9k3zkkLd94ZDr52gT9pBsxj7sYR6OdA9ryqbEfTEX9jAfm7CPTcgn98M8bMIeks3Yx9t6D7WbIwAAAIxiymfkAAAAmJG1F7mquqeqXqyq7ap6ZJ/Lq6o+vrj8+ap677pnOqwJe/jVxezPV9UXqurO45jzrRy0h6V1P1VV36mqDx7lfFNN2UdV3V1VX6yqS1X1l0c940Em/P/0Q1X1Z1X1pcUeZve5iap6rKpevdqfwd6Qx/Um7GH22ZRsRj7JpnnYhGxK5NNcyKb5GD2f1pZN3b22n+x+wPfvkvx4khuTfCnJmT1r7kvy59n9PpX3J/mbdc60pj38TJJ3Ln6/d8Q9LK37P9l9T/8Hj3vua7wvbkrylSSnF8c/ctxzX8Me/keS31/8fjLJN5PceNyz75nx55O8N8kLV7l8Ex7Xm7CHWWfT1H0srZtlPsmm459/acahs+kQ98Ws97EJ+SSb5vOzCfm0rmxa9ytydyXZ7u6XuvuNJE8kObtnzdkkn+ldzyS5qaretea5DuPAPXT3F7r7nxeHz2T3u2DmZMr9kCS/meSPk7x6lMMdwpR9fCjJZ7v7G0nS3XPby5Q9dJIfqKpK8v3ZDaPLRzvmW+vuz2d3rqsZ/nGdDdjDANmUbEY+yaaZ2IBsSuTTXMim+Rg+n9aVTesucqeSvLx0vLM4d9g1x+mw8/1Gdhv1nBy4h6o6leRXkpzPfE25L34iyTur6i+q6rmq+vCRTTfNlD18Ism7s/vFsF9O8lvd/d2jGW9lNuFxvQl7WDbHbEo2I59k0zjm/rhO5NNcyKb5eDvk0zU9pid9/cB1qH3O7f0zmVPWHKfJ81XVL2Y3jH52rRMd3pQ9/GGSj3b3d3b/MWOWpuzjhiTvS/KBJN+b5K+r6pnu/tq6h5toyh5+KckXk/zXJP8xyf+qqr/q7v+75tlWaRMe15uwh92F882mZDPySTaNY+6P60Q+zYVsmo+3Qz5d02N63UVuJ8mtS8e3ZLcpH3bNcZo0X1W9J8mnk9zb3f90RLNNNWUPW0meWATRzUnuq6rL3f0nRzLhNFP/f3q9u7+V5FtV9fkkdyaZSyBN2cODSX6vd980vV1VX09yR5K/PZoRV2ITHtebsIe5Z1OyGfkkm8Yx98d1Ip/mQjbNx9shn67tMT3lg3TX+pPdovhSktvy7x9O/E971vxyrvxw39+uc6Y17eF0ku0kP3Pc817rHvasfzwz+8DuIe6Ldyf534u135fkhST/+bhnP+QePpXkdxe//2iSf0hy83HPvs9e/kOu/qHdTXhcb8IeZp1NU/exZ/3s8kk2Hf/8e+YcNpsOcV/Meh+bkE+y6fjnP+Q+Zp9P68imtb4i192Xq+rhJE9n9y/OPNbdl6rqocXl57P7V37uy+6D+dvZbdSzMXEPv53kh5N8cvGvMpe7e+u4Zt5r4h5mb8o+uvurVfW5JM8n+W6ST3f3vn/q9ThMvC8+luTxqvpydh/QH+3u149t6H1U1R8luTvJzVW1k+R3knxPslGP603Yw6yzKdmMfJJN8zF6NiXy6bhm3ks2zccm5NO6sqkWLRAAAIBBrP0LwQEAAFgtRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwRxY5Krqsap6tapeuMrlVVUfr6rtqnq+qt67+jEB3kw+AXMkm4CjMOUVuceT3PMWl9+b5PbFz7kkn7r+sQAmeTzyCZifxyObgDU7sMh19+eTfPMtlpxN8pne9UySm6rqXasaEOBq5BMwR7IJOAqr+IzcqSQvLx3vLM4BHDf5BMyRbAKu2w0ruI7a51zvu7DqXHbfQpB3vOMd77vjjjtWcPPAXDz33HOvd/fJ455jiXwCkswun2QTkOT6smkVRW4nya1Lx7ckeWW/hd19IcmFJNna2uqLFy+u4OaBuaiqvz/uGfaQT0CS2eWTbAKSXF82reKtlU8m+fDiLzC9P8m/dPc/ruB6Aa6XfALmSDYB1+3AV+Sq6o+S3J3k5qraSfI7Sb4nSbr7fJKnktyXZDvJt5M8uK5hAZbJJ2COZBNwFA4sct39wAGXd5KPrGwigInkEzBHsgk4Cqt4ayUAAABHSJEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDmVTkquqeqnqxqrar6pF9Lv+hqvqzqvpSVV2qqgdXPyrAlWQTMFfyCVi3A4tcVZ1I8miSe5OcSfJAVZ3Zs+wjSb7S3XcmuTvJH1TVjSueFeDfyCZgruQTcBSmvCJ3V5Lt7n6pu99I8kSSs3vWdJIfqKpK8v1Jvpnk8konBbiSbALmSj4BazelyJ1K8vLS8c7i3LJPJHl3kleSfDnJb3X3d1cyIcD+ZBMwV/IJWLspRa72Odd7jn8pyReT/FiS/5LkE1X1g2+6oqpzVXWxqi6+9tprhxwV4Aory6ZEPgEr5bkTsHZTitxOkluXjm/J7r8eLXswyWd713aSrye5Y+8VdfeF7t7q7q2TJ09e68wAyQqzKZFPwEp57gSs3ZQi92yS26vqtsWHcO9P8uSeNd9I8oEkqaofTfKTSV5a5aAAe8gmYK7kE7B2Nxy0oLsvV9XDSZ5OciLJY919qaoeWlx+PsnHkjxeVV/O7tsJPtrdr69xbuBtTjYBcyWfgKNwYJFLku5+KslTe86dX/r9lST/fbWjAbw12QTMlXwC1m3SF4IDAAAwH4ocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYzKQiV1X3VNWLVbVdVY9cZc3dVfXFqrpUVX+52jEB3kw2AXMln4B1u+GgBVV1IsmjSf5bkp0kz1bVk939laU1NyX5ZJJ7uvsbVfUja5oXIIlsAuZLPgFHYcorcncl2e7ul7r7jSRPJDm7Z82Hkny2u7+RJN396mrHBHgT2QTMlXwC1m5KkTuV5OWl453FuWU/keSdVfUXVfVcVX14VQMCXIVsAuZKPgFrd+BbK5PUPud6n+t5X5IPJPneJH9dVc9099euuKKqc0nOJcnp06cPPy3Av1tZNiXyCVgpz52AtZvyitxOkluXjm9J8so+az7X3d/q7teTfD7JnXuvqLsvdPdWd2+dPHnyWmcGSFaYTYl8AlbKcydg7aYUuWeT3F5Vt1XVjUnuT/LknjV/muTnquqGqvq+JD+d5KurHRXgCrIJmCv5BKzdgW+t7O7LVfVwkqeTnEjyWHdfqqqHFpef7+6vVtXnkjyf5LtJPt3dL6xzcODtTTYBcyWfgKNQ3Xvfsn00tra2+uLFi8dy28B6VNVz3b113HNcL/kEm2cT8kk2wea5nmya9IXgAAAAzIciBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABjOpyFXVPVX1YlVtV9Ujb7Hup6rqO1X1wdWNCLA/2QTMlXwC1u3AIldVJ5I8muTeJGeSPFBVZ66y7veTPL3qIQH2kk3AXMkn4ChMeUXuriTb3f1Sd7+R5IkkZ/dZ95tJ/jjJqyucD+BqZBMwV/IJWLspRe5UkpeXjncW5/5NVZ1K8itJzq9uNIC3JJuAuZJPwNpNKXK1z7nec/yHST7a3d95yyuqOldVF6vq4muvvTZxRIB9rSybEvkErJTnTsDa3TBhzU6SW5eOb0nyyp41W0meqKokuTnJfVV1ubv/ZHlRd19IciFJtra29gYawGGsLJsS+QSslOdOwNpNKXLPJrm9qm5L8g9J7k/yoeUF3X3bv/5eVY8n+Z/7PVECWCHZBMyVfALW7sAi192Xq+rh7P5FpRNJHuvuS1X10OJy7+0GjpxsAuZKPgFHYcorcunup5I8tefcviHU3b9+/WMBHEw2AXMln4B1m/SF4AAAAMyHIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAYzqchV1T1V9WJVbVfVI/tc/qtV9fzi5wtVdefqRwW4kmwC5ko+Aet2YJGrqhNJHk1yb5IzSR6oqjN7ln09yS9093uSfCzJhVUPCrBMNgFzJZ+AozDlFbm7kmx390vd/UaSJ5KcXV7Q3V/o7n9eHD6T5JbVjgnwJrIJmCv5BKzdlCJ3KsnLS8c7i3NX8xtJ/vx6hgKYQDYBcyWfgLW7YcKa2udc77uw6hezG0Y/e5XLzyU5lySnT5+eOCLAvlaWTYs18glYFc+dgLWb8orcTpJbl45vSfLK3kVV9Z4kn05ytrv/ab8r6u4L3b3V3VsnT568lnkB/tXKsimRT8BKee4ErN2UIvdsktur6raqujHJ/UmeXF5QVaeTfDbJr3X311Y/JsCbyCZgruQTsHYHvrWyuy9X1cNJnk5yIslj3X2pqh5aXH4+yW8n+eEkn6yqJLnc3VvrGxt4u5NNwFzJJ+AoVPe+b9leu62trb548eKx3DawHlX13CY8EZFPsHk2IZ9kE2ye68mmSV8IDgAAwHwocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCTilxV3VNVL1bVdlU9ss/lVVUfX1z+fFW9d/WjAlxJNgFzJZ+AdTuwyFXViSSPJrk3yZkkD1TVmT3L7k1y++LnXJJPrXhOgCvIJmCu5BNwFKa8IndXku3ufqm730jyRJKze9acTfKZ3vVMkpuq6l0rnhVgmWwC5ko+AWs3pcidSvLy0vHO4txh1wCskmwC5ko+AWt3w4Q1tc+5voY1qapz2X37QJL8v6p6YcLtz9nNSV4/7iFWYBP2YQ/z8JNHeFsry6ZEPs2UPczHJuxjyHySTbO0CXtINmMfm7CHa86mKUVuJ8mtS8e3JHnlGtakuy8kuZAkVXWxu7cONe3MbMIeks3Yhz3MQ1VdPMKbW1k2JfJpjuxhPjZhH6Pmk2yan03YQ7IZ+9iUPVzrfzvlrZXPJrm9qm6rqhuT3J/kyT1rnkzy4cVfYHp/kn/p7n+81qEAJpBNwFzJJ2DtDnxFrrsvV9XDSZ5OciLJY919qaoeWlx+PslTSe5Lsp3k20keXN/IALIJmC/5BByFKW+tTHc/ld3AWT53fun3TvKRQ972hUOun6NN2EOyGfuwh3k40j2sKZsS98Vc2MN8bMI+NiGf3A/zsAl7SDZjH2/rPdRujgAAADCKKZ+RAwAAYEbWXuSq6p6qerGqtqvqkX0ur6r6+OLy56vqveue6bAm7OFXF7M/X1VfqKo7j2POt3LQHpbW/VRVfaeqPniU8001ZR9VdXdVfbGqLlXVXx71jAeZ8P/TD1XVn1XVlxZ7mN3nJqrqsap69Wp/BntDHtebsIfZZ1OyGfkkm+ZhE7IpkU9zIZvmY/R8Wls2dffafrL7Ad+/S/LjSW5M8qUkZ/asuS/Jn2f3+1Ten+Rv1jnTmvbwM0neufj93hH3sLTu/2T3Pf0fPO65r/G+uCnJV5KcXhz/yHHPfQ17+B9Jfn/x+8kk30xy43HPvmfGn0/y3iQvXOXyTXhcb8IeZp1NU/extG6W+SSbjn/+pRmHzqZD3Bez3scm5JNsms/PJuTTurJp3a/I3ZVku7tf6u43kjyR5OyeNWeTfKZ3PZPkpqp615rnOowD99DdX+juf14cPpPd74KZkyn3Q5L8ZpI/TvLqUQ53CFP28aEkn+3ubyRJd89tL1P20El+oKoqyfdnN4wuH+2Yb627P5/dua5m+Md1NmAPA2RTshn5JJtmYgOyKZFPcyGb5mP4fFpXNq27yJ1K8vLS8c7i3GHXHKfDzvcb2W3Uc3LgHqrqVJJfSXI+8zXlvviJJO+sqr+oqueq6sNHNt00U/bwiSTvzu4Xw345yW9193ePZryV2YTH9SbsYdkcsynZjHySTeOY++M6kU9zIZvm4+2QT9f0mJ709QPXofY5t/fPZE5Zc5wmz1dVv5jdMPrZtU50eFP28IdJPtrd39n9x4xZmrKPG5K8L8kHknxvkr+uqme6+2vrHm6iKXv4pSRfTPJfk/zHJP+rqv6qu//vmmdbpU14XG/CHnYXzjebks3IJ9k0jrk/rhP5NBeyaT7eDvl0TY/pdRe5nSS3Lh3fkt2mfNg1x2nSfFX1niSfTnJvd//TEc021ZQ9bCV5YhFENye5r6oud/efHMmE00z9/+n17v5Wkm9V1eeT3JlkLoE0ZQ8PJvm93n3T9HZVfT3JHUn+9mhGXIlNeFxvwh7mnk3JZuSTbBrH3B/XiXyaC9k0H2+HfLq2x/SUD9Jd6092i+JLSW7Lv3848T/tWfPLufLDfX+7zpnWtIfTSbaT/Mxxz3ute9iz/vHM7AO7h7gv3p3kfy/Wfl+SF5L85+Oe/ZB7+FSS3138/qNJ/iHJzcc9+z57+Q+5+od2N+FxvQl7mHU2Td3HnvWzyyfZdPzz75lz2Gw6xH0x631sQj7JpuOf/5D7mH0+rSOb1vqKXHdfrqqHkzyd3b8481h3X6qqhxaXn8/uX/m5L7sP5m9nt1HPxsQ9/HaSH07yycW/ylzu7q3jmnmviXuYvSn76O6vVtXnkjyf5LtJPt3d+/6p1+Mw8b74WJLHq+rL2X1Af7S7Xz+2ofdRVX+U5O4kN1fVTpLfSfI9yUY9rjdhD7POpmQz8kk2zcfo2ZTIp+OaeS/ZNB+bkE/ryqZatEAAAAAGsfYvBAcAAGC1FDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABnNgkauqx6rq1ap64SqXV1V9vKq2q+r5qnrv6scEeDP5BMyRbAKOwpRX5B5Pcs9bXH5vktsXP+eSfOr6xwKY5PHIJ2B+Ho9sAtbswCLX3Z9P8s23WHI2yWd61zNJbqqqd61qQICrkU/AHMkm4Cis4jNyp5K8vHS8szgHcNzkEzBHsgm4bjes4Dpqn3O978Kqc9l9C0He8Y53vO+OO+5Ywc0Dc/Hcc8+93t0nj3uOJfIJSDK7fJJNQJLry6ZVFLmdJLcuHd+S5JX9Fnb3hSQXkmRra6svXry4gpsH5qKq/v64Z9hDPgFJZpdPsglIcn3ZtIq3Vj6Z5MOLv8D0/iT/0t3/uILrBbhe8gmYI9kEXLcDX5Grqj9KcneSm6tqJ8nvJPmeJOnu80meSnJfku0k307y4LqGBVgmn4A5kk3AUTiwyHX3Awdc3kk+srKJACaST8AcySbgKKzirZUAAAAcIUUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMZlKRq6p7qurFqtquqkf2ufyHqurPqupLVXWpqh5c/agAV5JNwFzJJ2DdDixyVXUiyaNJ7k1yJskDVXVmz7KPJPlKd9+Z5O4kf1BVN654VoB/I5uAuZJPwFGY8orcXUm2u/ul7n4jyRNJzu5Z00l+oKoqyfcn+WaSyyudFOBKsgmYK/kErN2UIncqyctLxzuLc8s+keTdSV5J8uUkv9Xd313JhAD7k03AXMknYO2mFLna51zvOf6lJF9M8mNJ/kuST1TVD77piqrOVdXFqrr42muvHXJUgCusLJsS+QSslOdOwNpNKXI7SW5dOr4lu/96tOzBJJ/tXdtJvp7kjr1X1N0Xunuru7dOnjx5rTMDJCvMpkQ+ASvluROwdlOK3LNJbq+q2xYfwr0/yZN71nwjyQeSpKp+NMlPJnlplYMC7CGbgLmST8Da3XDQgu6+XFUPJ3k6yYkkj3X3pap6aHH5+SQfS/J4VX05u28n+Gh3v77GuYG3OdkEzJV8Ao7CgUUuSbr7qSRP7Tl3fun3V5L899WOBvDWZBMwV/IJWLdJXwgOAADAfChyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMJOKXFXdU1UvVtV2VT1ylTV3V9UXq+pSVf3lascEeDPZBMyVfALW7YaDFlTViSSPJvlvSXaSPFtVT3b3V5bW3JTkk0nu6e5vVNWPrGlegCSyCZgv+QQchSmvyN2VZLu7X+ruN5I8keTsnjUfSvLZ7v5GknT3q6sdE+BNZBMwV/IJWLspRe5UkpeXjncW55b9RJJ3VtVfVNVzVfXhVQ0IcBWyCZgr+QSs3YFvrUxS+5zrfa7nfUk+kOR7k/x1VT3T3V+74oqqziU5lySnT58+/LQA/25l2ZTIJ2ClPHcC1m7KK3I7SW5dOr4lySv7rPlcd3+ru19P8vkkd+69ou6+0N1b3b118uTJa50ZIFlhNiXyCVgpz52AtZtS5J5NcntV3VZVNya5P8mTe9b8aZKfq6obqur7kvx0kq+udlSAK8gmYK7kE7B2B761srsvV9XDSZ5OciLJY919qaoeWlx+vru/WlWfS/J8ku8m+XR3v7DOwYG3N9kEzJV8Ao5Cde99y/bR2Nra6osXLx7LbQPrUVXPdffWcc9xveQTbJ5NyCfZBJvnerJp0heCAwAAMB+KHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGMykIldV91TVi1W1XVWPvMW6n6qq71TVB1c3IsD+ZBMwV/IJWLcDi1xVnUjyaJJ7k5xJ8kBVnbnKut9P8vSqhwTYSzYBcyWfgKMw5RW5u5Jsd/dL3f1GkieSnN1n3W8m+eMkr65wPoCrkU3AXMknYO2mFLlTSV5eOt5ZnPs3VXUqya8kOb+60QDekmwC5ko+AWs3pcjVPud6z/EfJvlod3/nLa+o6lxVXayqi6+99trEEQH2tbJsSuQTsFKeOwFrd8OENTtJbl06viXJK3vWbCV5oqqS5OYk91XV5e7+k+VF3X0hyYUk2dra2htoAIexsmxK5BOwUp47AWs3pcg9m+T2qrotyT8kuT/Jh5YXdPdt//p7VT2e5H/u90QJYIVkEzBX8glYuwOLXHdfrqqHs/sXlU4keay7L1XVQ4vLvbcbOHKyCZgr+QQchSmvyKW7n0ry1J5z+4ZQd//69Y8FcDDZBMyVfALWbdIXggMAADAfihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMEocgAAAINR5AAAAAajyAEAAAxGkQMAABjMpCJXVfdU1YtVtV1Vj+xz+a9W1fOLny9U1Z2rHxXgSrIJmCv5BKzbgUWuqk4keTTJvUnOJHmgqs7sWfb1JL/Q3e9J8rEkF1Y9KMAy2QTMlXwCjsKUV+TuSrLd3S919xtJnkhydnlBd3+hu/95cfhMkltWOybAm8gmYK7kE7B2U4rcqSQvLx3vLM5dzW8k+fPrGQpgAtkEzJV8Atbuhglrap9zve/Cql/Mbhj97FUuP5fkXJKcPn164ogA+1pZNi3WyCdgVTx3AtZuyityO0luXTq+JckrexdV1XuSfDrJ2e7+p/2uqLsvdPdWd2+dPHnyWuYF+Fcry6ZEPgEr5bkTsHZTityzSW6vqtuq6sYk9yd5cnlBVZ1O8tkkv9bdX1v9mABvIpuAuZJPwNod+NbK7r5cVQ8neTrJiSSPdfelqnpocfn5JL+d5IeTfLKqkuRyd2+tb2zg7U42AXMln4CjUN37vmV77ba2tvrixYvHctvAelTVc5vwREQ+webZhHySTbB5riebJn0hOAAAAPOhyAEAAAxGkQMAABiMIgcAADAYRQ4AAGAwihwAAMBgFDkAAIDBKHIAAACDUeQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwShyAAAAg1HkAAAABqPIAQAADEaRAwAAGIwiBwAAMBhFDgAAYDCKHAAAwGAUOQAAgMFMKnJVdU9VvVhV21X1yD6XV1V9fHH581X13tWPCnAl2QTMlXwC1u3AIldVJ5I8muTeJGeSPFBVZ/YsuzfJ7Yufc0k+teI5Aa4gm4C5kk/AUZjyitxdSba7+6XufiPJE0nO7llzNslnetczSW6qqneteFaAZbIJmCv5BKzdlCJ3KsnLS8c7i3OHXQOwSrIJmCv5BKzdDRPW1D7n+hrWpKrOZfftA0ny/6rqhQm3P2c3J3n9uIdYgU3Yhz3Mw08e4W2tLJsS+TRT9jAfm7CPIfNJNs3SJuwh2Yx9bMIerjmbphS5nSS3Lh3fkuSVa1iT7r6Q5EKSVNXF7t461LQzswl7SDZjH/YwD1V18QhvbmXZlMinObKH+diEfYyaT7JpfjZhD8lm7GNT9nCt/+2Ut1Y+m+T2qrqtqm5Mcn+SJ/eseTLJhxd/gen9Sf6lu//xWocCmEA2AXMln4C1O/AVue6+XFUPJ3k6yYkkj3X3pap6aHH5+SRPJbkvyXaSbyd5cH0jA8gmYL7kE3AUpry1Mt39VHYDZ/nc+aXfO8lHDnnbFw65fo42YQ/JZuzDHubhSPewpmxK3BdzYQ/zsQn72IR8cj/MwybsIdmMfbyt91C7OQIAAMAopnxGDgAAgBlZe5Grqnuq6sWq2q6qR/a5vKrq44vLn6+q9657psOasIdfXcz+fFV9oaruPI4538pBe1ha91NV9Z2q+uBRzjfVlH1U1d1V9cWqulRVf3nUMx5kwv9PP1RVf1ZVX1rsYXafm6iqx6rq1av9GewNeVxvwh5mn03JZuSTbJqHTcimRD7NhWyaj9HzaW3Z1N1r+8nuB3z/LsmPJ7kxyZeSnNmz5r4kf57d71N5f5K/WedMa9rDzyR55+L3e0fcw9K6/5Pd9/R/8Ljnvsb74qYkX0lyenH8I8c99zXs4X8k+f3F7yeTfDPJjcc9+54Zfz7Je5O8cJXLN+FxvQl7mHU2Td3H0rpZ5pNsOv75l2YcOpsOcV/Meh+bkE+yaT4/m5BP68qmdb8id1eS7e5+qbvfSPJEkrN71pxN8pne9UySm6rqXWue6zAO3EN3f6G7/3lx+Ex2vwtmTqbcD0nym0n+OMmrRzncIUzZx4eSfLa7v5Ek3T23vUzZQyf5gaqqJN+f3TC6fLRjvrXu/nx257qa4R/X2YA9DJBNyWbkk2yaiQ3IpkQ+zYVsmo/h82ld2bTuIncqyctLxzuLc4ddc5wOO99vZLdRz8mBe6iqU0l+Jcn5zNeU++Inkryzqv6iqp6rqg8f2XTTTNnDJ5K8O7tfDPvlJL/V3d89mvFWZhMe15uwh2VzzKZkM/JJNo1j7o/rRD7NhWyaj7dDPl3TY3rS1w9ch9rn3N4/kzllzXGaPF9V/WJ2w+hn1zrR4U3Zwx8m+Wh3f2f3HzNmaco+bkjyviQfSPK9Sf66qp7p7q+te7iJpuzhl5J8Mcl/TfIfk/yvqvqr7v6/a55tlTbhcb0Je9hdON9sSjYjn2TTOOb+uE7k01zIpvl4O+TTNT2m113kdpLcunR8S3ab8mHXHKdJ81XVe5J8Osm93f1PRzTbVFP2sJXkiUUQ3Zzkvqq63N1/ciQTTjP1/6fXu/tbSb5VVZ9PcmeSuQTSlD08mOT3evdN09tV9fUkdyT526MZcSU24XG9CXuYezYlm5FPsmkcc39cJ/JpLmTTfLwd8unaHtNTPkh3rT/ZLYovJbkt//7hxP+0Z80v58oP9/3tOmda0x5OJ9lO8jPHPe+17mHP+sczsw/sHuK+eHeS/71Y+31JXkjyn4979kPu4VNJfnfx+48m+YckNx/37Pvs5T/k6h/a3YTH9SbsYdbZNHUfe9bPLp9k0/HPv2fOYbPpEPfFrPexCfkkm45//kPuY/b5tI5sWusrct19uaoeTvJ0dv/izGPdfamqHlpcfj67f+Xnvuw+mL+d3UY9GxP38NtJfjjJJxf/KnO5u7eOa+a9Ju5h9qbso7u/WlWfS/J8ku8m+XR37/unXo/DxPviY0ker6ovZ/cB/dHufv3Yht5HVf1RkruT3FxVO0l+J8n3JBv1uN6EPcw6m5LNyCfZNB+jZ1Min45r5r1k03xsQj6tK5tq0QIBAAAYxNq/EBwAAIDVUuQAAAAGo8gBAAAMRpEDAAAYjCIHAAAwGEUOAABgMIocAADAYBQ5AACAwfz/PcHDAOy3vNAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = np.linspace(lower_r, upper_r, steps)[:,None]\n",
    "fig, axs = plt.subplots(3,3,figsize=(15,10))\n",
    "\n",
    "fil = 0\n",
    "col = 0\n",
    "for i in range(1,10):\n",
    "    yy = Phis_t[i]\n",
    "    axs[fil,col].plot(rr, yy.squeeze(), \".\", label=f\"Epochs {epochs[i]}\")\n",
    "    axs[fil,col].set_xlabel(\"$r$\")\n",
    "    axs[fil,col].set_ylabel(\"$\\phi(x)$\")\n",
    "    axs[fil,col].legend(loc=\"best\")\n",
    "    axs[fil,col].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    if col == 2:\n",
    "       col = 0\n",
    "       fil = fil+1\n",
    "    else:\n",
    "       col = col+1\n",
    "plt.tight_layout()\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d02683",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1,2,figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, Es, \"r.\", label=\"Energies\")\n",
    "plt.title(\"Eigenvalues of Energy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Energy\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, lss, \"b.\", label=\"Losses\")\n",
    "plt.title(\"Loss per 100 epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.squeeze(Es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67303d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e7e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0820a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74e7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df878b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
