{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb94f89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020576f",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d970ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(1,10),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(10,1, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N = self.layers(x)\n",
    "        return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a56de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x, loss_fn, optimizer):\n",
    "    x = x.to(device)\n",
    "    def closure():\n",
    "        loss = loss_fn(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d63b2",
   "metadata": {},
   "source": [
    "### Differential equation\n",
    "$$\\frac{d^2\\phi(r)}{dr^2} + \\frac{2m}{\\hbar^2}\\left(E-\\frac{l(l+1)}{2mr^2}\\hbar^2-V(r)\\right)\\phi(r) = 0$$ \n",
    "Dataset are vectors of domain of differential equation, like the vectors are one-dimentional, the shape of dataset is one by m samples. Trial solution $\\phi_t(r) = e^{-\\beta r^2}N(r,\\vec{p})$, with $\\phi(r=0) = 0$ and $\\phi(r\\rightarrow\\infty) = 0$ as boundary conditions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03384e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=10, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=10, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19eb90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=0.0001)\n",
    "beta = 2\n",
    "global Z\n",
    "Z = 1\n",
    "global e\n",
    "#e = -1.602e-19\n",
    "e = -1\n",
    "global hbar\n",
    "#hbar = 1.054e-34\n",
    "hbar = 1\n",
    "global m\n",
    "#m = 9.109e-31\n",
    "m = 1\n",
    "global l\n",
    "l = 0\n",
    "V = lambda r: -(Z*e**2)/r\n",
    "Phi_t = lambda r: torch.exp(-beta*r**2) * model.forward(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21bb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(r):\n",
    "    r.requires_grad = True\n",
    "    \n",
    "    outputs = Phi_t(r)\n",
    "    Phi_t_r = torch.autograd.grad(outputs, r, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "    Phi_t_r_r = torch.autograd.grad(Phi_t_r, r, grad_outputs=torch.ones_like(Phi_t_r), create_graph=True)[0]\n",
    "    H_Phi_t = -(hbar**2/(2*m))*Phi_t_r_r + (l*(l+1)*hbar**2/(2*m*r**2) + V(r))*outputs\n",
    "    \n",
    "    prom = outputs.size()[0]\n",
    "    \n",
    "    delta = r[1]-r[0]\n",
    "    norm = torch.sum(outputs**2)*delta\n",
    "    \n",
    "    global E\n",
    "    E = (torch.sum(outputs*H_Phi_t)*delta)/norm\n",
    "    \n",
    "    return (torch.mean((H_Phi_t - E*outputs)**2)*prom)/norm #multiply by m to avoit division by m in the mean function of torh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "959e5101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------- loss: tensor([17725.2695], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([17356.0723], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([56353.9648], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([55995.9102], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([55491.0586], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([54821.2266], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([53989.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([53024.7148], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([51970.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([28843.5547], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([28418.6387], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([27905.4199], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([27568.0254], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([27295.6875], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([27057.8711], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([26834.7012], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([26358.5391], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([25869.7461], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([25473.4590], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([25122.9141], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([24792.1094], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([24448.8125], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([24003.9551], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([23526.9102], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([23102.8105], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([22691.3672], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([22176.4082], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([21606.4883], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([21130.6934], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([20644.5020], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([19201.8633], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([17979.6875], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([16684.1602], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([15542.9570], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([14731.8486], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([13966.0215], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([13247.3975], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([12640.5010], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([12259.5479], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([11841.3564], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([11467.4785], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([11173.8174], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([10941.5977], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([10738.4805], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([10557.3213], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([10404.6943], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([10275.0059], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([10036.6289], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([9708.3262], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([9239.6348], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([8813.6992], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([8554.8135], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([8342.3936], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([7948.6602], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([7585.6426], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([7320.3677], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([7079.4810], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([6843.1885], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([6553.7920], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([6232.6753], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([5936.6895], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([5648.9355], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([5371.5698], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([5098.4497], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([4841.1504], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([4601.5088], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([4388.6045], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([4211.9844], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([4064.2927], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([3934.4673], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([3793.6023], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([3618.3044], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([3448.1599], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([3312.4280], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([3210.3567], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([3121.6821], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([3028.8445], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([2945.0911], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([2813.9299], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([2707.5310], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([2633.5588], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([2571.6289], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([2497.7559], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([2420.5337], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([2310.7190], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([2221.5605], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([2157.2781], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([2107.2048], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([2061.6814], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([1902.0021], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([1725.2035], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([1601.5602], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([1517.1411], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([1458.0558], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([1416.5469], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([1382.4500], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([1300.6633], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([1232.8069], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([1190.6628], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([1134.1846], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([1106.3289], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102\n",
      " ---------------------- loss: tensor([1088.0504], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([1027.6852], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([969.1901], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([934.5441], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([908.5512], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([886.6343], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([867.0953], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([841.2452], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([804.6687], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([776.1043], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([752.6710], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([726.7173], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([698.0101], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([676.3810], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([658.9538], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([641.1406], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([622.3916], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([606.6936], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([594.2865], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([583.8448], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([574.2355], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([540.2634], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([490.5720], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([469.8929], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([457.5237], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([448.7005], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([441.7455], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([435.5490], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([429.8342], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([393.9206], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([372.5377], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([359.8789], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([349.9821], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([341.5107], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([334.0238], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([326.6794], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([320.0270], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([314.1033], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([308.7468], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([303.6927], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([290.3061], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([277.9886], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([265.2361], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([255.4121], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([247.5591], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([240.8505], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([234.5264], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([229.1086], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([224.6290], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([220.7608], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([216.5354], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([208.4815], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([203.2307], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([199.5790], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([196.5181], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([193.8883], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([191.0709], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([186.5832], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([183.5494], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([181.1544], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([179.0175], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([176.9079], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([174.5845], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([172.5441], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([170.8270], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([169.3623], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([168.0749], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([166.8669], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([165.6470], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([164.3878], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([163.1946], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([162.2293], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([161.4584], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([160.8089], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([160.1478], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([159.3389], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([158.5665], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([157.9244], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([157.3174], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([156.7031], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([156.0894], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([155.4736], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([154.7891], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([154.0289], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([153.2713], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([152.4587], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([151.5352], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([150.5347], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([149.3150], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([147.2415], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([144.9303], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([142.7897], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([140.8306], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([138.8892], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([136.8598], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([135.1574], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([133.6848], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([132.4020], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([131.1905], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "upper_r = 6\n",
    "lower_r = 1e-2\n",
    "steps = 100\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "epochs = 200\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n ---------------------- loss: {loss_fn(R_train.to(device))}\")\n",
    "    training(R_train, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c3b74c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9272], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e8fe7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8c1b87d340>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = np.linspace(lower_r, upper_r, steps)[:,None]\n",
    "\n",
    "with torch.no_grad():\n",
    "    yy = Phi_t(torch.Tensor(rr).to(device)).cpu().numpy()\n",
    "#yt = xx**2 + np.exp(-xx**2 / 2)/(1+xx+xx**3)\n",
    "\n",
    "fig, axs = plt.subplots(dpi=100)\n",
    "#axs.plot(xx, yt, label=\"True\")\n",
    "axs.plot(rr, yy, \".\", label=\"Neural Network Approximation\")\n",
    "axs.set_xlabel(\"$x$\")\n",
    "axs.set_ylabel(\"$\\phi(x)$\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b29354",
   "metadata": {},
   "source": [
    "## With Xavier initialization of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6857e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Linear)):\n",
    "            nn.init.xavier_normal_(m.weight.data)\n",
    "        # if you also want for linear layers ,add one more elif condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8dcddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------- loss: tensor([15741.4668], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([17673.2246], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([17347.7031], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([17048.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([16786.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([16528.7539], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([16251.4766], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([15938.7061], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([15535.4736], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([14727.3320], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([13772.7900], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([13071.5703], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([12501.4121], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([11997.3740], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([11528.5801], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([11075.3789], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([10631.2861], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([10228.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([9884.2529], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([9585.8271], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([9322.6270], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([9077.4004], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([8830.3604], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([8614.9111], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([8440.9443], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([8287.4346], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([8132.6318], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([7965.5737], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([7814.7974], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([7659.5889], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([7518.2593], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([7401.4067], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([7279.6182], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([7143.0664], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([7013.8555], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([6877.0713], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([6720.1489], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([6538.6279], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([6291.2065], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([5948.8682], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([5567.6016], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([5240.1631], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([4971.1616], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([4748.3389], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([4552.8794], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([4343.2388], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([4053.2209], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([3667.3374], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([3241.5615], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([2911.6213], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([2673.4397], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([2480.4673], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([2312.8376], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([2157.6897], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([2033.3921], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([1938.6058], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([1860.8861], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([1791.0100], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([1728.1672], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([1674.0925], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([1625.7067], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([1577.1771], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([1521.1545], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([1469.5166], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([1416.7251], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([1370.8157], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([1337.2858], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([1309.7998], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([1235.4371], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([1175.8661], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([1137.2300], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([1090.1776], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([1053.8877], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([1014.7580], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([976.7436], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([927.9710], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([868.0759], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([821.6939], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([782.7701], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([747.0920], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([712.0059], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([684.9745], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([665.7933], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([649.9301], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([615.0125], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([583.9120], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([552.5963], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([529.5568], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([513.5801], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([501.8522], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([488.6751], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([475.8532], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([467.0179], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([460.2395], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([454.4763], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([449.3973], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([444.8841], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([437.3106], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([428.3265], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([421.7311], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101\n",
      " ---------------------- loss: tensor([407.5633], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([399.0474], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([392.8362], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([385.1079], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([376.8852], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([370.6664], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([365.3058], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([360.3129], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([355.6548], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([351.4112], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([347.6437], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([344.2798], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([341.2155], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([338.2230], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([334.9966], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([331.3849], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([327.8657], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([324.6808], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([321.4816], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([317.4911], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([310.6335], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([305.9452], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([303.6560], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([302.1985], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([301.2027], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([300.4412], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([299.7824], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([299.1634], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([298.3059], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([297.1327], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([290.5353], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([285.5540], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([281.8353], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([278.6892], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([275.3724], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([271.2445], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([266.2682], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([260.8002], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([256.8005], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([253.9841], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([251.6704], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([249.5747], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([247.8780], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([246.5242], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([245.2976], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([244.1227], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([243.1394], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([242.3265], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([241.6335], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([241.0786], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([240.6292], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([240.2337], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([239.8708], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([239.5514], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([239.2554], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([238.9814], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([238.7281], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([238.4671], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([238.1917], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([237.9010], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([237.5801], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([237.2074], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([236.7744], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([236.2542], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([235.6345], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([234.9520], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([234.2951], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([233.7245], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([233.2643], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([232.8953], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([232.5713], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([232.2650], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([231.9570], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([231.6401], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([231.3139], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([231.0253], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([230.5592], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([229.5835], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([227.9009], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([225.5372], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([221.7330], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([215.6033], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([212.8157], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([211.1392], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([209.8851], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([208.8060], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([207.8155], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([206.8176], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([205.2946], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([203.8957], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([202.6972], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([201.4760], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([200.1271], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([198.8477], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([197.6467], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([196.4750], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([195.2453], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([193.4542], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([191.5989], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      " ---------------------- loss: tensor([190.0755], grad_fn=<DivBackward0>)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "initialize_weights(model)\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=0.0001)\n",
    "upper_r = 6\n",
    "lower_r = 1e-2\n",
    "steps = 100\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "epochs = 200\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n ---------------------- loss: {loss_fn(R_train.to(device))}\")\n",
    "    training(R_train, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e38ff0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4337], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3f1216e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8c146a2c70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = np.linspace(lower_r, upper_r, steps)[:,None]\n",
    "\n",
    "with torch.no_grad():\n",
    "    yy = Phi_t(torch.Tensor(rr).to(device)).cpu().numpy()\n",
    "#yt = xx**2 + np.exp(-xx**2 / 2)/(1+xx+xx**3)\n",
    "\n",
    "fig, axs = plt.subplots(dpi=100)\n",
    "#axs.plot(xx, yt, label=\"True\")\n",
    "axs.plot(rr, yy, \".\", label=\"Neural Network Approximation\")\n",
    "axs.set_xlabel(\"$x$\")\n",
    "axs.set_ylabel(\"$\\phi(x)$\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d7443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41d6f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------- loss: tensor([4313.9937], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([2467.5122], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([379.2067], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([108.8350], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([43.5667], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([28.5400], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([21.9374], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([18.8255], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([36.0910], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([23.6692], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([21.7863], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([19.2615], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([17.5261], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([10.9460], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([9.7807], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([9.7348], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([9.6296], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([8.6085], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([7.6273], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([7.0759], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([6.9570], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([6.9199], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([6.9029], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([6.8330], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([6.4192], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([6.2478], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([6.2227], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([6.1580], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([6.1011], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([6.0504], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([5.9904], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([5.9625], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([6.4275], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([19514.3984], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([16316.6406], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([16025.5732], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([1.7014e+09], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([17243.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([17256.1465], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([16679.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([16546.7480], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([16882.2930], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([16801.5098], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([5051.2383], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([2439.1921], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([2432.0520], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([2424.7271], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([2417.2009], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([2409.4700], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([2401.4907], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([2393.2571], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([2384.7295], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([2375.8691], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([2366.6614], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([2357.0332], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([2346.9619], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([2336.3752], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([2325.1931], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([2313.3457], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([2300.7261], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([2165.2656], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([756.4656], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([34.8379], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([15787.2236], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([15164.8447], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([13664.0361], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([9818.0869], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([8497.3008], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([4524.8623], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([428.7913], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([51.5965], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([14.8601], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([10.6606], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([10.1654], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([10.0990], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([10.0976], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([10.0978], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([10.0988], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([10.0988], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([10.0977], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([10.0983], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([10.0977], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([10.0982], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([16709.8887], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([512.8349], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([324.9480], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([222.1618], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([163.2590], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([128.1133], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([106.5253], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([92.9925], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([84.4020], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([78.8932], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([75.3290], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([73.0063], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([71.4840], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([70.4817], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([69.8192], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([69.3799], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([69.0874], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([68.8919], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([68.7602], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([68.6707], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([68.6085], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([68.5639], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([68.5297], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([68.5002], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([68.4686], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([68.4201], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([68.0784], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([67.7977], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([67.7190], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([67.6271], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([67.4583], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([67.2475], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([144.9239], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([117.1274], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([95.4052], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([82.5396], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([75.2034], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([70.9617], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([68.4620], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([66.9208], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([65.9156], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([65.2386], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([64.7810], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([64.4740], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([64.2675], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([64.1172], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([63.9845], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([63.8443], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([63.6776], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([63.4553], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([63.0991], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([62.6082], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([62.2544], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([62.1093], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([62.0304], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([61.9685], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([61.9192], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([61.8739], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([61.8165], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([8553.7852], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([6529.1025], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([2717.8647], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([462.5687], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([272.0712], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([187.0654], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([145.6803], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([122.0017], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([108.0204], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([98.4763], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([91.5351], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([86.5098], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([82.3552], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73\n",
      " ---------------------- loss: tensor([78.7595], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([75.7169], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([72.8546], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([68.5750], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([61.0646], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([56.3912], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([52.9726], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([50.1449], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([47.3804], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([43.4535], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([40.0419], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([38.2963], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([37.3397], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([36.7734], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([36.4057], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([36.1335], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([35.3653], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([33.8318], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([32.4819], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([31.5305], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([30.6009], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([29.6928], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([28.7808], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([27.9117], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([27.1342], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([26.5430], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([26.0092], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([25.5953], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([25.1683], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([24.6695], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([23.7775], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([22.5196], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([21.5538], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([20.3396], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([19.8861], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([19.6526], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([19.4747], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([19.3085], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([19.0606], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([18.8947], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([18.7586], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([18.6315], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([18.5006], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([18.3745], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([18.2699], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([18.1830], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([18.1102], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([18.0492], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([17334.1641], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([17324.6914], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([17315.0820], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([18255.0332], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([16581.1562], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([16581.1152], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([16581.0547], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([16584.4258], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([16584.4141], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([16584.3809], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([16588.1992], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([16588.3398], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([16588.3047], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([nan], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([20175.5508], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([16580.6523], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([11010.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([7367.0400], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([4421.3916], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([1720.9376], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([998.9999], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([656.6103], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([438.6873], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([299.6400], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([219.3689], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([171.1045], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([139.9029], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([117.8011], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([100.4328], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([87.5419], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([79.4628], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([74.5806], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([71.4930], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([69.3926], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([67.8271], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([66.6431], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([65.8442], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([65.3437], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([65.0282], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([64.8187], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([64.6671], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([64.5544], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([64.4752], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([64.4234], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([64.3910], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([64.3695], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([64.3542], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([64.3420], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([64.3329], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([64.3271], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([64.3232], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([64.3210], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([64.3205], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([64.3182], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([64.3162], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([64.3142], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([64.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([64.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([64.3113], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([64.3097], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([64.3094], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([64.3058], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([64.2986], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([64.1147], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([63.9876], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([63.0810], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([95.6842], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([75.2859], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([1247.9910], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([722.1480], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([440.9833], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([300.4307], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([220.9771], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([172.4077], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([142.3260], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([121.6960], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([105.1484], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([93.1290], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([86.1750], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([82.0473], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([79.3865], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([77.5543], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([76.2183], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([75.2780], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([74.7150], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([74.3856], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([74.1704], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([74.0067], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([73.8858], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([73.8124], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([73.2430], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([72.2305], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([71.9001], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([71.5128], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([71.1309], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([70.6352], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([69.2991], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([68.0018], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([66.8953], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([65.9930], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([88.3836], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88\n",
      " ---------------------- loss: tensor([69.2899], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([67.0210], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([65.8440], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([65.1077], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([64.6080], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([64.2416], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([63.8749], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([63.6355], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([63.5020], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([63.4238], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([63.3728], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([63.2761], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([63.2612], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([63.1953], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([63.1112], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([63.0970], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([63.0687], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([63.0297], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([62.9935], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([62.9460], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([62.8774], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([62.7682], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([62.6525], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([62.5553], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([62.4530], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([62.4087], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([62.3773], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([62.3543], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([62.2942], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([62.2867], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([62.2844], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([62.2841], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([62.2836], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([62.2823], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([62.2818], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([62.2811], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([62.2811], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([62.2804], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([62.2807], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([62.2806], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([62.2800], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([62.2796], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([62.2791], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([62.2782], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([66.6462], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([66.0465], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([65.5477], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([65.1233], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([64.7559], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([64.4362], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([64.1687], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([63.9605], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([63.7907], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([63.6692], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([63.5822], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([63.5183], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([63.4789], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([63.4501], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([63.4269], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([63.4258], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([63.4203], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([63.4189], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([63.4180], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([63.4173], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([63.4157], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([63.4141], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([63.4122], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([63.4121], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([63.4115], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([63.4116], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([63.4070], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([63.4057], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([63.4033], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([63.3972], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([63.3950], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([63.3932], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([63.3869], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([63.3788], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([63.3707], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([63.3633], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([63.3551], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([63.3460], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([63.3350], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([63.2605], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([63.1957], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([63.1044], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([63.0308], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([62.9699], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([62.9171], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([62.8636], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([62.8031], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([62.7241], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([62.6553], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([62.5637], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([62.4399], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([62.2853], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([62.2369], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([62.1980], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([62.1662], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([62.1333], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([62.1064], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189\n",
      " ---------------------- loss: tensor([62.0832], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([62.0633], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([62.0457], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([62.0313], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([62.0188], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([62.0078], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([61.9984], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([61.9908], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([61.9845], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([61.9781], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([61.9721], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([61.9671], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([61.9638], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([61.9597], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([61.9562], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([61.9520], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([61.9448], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([61.9348], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([61.9209], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([61.9286], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([1406.9493], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([16587.8867], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([18560.6289], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([14575.7764], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([12167.9453], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([9961.2588], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([8023.5454], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([6286.0439], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([4726.2920], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([2605.6704], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([1821.8558], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([1425.0875], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([1160.3735], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([965.3016], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([815.9466], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([698.7957], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([599.2116], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([513.2720], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([439.9995], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([377.9309], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([326.7127], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([285.3918], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([251.4936], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([223.4194], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([200.1089], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([179.8745], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([161.4993], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([146.0421], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([133.6476], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([123.3050], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([114.8498], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([108.1639], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([102.0307], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([95.8596], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([91.1512], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([87.4249], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([83.9712], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([81.3439], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([79.3851], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([77.1997], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([75.0836], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([73.7000], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([72.3887], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([71.0805], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([70.2401], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([69.6409], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([68.7284], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([67.8914], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([67.2884], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([66.5576], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([66.1478], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([65.8800], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([65.5827], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([65.3286], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([65.1653], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([65.0403], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([64.9293], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([64.8490], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([64.7954], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([64.7596], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([64.7325], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([64.7151], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([64.6673], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([64.6070], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([64.5661], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([64.5157], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([64.4792], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([64.4585], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([64.4443], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([64.4259], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([64.3981], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([64.3687], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([64.3322], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([64.3087], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([64.2840], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([64.2405], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([64.0143], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([63.9568], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([63.8891], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([63.8018], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([63.7268], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([63.6523], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([63.5808], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([63.5084], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([63.4389], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([63.3710], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([63.3020], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([63.1112], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([63.0226], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([62.9968], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([62.9759], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([62.9566], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([62.9393], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([62.9127], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([62.8751], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([62.8493], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([62.8287], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([62.8089], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([62.7860], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98\n",
      " ---------------------- loss: tensor([62.7406], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([62.6980], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([62.6451], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([62.5942], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([62.5445], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([62.4950], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([62.4482], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([62.4038], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([69.0186], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([62.4401], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([62.3608], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([62.3199], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([62.2917], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([62.2733], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([62.2607], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([62.2530], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([62.2131], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([62.1895], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([62.1747], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([62.1539], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([62.1344], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([62.1193], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([62.1081], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([62.0961], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([62.0848], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([62.0771], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([62.0677], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([62.0655], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([62.0557], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([62.0316], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([62.0306], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([62.0268], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([62.0231], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([62.0128], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([61.9962], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([61.9784], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([61.9471], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([61.9193], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([61.8529], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([74.9439], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([74.0619], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([73.1354], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([72.1316], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([71.0000], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([69.7534], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([68.3756], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([66.9009], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([2833.4067], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([2022.7520], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([65.6422], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([65.5466], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([65.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([65.3585], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([65.2532], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([65.1591], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([65.0762], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([65.0075], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([64.9354], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([64.8535], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([64.7868], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([64.7189], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([64.6409], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([64.5835], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([64.5118], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([64.4458], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([64.4059], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([64.3646], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([64.3162], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([64.2672], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([64.2319], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([64.1903], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([64.1449], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([64.0309], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([64.0021], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([63.9775], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([63.9556], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([63.9043], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([63.8790], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([63.7737], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([63.7600], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([63.7312], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([63.6568], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([63.6496], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([63.6391], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([63.6347], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([63.6266], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([63.6221], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([63.6189], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([63.6103], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([63.5669], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([63.5535], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([63.5458], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([63.5448], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([63.5310], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([63.5002], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([63.4932], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([63.4918], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([63.4909], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([63.4858], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([63.4789], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198\n",
      " ---------------------- loss: tensor([63.4796], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([63.4743], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([63.4705], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([63.4645], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([64.6151], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([64.6153], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([64.5999], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([64.6001], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([64.5999], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([64.5999], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([64.6000], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([64.5998], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([64.5998], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([64.6000], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([64.5999], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([64.6001], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([64.6001], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([64.6002], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([64.5944], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([64.5988], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([64.5986], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([64.5900], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([64.5711], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([64.5659], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([64.5653], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([64.5573], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([64.5483], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([64.5443], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([64.4953], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([64.4858], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([64.2851], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([64.2594], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([64.2217], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([64.1935], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([64.1623], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([64.6610], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([64.2693], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([64.2070], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([64.1690], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([64.1805], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([64.1756], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([64.1521], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([64.1508], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([64.1210], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([64.0241], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([64.0217], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([64.0247], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([64.0108], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([63.9868], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([63.9670], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([63.6942], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([63.6941], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([63.6637], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([63.6487], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([63.6219], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([63.5846], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([63.5513], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([367.9726], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([347.3991], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([325.8421], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([303.3890], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([279.9943], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([255.9420], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([10275.1729], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([10269.6777], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([10264.1670], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([10258.6553], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([10253.1123], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([10247.5449], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([10241.9678], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([10236.3818], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([10230.7676], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([10225.1475], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([10219.5098], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([10213.8691], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([10208.2041], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([10202.5127], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([10196.8037], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([10191.0752], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([10185.3379], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([10179.5752], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([10173.7998], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([10168.0049], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([10162.1885], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([10156.3613], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([10150.5156], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([10144.6562], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([10138.7744], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([10132.8809], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([10126.9678], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([10121.0166], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([10115.0723], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([10109.0996], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([10103.1172], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([10097.1074], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([10091.0820], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([10085.0439], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([10078.9961], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([10072.9277], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([10066.8379], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298\n",
      " ---------------------- loss: tensor([10060.7217], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([10054.5996], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([10048.4590], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([25693.2871], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([25532.1992], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([24850.6309], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([24063.0957], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([23445.4258], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([22919.1055], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([22443.9473], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([21915.5645], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([21046.9746], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([20083.0879], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([19219.8730], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([18436.5625], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([17692.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([16885.4961], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([15867.2949], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([14758.6084], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([13720.2842], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([12766.4854], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([11841.1064], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([10836.5303], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([9703.2920], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([8569.8613], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([7558.3735], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([6705.0732], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([5993.3564], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([5369.0200], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([4667.1489], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([3569.1013], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([2458.8250], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([1842.8011], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([1455.1084], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([1189.9891], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([1003.5049], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([870.2173], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([772.4436], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([694.7061], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([631.2949], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([577.6876], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([515.9884], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([451.2672], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([400.7151], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([359.5020], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([320.9203], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([289.7102], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([266.5357], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([245.7683], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([215.8620], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([194.4659], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([174.6343], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([150.5869], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([136.6578], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([126.6086], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([116.1576], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([107.7115], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([101.5382], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([95.8141], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([90.8663], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([87.1345], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([83.8620], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([80.9245], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([78.5950], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([76.6252], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([74.8767], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([73.4039], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([72.1713], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([71.0440], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([70.0803], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([69.2641], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([68.5372], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([67.9122], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([67.3860], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([66.9277], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([66.5278], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([66.2014], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([65.9256], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([65.6802], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([65.4842], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([65.3186], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([65.1741], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([65.0595], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([64.9682], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([64.8857], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([64.8249], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([64.6880], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([64.6709], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([64.6417], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([64.6242], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([64.6032], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([64.5947], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([64.5853], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([64.5620], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([64.7771], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([64.6992], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([64.6499], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([64.6234], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([64.6114], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([64.6008], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98\n",
      " ---------------------- loss: tensor([64.5735], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([64.5207], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([64.5044], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([64.5044], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([64.5044], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([64.4969], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([64.4932], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([64.4899], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([64.4746], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([64.4713], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([64.4638], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([64.4555], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([64.4471], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([64.4417], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([64.4380], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([64.4371], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([64.4339], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([64.4313], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([64.4232], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([64.4023], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([64.4011], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([64.3990], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([64.3990], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([64.3958], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([64.3921], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([64.3837], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([64.3793], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([64.3733], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([64.3598], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([64.2293], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([64.0272], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([63.8550], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([63.7517], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([63.6474], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([63.4910], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([63.4474], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([63.4005], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([63.3647], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([63.3266], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([63.2683], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([63.2403], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([63.2223], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([63.1720], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([63.1708], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([63.1690], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([63.1640], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([63.1620], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([63.1579], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([63.1563], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([63.1373], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([63.1093], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([63.1084], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([63.1085], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([63.1088], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([63.1089], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([63.1088], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([63.1089], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([63.1089], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([63.1091], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([63.1091], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([63.1093], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([63.1093], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([63.1093], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([63.1095], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([63.1097], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([63.1096], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([63.1097], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([63.1097], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([63.1097], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([63.1097], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([63.1097], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([63.1098], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([63.1100], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([63.1101], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([63.1100], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([63.1101], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([63.1103], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([63.1104], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([63.1104], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([63.1104], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([63.1105], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([63.1106], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([63.1106], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([63.1108], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([63.1108], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([63.1110], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([63.1109], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([63.1110], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([63.1109], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([63.1111], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([63.1109], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([63.1111], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([63.1113], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([63.1113], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([63.1114], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([63.1114], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([63.1116], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([63.1116], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([63.1117], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([63.1116], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([63.1118], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([63.1117], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([63.1118], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201\n",
      " ---------------------- loss: tensor([63.1120], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([63.1120], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([63.1120], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([63.1123], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([63.1124], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([63.1124], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([63.1126], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([63.1126], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([63.1127], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([63.1128], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([63.1129], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([63.1128], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([63.1128], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([63.1128], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([63.1131], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([63.1130], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([63.1132], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([63.1132], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([63.1132], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([63.1132], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([63.1132], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([63.1132], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([63.1132], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([63.1132], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([63.1131], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([63.1133], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([63.1135], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([63.1135], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([63.1135], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([63.1135], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([63.1135], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([63.1138], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([63.1137], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([63.1137], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([63.1137], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([63.1139], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([63.1139], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([63.1140], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([63.1140], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([63.1142], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([63.1143], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([63.1143], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([63.1144], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([63.1143], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([63.1145], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([63.1145], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([63.1145], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([63.1149], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([63.1148], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([63.1148], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([63.1149], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([63.1149], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([63.1151], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([63.1151], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([63.1152], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([63.1153], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([63.1152], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([63.1154], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([63.1156], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([63.1156], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([63.1155], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([63.1158], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([63.1157], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([63.1159], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([63.1159], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([63.1161], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([63.1161], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([63.1161], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([63.1161], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([63.1162], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([63.1164], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([63.1163], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([63.1165], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([63.1166], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([63.1167], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([63.1167], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([63.1167], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([63.1167], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([63.1168], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([63.1168], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([63.1167], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([63.1168], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([63.1171], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([63.1170], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([63.1170], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([63.1171], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([63.1173], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([63.1176], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([63.1175], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([63.1176], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([63.1175], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([63.1177], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([63.1177], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([63.1177], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([63.1177], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([63.1179], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([63.1180], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([63.1182], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([63.1183], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([63.1182], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([14605.6074], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([14481.1396], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([13839.0566], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      " ---------------------- loss: tensor([13428.0742], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([13086.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([12740.0908], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([12308.5635], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([11746.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([10854.1699], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([9896.8643], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([8882.1045], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([7808.3057], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([6929.6802], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([6254.0918], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([5664.0503], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([5180.5449], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([4799.8521], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([4477.2358], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([4152.7881], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([3786.1038], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([3414.4817], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([3089.6204], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([2841.1921], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([2649.6665], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([2489.1357], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([2344.6228], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([2214.0151], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([2104.0703], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([2011.6421], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([1929.5303], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([1851.0851], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([1777.6736], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([1711.1742], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([1647.7697], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([1587.3270], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([1530.1929], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([1479.6237], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([1434.7793], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([1395.0226], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([1358.2655], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([1326.2705], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([1300.3610], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([1278.2247], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([1255.4678], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([1232.2260], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([1211.9972], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([1190.6368], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([1169.0891], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([1151.5885], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([1136.9432], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([1123.4940], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([1109.8108], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([1095.3223], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([1081.6855], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([1068.7998], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([1055.4080], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([1039.9229], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([1025.4193], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([1013.4006], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([1001.3792], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([979.2125], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([942.9474], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([909.0587], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([865.2297], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([834.4640], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([813.2390], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([794.9250], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([778.0005], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([764.0566], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([744.6860], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([714.9713], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([685.9485], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([662.1597], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([646.9166], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([635.8323], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([627.2216], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([618.1479], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([605.6273], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([587.9020], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([570.9566], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([554.9148], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([543.5065], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([536.4732], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([530.9483], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([526.2506], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([518.6259], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([497.1967], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([466.1783], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([453.8501], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([442.5247], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([434.3892], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([428.1127], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([421.2502], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([414.1539], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([406.7340], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([395.3009], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([383.1248], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([374.6757], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([368.1422], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([362.5843], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([357.6267], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([352.3110], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([341.4540], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([331.9716], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([319.1850], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106\n",
      " ---------------------- loss: tensor([311.0168], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([303.9370], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([297.4789], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([291.2480], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([282.8836], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([272.7797], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([265.3907], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([256.9544], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([248.3925], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([240.9432], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([230.9650], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([220.8261], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([210.4877], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([201.2839], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([195.1656], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([189.6452], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([184.9188], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([179.1873], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([170.9846], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([164.5183], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([158.8242], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([151.3260], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([147.1925], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([143.5993], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([140.7244], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([138.4064], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([136.3059], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([134.2220], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([131.8268], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([128.8635], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([124.0240], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([119.9812], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([116.8210], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([114.1044], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([110.9688], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([107.1154], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([104.0151], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([101.5596], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([99.4512], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([97.8016], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([96.4567], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([95.1106], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([93.9245], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([92.7907], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([91.4417], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([89.8136], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([88.1388], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([86.3502], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([84.4987], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([82.8141], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([81.3268], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([79.7678], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([77.7744], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([75.3818], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([72.2137], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([69.1464], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([66.6359], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([57.9172], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([53.7329], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([50.5161], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([47.6936], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([46.2377], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([45.2352], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([43.9562], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([42.7832], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([41.9450], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([41.2649], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([40.6547], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([40.0960], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([39.5510], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([39.0376], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([38.5819], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([38.1850], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([37.8321], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([37.4927], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([37.1400], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([36.7951], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([36.4758], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([36.1849], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([35.9170], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([35.6478], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([35.3410], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([35.0381], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([34.7966], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([34.6039], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([34.4300], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([34.2281], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([34.0402], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([33.7918], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([33.5754], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([33.4287], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([33.3183], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([33.2259], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([33.1456], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([33.0674], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([32.9187], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([32.7812], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([32.6538], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([32.4396], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([32.2993], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([32.2024], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([32.1272], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208\n",
      " ---------------------- loss: tensor([32.0654], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([32.0104], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([31.7995], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([31.6818], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([31.6031], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([31.5492], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([31.5081], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([30.9703], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([30.9498], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([30.8969], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([28.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([27.5592], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([27.0119], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([26.4951], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([25.9264], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([25.3933], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([24.7532], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([24.0561], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([23.5189], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([23.1178], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([22.8135], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([22.5432], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([22.2054], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([21.8661], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([21.5256], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([21.1942], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([20.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([20.5863], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([20.2951], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([20.0286], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([19.7481], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([19.3639], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([19.0000], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([18.6546], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([18.3327], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([18.1188], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([17.9195], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([17.7230], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([17.4979], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([17.2377], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([17.0307], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([16.8341], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([16.6521], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([16.4028], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([15.4340], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([14.2601], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([13.9298], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([13.7101], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([13.4835], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([13.3768], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([13.2722], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([13.1783], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([13.0874], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([12.9661], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([12.8835], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([12.2276], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([12.1086], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([12.0057], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([11.9842], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([11.9542], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([11.7884], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([11.7825], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([11.7632], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([11.7584], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([11.7350], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([11.7296], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([11.7243], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([11.7013], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([11.6854], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([11.6792], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([11.6468], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([11.6391], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([11.6239], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([11.6150], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([11.4913], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([11.4669], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([11.1113], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([11.1106], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([10.9837], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([10.9821], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([10.9807], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([10.9786], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([10.9720], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([1300.9869], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([874.0394], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([852.6818], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([831.2143], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([809.5947], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([787.9041], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([766.2277], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([4279.5425], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([4173.3833], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([4064.0593], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upper_r = 6\n",
    "lower_r = 1e-2\n",
    "steps = 100\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "epochs = 300\n",
    "lrs = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "Phis_t = []\n",
    "Es = []\n",
    "\n",
    "for lr in lrs:\n",
    "    model = NeuralNetwork().to(device)\n",
    "    initialize_weights(model)\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n ---------------------- loss: {loss_fn(R_train.to(device))}\")\n",
    "        training(R_train, loss_fn, optimizer)\n",
    "    print(\"Done!\\n\\n\")\n",
    "    Phis_t.append(Phi_t(R_train).detach().numpy())\n",
    "    Es.append(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d87e2420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAJZCAYAAADxmft+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAB+k0lEQVR4nO39e5xcZZXo/39WbkYEJQZUIIQQg4hAAqQhrSIDghAZDjiIgjIDKphBcbydmUEH0Rk95/XTg+MwCMiJwFG+kyMjKJfjoAIjHHUkQJoT7peEaKQBBWJQLqNJp9fvj6qOTac6qU5X1d5V9Xm/Xv1K1a6ndq3d6V6917Of/TyRmUiSJEmSus+EogOQJEmSJBXDglCSJEmSupQFoSRJkiR1KQtCSZIkSepSFoSSJEmS1KUsCCVJkiSpS3VEQRgRl0XEkxFxbx1tD4mIOyNiICJOGPHaqRGxovp1avMiltQtxpifzoiIeyJieUT8NCLe0IoYJXWfseSmOva1X0TcGhH3RcTdEXFiI2KU1BrRCesQRsQhwHPA5Zm5zxbazgJeDvw1cF1mXlXd/kpgGdADJNAHzM/MtU0MXVKHG2N+enlm/q76+Fjgw5m5sAVhSuoyY8lNdezrdUBm5oqI2JnKOdRemfnM+COV1GwdcYUwM38M/Gb4toh4bUT8ICL6IuInEfH6attfZObdwOCI3RwF3JiZv6kWgTcCnohJGpcx5qffDWv2MiqdU5LUcGPJTXXs6+HMXFF9/DjwJLBjw4OW1BSTig6giRYDZ1R7qxYAFwFv3Uz7XYBHhz3vr26TpEYbNT9FxJnAJ4EpbD5nSVKjjfXcaRMRcRCV/PVIE+KT1AQdWRBGxLbAm4ArI2Jo80u29LYa2+ydl9RQW8pPmXkhcGFEvBf4DOD9zJKabnO5KSKOBz5f422PZeZRw/axE/D/Aadm5siRWJJKqiMLQipDYZ/JzP3G8J5+4NBhz2cAtzQuJEkC6s9PVwBfa344kgRsJjdl5neB727uzRHxcuDfgM9k5tKmRCipKTriHsKRqvfh/Dwi3gUQFfO28LYfAkdGxLSImAYcWd0mSQ2zufwUEXsMa/qnwIoCQpTUhbby3Ilq2ynA1VQmqLmyiWFKaoKOKAgj4lvArcCeEdEfEacBJwOnRcRdwH3AcdW2B0ZEP/Au4H9GxH0Amfkb4AvAHdWvz1e3SdJWG0t+Aj5SnbZ9OZX7CB0uKqkpxpibtuTdwCHA+6rL5iyPiP2aEbekxuuIZSckSZIkSWPXEVcIJUmSJEljZ0EoSZIkSV2q7WcZ3WGHHXLWrFlFhyGpgfr6+p7OzLZf1Nj8JHWeTshP5iap84wnN7V9QThr1iyWLVtWdBiSGigiVhcdQyOYn6TO0wn5ydwkdZ7x5CaHjEqSJElSl2pZQRgRUyPi9oi4qzqt+j/UaBMRcX5ErIyIuyPigFbFJ0mSJEndppVDRv8AvDUzn4uIycBPI+L7mbl0WJu3A3tUvxYAX6v+K0mSJElqsJYVhFlZ8PC56tPJ1a+RiyAeB1xebbs0IraPiJ0y84lWxTmavtVrWbpqDb2zpzN/t2lFh9N11q9fT39/P7///e+LDkUNNHXqVGbMmMHkyZOLDqW0zD3lYA7qPuYntQNzU/dpRm5q6aQyETER6APmABdm5m0jmuwCPDrseX91W6EFYd/qtZx8yVLWDQwyZdIElpze64lZi/X397Pddtsxa9YsIqLocNQAmcmaNWvo7+9n9913LzqcUhkqAqdtM4XPf+8+c08JmIO6i/lJ7cLc1F2alZtaOqlMZm7IzP2AGcBBEbHPiCa1fpJHXkUkIhZFxLKIWPbUU081IdIXW7pqDesGBhlMWD8wyNJVa5r+mXqx3//+90yfPt1k10EigunTp9urOcJQB9Q/3vAQn732XnNPSZiDuov5Se3C3NRdmpWbCpllNDOfAW4BFo54qR/YddjzGcDjNd6/ODN7MrNnxx2bvxRQ7+zpTJk0gYkBkydNoHf29KZ/pjZlsus8Zfk/jYjLIuLJiLh3lNdbNuHV8A6owcFkQoS5pyTK8vOq1vD/W+3Cn9Xu0oz/71bOMrpjRGxfffxS4AjgwRHNrgNOqZ589QK/LcP9g/N3m8aS03v55JF7OmSri2277bZN/4yLL76Yyy+/vOmfM9w111zD/fffP6b3ZCYf/ehHmTNnDnPnzuXOO++s2e6CCy5gzpw5RARPP/10I8Jtlm+waQfVcMMnvFpEZcKrphjeATVl8gQ+f9w+5h4B5qDh6s1BP//5z1mwYAF77LEHJ554IuvWrQPglltu4RWveAX77bcf++23H5///OfHfRxStzI3/dF4c9ODDz7IG9/4Rl7ykpfw5S9/edzHUK9WXiHcCbg5Iu4G7gBuzMzvRcQZEXFGtc31wCpgJfB14MMtjG+z5u82jTMPm+MJmcZtw4YNo752xhlncMopp7T0M7cm4X3/+99nxYoVrFixgsWLF/OhD32oZrs3v/nN3HTTTey2225j2n+rZeaPgd9spsnGCa+qMyNvHxE7NSOWkR1Q710w09yjhuqmHHTWWWfxiU98ghUrVjBt2jQuvfTSja+95S1vYfny5SxfvpzPfvazY/p8SY1nboJXvvKVnH/++fz1X//1mD53vFpWEGbm3Zm5f2bOzcx9MvPz1e0XZ+bF1ceZmWdm5mszc9/MXNaq+KSxOPfccznwwAOZO3cun/vc5zZuf8c73sH8+fPZe++9Wbx48cbt2267LZ/97GdZsGABt956K9tuuy1nn3028+bNo7e3l1//+tcA/P3f//3GHqFDDz2Us846i4MOOojXve51/OQnPwHghRde4N3vfjdz587lxBNPZMGCBSxbtumvyqxZs/j85z/PwQcfzJVXXsnXv/51DjzwQObNm8c73/lOXnjhBX72s59x3XXX8Td/8zfst99+PPLIIzzyyCMsXLiQ+fPn85a3vIUHHxx5IR+uvfZaTjnlFCKC3t5ennnmGZ54YtOL+fvvvz+zZs0a1/e6JEab8Kop7IDSlpiDtpyDMpMf/ehHnHDCCQCceuqpXHPNNeP7xkvaLHPT+HLTq171Kg488MCWz25cyD2EUiv0rV7LhTevpG/12obu94YbbmDFihXcfvvtLF++nL6+Pn784x8DcNlll9HX18eyZcs4//zzWbOmMgnI888/zz777MNtt93GwQcfzPPPP09vby933XUXhxxyCF//+tdrftbAwAC333475513Hv/wD/8AwEUXXcS0adO4++67Oeecc+jr6xs11qlTp/LTn/6Uk046ieOPP5477riDu+66i7322otLL72UN73pTRx77LGce+65LF++nNe+9rUsWrSIr371q/T19fHlL3+ZD3940wv1jz32GLvu+sfbfWfMmMFjjz221d/TNlDXhFfQ+kmvVF7moGJz0Jo1a9h+++2ZNGlSzTa33nor8+bN4+1vfzv33XdfPd96qSOYm8qdm4rQ0mUnpFZp5lIhN9xwAzfccAP7778/AM899xwrVqzgkEMO4fzzz+fqq68G4NFHH2XFihVMnz6diRMn8s53vnPjPqZMmcIxxxwDwPz587nxxhtrftbxxx+/sc0vfvELAH7605/ysY99DIB99tmHuXPnjhrriSeeuPHxvffey2c+8xmeeeYZnnvuOY466qhN2j/33HP87Gc/413vetfGbX/4wx82aVdZKvTFOvym9romvILKpFfAYoCenp6aRaM6nzmoosgctLk2BxxwAKtXr2bbbbfl+uuv5x3veAcrVqwY9TikTmFuqihrbiqKBaE6Uq2lQhqV8DKTT3/60/zlX/7li7bfcsst3HTTTdx6661ss802HHrooRunBZ46dSoTJ07c2Hby5Mkbf/knTpzIwMBAzc96yUteskmbWolkNC972cs2Pn7f+97HNddcw7x58/jGN77BLbfcskn7wcFBtt9+e5YvX77Z/c6YMYNHH/3jCMr+/n523nnnuuNqQ9cBH4mIK4AFlGTCK5WXOaiiyBy0ww478MwzzzAwMMCkSZNe1OblL3/5xnZHH300H/7wh3n66afZYYcd6j42qR2ZmyrKmpuK4pBRdaRmLhVy1FFHcdlll/Hcc88BleEBTz75JL/97W+ZNm0a22yzDQ8++CBLly5t2GcOd/DBB/Ptb38bgPvvv5977rmnrvc9++yz7LTTTqxfv54lS5Zs3L7ddtvx7LPPApWTpN13350rr7wSqCTXu+66a5N9HXvssVx++eVkJkuXLuUVr3gFO+3UlDlWWiIivgXcCuwZEf0RcVq7THilcjIHbarVOSgiOOyww7jqqqsA+OY3v8lxxx0HwK9+9auNJ4+33347g4ODTJ/usi7qfOamTZUpNxXFglAdqZlLhRx55JG8973v5Y1vfCP77rsvJ5xwAs8++ywLFy5kYGCAuXPncs4559Db29uwzxzuwx/+ME899RRz587lS1/6EnPnzuUVr3jFFt/3hS98gQULFvC2t72N17/+9Ru3n3TSSZx77rnsv//+PPLIIyxZsoRLL72UefPmsffee3Pttddusq+jjz6a2bNnM2fOHD74wQ9y0UUXvei1xx+vjKY8//zzmTFjBv39/cydO5fTTz+9Ad+BxsvM92TmTpk5OTNnZOalTnil8TAHbaqIHPSlL32Jr3zlK8yZM4c1a9Zw2mmnAXDVVVexzz77MG/ePD760Y9yxRVXFD5kS2oFc9OmypSbfvWrXzFjxgy+8pWv8N/+239jxowZ/O53vxvvt2aLYiyXV8uop6cna80gpM7ywAMPsNdeexUdRils2LCB9evXM3XqVB555BEOP/xwHn74YaZMmVJ0aFul1v9tRPRlZk9BITWM+alzmIP+qNNy0OZ0an4yN3UOc9MfmZu2Pjd5D6HUZl544QUOO+ww1q9fT2byta99rSOTnV6sb/Valq5aQ+/s6S5HoUKZg8opIiYCy4DHMvOYouORWs3ctPUsCKU2s91229VcV0edq5mzwkljZQ4qrY8BDwAv31JDqROZm7ae9xCOUbPWbpGk0dSaFU6ShkTEDOBPgUuKjkVS+/EK4RjYS1+szPSm/w7T7vcwt8rQrHDrBwYbPiuc6mcO6i5tlp/OA/4W2K7gOFQAc1N3aUZu8grhGNhLX5ypU6eyZs2advsDrc3ITNasWcPUqVOLDqX0mjkrnOpjDuou7ZSfIuIY4MnM7NtCu0URsSwilj311FMtik7NZm7qLs3KTV4hHAN76YsztHSBf8Q6y9SpU5kxY0bRYbSF+btNsxAskDmo+7RRfnozcGxEHA1MBV4eEf+SmX8+vFFmLgYWQ2WW0daHqWYwN3WfZuQmC8IxGOqld6a/1ps8eTK777570WFI6lLmIJVVZn4a+DRARBwK/PXIYlCdy9ykRrAgHCN76SVJkiR1ipbdQxgRu0bEzRHxQETcFxEfq9Hm0Ij4bUQsr359tlXxSVI7cKZjSaPJzFtcg1DSWLXyCuEA8F8z886I2A7oi4gbM/P+Ee1+YjKTpE0507EkSWq0ll0hzMwnMvPO6uNnqSyeukurPl+S2p0zHUuSpEYrZNmJiJgF7A/cVuPlN0bEXRHx/YjYu7WRSVJ5Dc10PDFwpmNJktQQLZ9UJiK2Bb4DfDwzfzfi5TuB3TLzuer0ydcAe9TYxyJgEcDMmTObG7AklYQzHUuSpEZraUEYEZOpFINLMvO7I18fXiBm5vURcVFE7JCZT49o51o6krqSMx1LkqRGauUsowFcCjyQmV8Zpc1rqu2IiIOq8XmTjCRJkiQ1QSuvEL4Z+AvgnohYXt32d8BMgMy8GDgB+FBEDAD/CZyUmV4BlCRJkqQmaFlBmJk/BWILbS4ALmhNRJIkSZLU3QqZZbRTuEC0JEmSpHZmQbiVhhaI/scbHuLkS5ZaFEptLCIWRsRDEbEyIj5V4/VXRMT/qS6Jc19EvL+IOIezQ0qSJDVCy5ed6BS1Foh25j+p/UTEROBC4G1AP3BHRFyXmfcPa3YmcH9m/peI2BF4KCKWZOa6AkLe2CG1bmCQKZMmsOT0XvOPJEnaKl4h3EouEC11jIOAlZm5qlrgXQEcN6JNAttVZ0HeFvgNMNDaMP+oVoeUJEnS1vAK4VZygWipY+wCPDrseT+wYESbC4DrgMeB7YATM3OwNeFtaqhDav3AoB1SkiRpXCwIx8EFoqWOUGv245HL3RwFLAfeCrwWuDEifpKZv9tkZxGLgEUAM2fObGykVXZISZKkRrEglNTt+oFdhz2fQeVK4HDvB75YXRd1ZUT8HHg9cPvInWXmYmAxQE9PT9PWUbVDSpIkNYL3EErqdncAe0TE7hExBTiJyvDQ4X4JHA4QEa8G9gRWtTRKSZKkJvAKoaSulpkDEfER4IfAROCyzLwvIs6ovn4x8AXgGxFxD5Uhpmdl5tOFBS1JktQgFoRN0rd6rff3SG0iM68Hrh+x7eJhjx8Hjmx1XJIkSc1mQdgErhEmSZIkqR14D2ETuEaYJEmSpHZgQdgELlovqZX6Vq/lwptX0rd6bdGhSGqxiNg1Im6OiAci4r6I+FjRMUlqLw4ZbQLXCJPUKg5Rl7reAPBfM/POiNgO6IuIGzPz/qIDk9QeWnaFsJ4erKg4PyJWRsTdEXFAq+Ibj1q98/N3m8aZh83xxExSUzlEXepumflEZt5Zffws8ACwS7FRSWonrbxCWE8P1tuBPapfC4CvVf8tLXvnJRVpaIj6+oFBh6hLXS4iZgH7A7cVHIqkNtKygjAznwCeqD5+NiKGerCGF4THAZdnZgJLI2L7iNip+t5SqtU7b0EoqVUcoi4JICK2Bb4DfDwzf1fj9UXAIoCZM2e2ODpJZVbIPYSb6cHaBXh02PP+6rbSFoT2zksq2vzdplkISl0sIiZTKQaXZOZ3a7XJzMXAYoCenp5sYXiSSq7lBeEWerCixls2SVpl6uWyd16SJBUlIgK4FHggM79SdDyS2k9LC8I6erD6gV2HPZ8BPD6yUdl6ueydlyRJBXkz8BfAPRGxvLrt7zLz+uJCktROWlYQ1tmDdR3wkYi4gspkMr8t8/2DkiRJRcrMn1J7hJUk1aWVVwhr9mABMwEy82LgeuBoYCXwAvD+FsYnSZIkSV2llbOMbrEHqzq76JmtiUiSJEmSulvLFqaXJDVX3+q1XHjzSvpWry06FEmS1CYKWXZCktRYfavXcvIlS1k3MMiUSRNYcnqvk11JkqQt8gqhJHWApavWsG5gkMGE9QODLF21puiQJElSG7AglKQO0Dt7OlMmTWBiwORJE+idPb3okCRJUhtwyKgkdYD5u01jyem9LF21ht7Z0x0uKkmS6mJB2EB9q9d6MiZpzBqVO+bvNs3cI0mSxsSCsEGc0EFqXxGxEPhnYCJwSWZ+sUabQ4HzgMnA05n5J434bHOHJEkqkvcQNogTOkjtKSImAhcCbwfeALwnIt4wos32wEXAsZm5N/CuRn2+uUOSJBXJgrBBnNBBalsHASszc1VmrgOuAI4b0ea9wHcz85cAmflkoz7c3CFJkorkkNEGcUIHqW3tAjw67Hk/sGBEm9cBkyPiFmA74J8z8/JGfLi5Q5IkFcmCsIGc0EFqS1FjW454PgmYDxwOvBS4NSKWZubDm+wsYhGwCGDmzJl1BWDukCRJRXHIqKRu1w/sOuz5DODxGm1+kJnPZ+bTwI+BebV2lpmLM7MnM3t23HHHpgS8JX2r13LhzSvpW722kM+XJEntwyuEkrrdHcAeEbE78BhwEpV7Boe7FrggIiYBU6gMKf2nlkZZJ2ctlSRJYzHmK4QR8bLqrHySVCpbk58ycwD4CPBD4AHg25l5X0ScERFnVNs8APwAuBu4ncrSFPc2NvrGcNZSqZw8f5JUVlu8QhgRE6j0mJ8MHAj8AXhJRDwFXA8szswVdeznMuAY4MnM3KfG64dS6YX/eXXTdzPz8/UdhqRu1Kj8lJnXV9sP33bxiOfnAuc2KPSmGZq1dP3AoLOWSgVqVH6SpGarZ8jozcBNwKeBezNzECAiXgkcBnwxIq7OzH/Zwn6+AVwAbG5mvp9k5jF1xCRJ0Lj81DGctVQqDfOTpLZQT0F4RGauH7kxM38DfAf4TkRM3tJOMvPHETFr7CFK0qgakp86jbOWSqVgfpLUFrZ4D+FQMouI8yKi1vTs1Ep4W+mNEXFXRHw/IvZu0D4ldagW5ydJqpv5SVK7GMukMs8B10XEywAi4siI+I8GxnInsFtmzgO+ClwzWsOIWBQRyyJi2VNPPdXAECS1qWbnJ0naWk3PTxGxMCIeioiVEfGpRu5bUuere9mJzPxMRLwXuCUi/gA8DzQs6WTm74Y9vj4iLoqIHaprfo1suxhYDNDT0zNyAWlJXabZ+UmStlaz81N15tILgbdRWTP1joi4LjPvb9RnSOpsdReEEXE48EEqiWwn4LTMfKhRgUTEa4BfZ2ZGxEFUrl46X7qkLWp2fpKkrdWC/HQQsDIzV1U/7wrgOMCCUFJdxjJk9GzgnMw8FDgB+NeIeGu9b46IbwG3AntGRH9EnDZ8na/qPu+NiLuA84GTMtOrf5LqMa78JElN1Oz8tAvw6LDn/dVtklSXsQwZfeuwx/dExNupzJL1pjrf/54tvH4BlWUpJGlMxpufOlXf6rUuPyEVrAX5qdaENZt0qEfEImARwMyZMxv00ZI6QT0L00etK3WZ+UR1GMSobSSpmTotPzWygOtbvZaTL1nKuoFBpkyawJLTey0KpRZqYX7qB3Yd9nwG8HiNz3X+BUk11TNk9OaI+KuIeFF3UkRMobJMxDeBU5sSnSRtXsfkp6EC7h9veIiTL1lK3+q149rf0lVrWDcwyGDC+oFBlq7ylmypxVqVn+4A9oiI3av7Pgm4rgH7ldQl6hkyuhD4APCtiJgNrAVeSqWYvAH4p8xc3rQIJWl0HZOfahVw47mi1zt7OlMmTWD9wCCTJ02gd/b0BkYrqQ4tyU+ZORARHwF+CEwELsvM+8a7X0ndY4sFYWb+HrgIuCgitgO2A17IzGeaHJskbVYn5adGF3Dzd5vGktN7vYdQKkgr81NmXg9c3+j9SuoOY1l24qPA54D/BJ6NiAsy88KmRSZJdeqE/NSMAm7+btMsBKWCdUJ+ktTZtngPYUScFxGnAB8H9srMGcAhwN4R8YUmxydJo+q0/DR/t2mcedgcizipA3RafpLUueqZVOb/AnOAHYCfRcSdwLnAI8BJEbF988KTpM0yP0kqK/OTpLZQzz2EVwNXR0Qv8AngCWAeMBd4JXBLRGybmXOaGqkkjWB+klRW5idJ7aLuewiBM4FvA8uBe4C9gHsy89DqNMeSVBTzk6SyMj9JKrV6howCkJkrgAXAVVSmTb4b+LPqa+uaEp0k1cH8tGV9q9dy4c0rx72+oaSxMT9JKruxXCEcSlz/Vv2SpNIwP41uaNH7dQODTJk0gSWn9zpxjdRC5idJZVb3FUJJ6lQRsTAiHoqIlRHxqc20OzAiNkTECa2Mb7xqLXovSZIEFoSSulxETAQuBN4OvAF4T0S8YZR2XwJ+2NoIx29o0fuJQUMWvZckSZ1jTENGJakDHQSszMxVABFxBXAccP+Idn8FfAc4sLXhjV8zFr2XJEmdoWUFYURcBhwDPJmZ+9R4PYB/Bo4GXgDel5l3tio+SV1rF+DRYc/7qUwAsVFE7EJlEoi30oYFIVSKQgtBSZI0UiuHjH4DWLiZ198O7FH9WgR8rQUxSVLU2JYjnp8HnJWZG7a4s4hFEbEsIpY99dRTjYhPkiSpaVpWEGbmj4HfbKbJccDlWbEU2D4idmpNdJK6WD+w67DnM4DHR7TpAa6IiF8AJwAXRcQ7au0sMxdnZk9m9uy4445NCFeSJKlxynQPYa1hW7sATxQTjqQucQewR0TsDjwGnAS8d3iDzNx96HFEfAP4XmZe08IYJUmSmqJMBWE9w7YqDSMWURlWysyZM5sZk6QOl5kDEfERKrOHTgQuy8z7IuKM6usXFxqgJElSE5WpIKxn2BZQGZIFLAbo6empWTRKUr0y83rg+hHbahaCmfm+VsTULH2r1zrbqCRJ2qhMBeF1wEeqU74vAH6bmQ4XlaQG6Vu9lpMvWcq6gUGmTJrAktN7LQolSepyrVx24lvAocAOEdEPfA6YDBt74q+nsuTESirLTry/VbFJUjdYumoN6wYGGUxYPzDI0lVrLAglSepyLSsIM/M9W3g9gTNbFI4kdZ3e2dOZMmkC6wcGmTxpAr2zpxcdkiRJKliZhoxKkppo/m7TWHJ6r/cQSpKkjSwIJamLzN9tmoWg1CEi4lzgvwDrgEeA92fmM4UGJanttGxhekmSJDXUjcA+mTkXeBj4dMHxSGpDFoSSJEltKDNvyMyB6tOlVJbskqQxsSCUpC7Ut3otF968kr7Va4sORVJjfAD4ftFBSGo/3kMoSV3G9Qil9hERNwGvqfHS2Zl5bbXN2cAAsGQz+1kELAKYOXNmEyKV1K4sCCWpy7geodQ+MvOIzb0eEacCxwCHV5fwGm0/i4HFAD09PaO2k9R9LAglqcu4HqHUGSJiIXAW8CeZ+ULR8UhqTxaEktRlXI9Q6hgXAC8BbowIgKWZeUaxIUlqNxaEktSFXI9Qan+ZOafoGCS1P2cZlSRJkqQuZUEoSZIkSV3KglCSupjrEUqS1N28h1CSupTrEUqSJK8QSlKXqrUeoSRJ6i4tLQgjYmFEPBQRKyPiUzVePzQifhsRy6tfn21lfJLUTYbWI5wYuB6hJEldqmVDRiNiInAh8DagH7gjIq7LzPtHNP1JZh7TqrgkqVu5HqEkSWrlFcKDgJWZuSoz1wFXAMe18PMlqaY6Ri+cHBF3V79+FhHzioizGebvNo0zD5tjMShJUpdqZUG4C/DosOf91W0jvTEi7oqI70fE3q0JTVK3GjZ64e3AG4D3RMQbRjT7OfAnmTkX+AKwuLVRSpIkNUcrC8KosS1HPL8T2C0z5wFfBa6puaOIRRGxLCKWPfXUU42NUlK32eLohcz8WWYOrcuwFJjR4hhbwiUoJEnqPq0sCPuBXYc9nwE8PrxBZv4uM5+rPr4emBwRO4zcUWYuzsyezOzZcccdmxmzpM5X7+iFIacB329qRAUYWoLiH294iJMvWWpRKElSl2hlQXgHsEdE7B4RU4CTgOuGN4iI10REVB8fVI3PedAlNVM9oxcqDSMOo1IQnjXqztp0BINLUEiS1J1aNstoZg5ExEeAHwITgcsy876IOKP6+sXACcCHImIA+E/gpMyseWImSQ2yxdELABExF7gEeHtmjlotZeZiqvcY9vT0tE3+GlqCYv3AoEtQSJLURVpWEMLGYaDXj9h28bDHFwAXtDImSV1v4+gF4DEqoxfeO7xBRMwEvgv8RWY+3PoQm88lKCRJ6k4tXZheksomMweAodELDwDfHhq9MDSCAfgsMB24KCKWR8SygsJtqqElKAAnl5EkqUu09AqhJJVRHaMXTgdOb3VcRRiaXGbdwCBTJk1gyem9Xi2UJKmDeYVQkrSRk8tIktRdLAglSRsNTS4zMXByGUmSuoBDRiVJGzm5jCRJ3cUrhJKkF3FyGUmSuodXCCVJm3ByGal9RMRfA+cCO2bm00XHI6m9eIVQkrQJJ5eR2kNE7Aq8Dfhl0bFIak8WhJKkTTi5jNQ2/gn4WyCLDkRSe3LIqCRpE8Mnl5m2zZSNVwgdNiqVR0QcCzyWmXdFRNHhSGpTFoSSpJqGij/vJZSKExE3Aa+p8dLZwN8BR9a5n0XAIoCZM2c2LD5J7c+CUJI0qlr3EloQSq2TmUfU2h4R+wK7A0NXB2cAd0bEQZn5qxr7WQwsBujp6XF4qaSNuqYg7Fu9duO6WsDGYVBrX1jnWluSNIqhewnXDwx6L6FUIpl5D/CqoecR8Qugx1lGJY1VVxSEw6dPnzQhIIL1A4MkMCFg0oTgXT27svfOr9hYIIJFoySNXKgeKmsTmhMlSeoMLS0II2Ih8M/AROCSzPziiNej+vrRwAvA+zLzzvF+7ouGPG1IIDdOxTWYsG5DsuS2ymzNQwXiyKLRe2ckdav5u01j/m7TXJtQKrHMnFV0DJLaU8uWnYiIicCFwNuBNwDviYg3jGj2dmCP6tci4GuN+OwXTZ8+MZg8acLGAx85J9dQ0ThUDG7c5jpckrrc8M61desHOe+mh+lbvbbosCRJ0ji08grhQcDKzFwFEBFXAMcB9w9rcxxweWYmsDQito+InTLzifF8cK0hT0PDQe99/Ldc1dfPwMAgg7z4CuHwbWW+d2bo/sih4a0j/601BHYsbcb7/rK1KUsc3XjMDjNsb0Oda+vWV3Ljf6x8mjt+8RuvFEqS1MZaWRDuAjw67Hk/sKCONrsA4yoI4Y9DnoY/H/LOA2Zscr8glOsews0VfZ//3n38YX3limbAi/6tNQR2LG3G+/6ytSlLHN14zA69bn9DnWvn3fQw/7Hy6RddKfz4Ea/z/1WSpDbUyoKw1oqpI6c9rqdNw9fSGVksDt9ehJEzon7nzn6u6uuveYI9IYLB/OM9kSP/rXXf5FjajPf9ZWtTlji68ZhdtqAzzN9tGh8/4nXc8YvfeKVQkqQO0MqCsB/YddjzGcDjW9Gm49bSGX71b+MQ1g2bzog6ZPgJNplMmBCQySCbv2IzNAR2LG3G+/6ytSlLHN14zGUfeq361bpSuH5gkO/c2b+xM8vCUJKk9tDKgvAOYI+I2B14DDgJeO+INtcBH6neX7gA+O147x8sm3qv/sGmV1qGjByC99lj9q55L1en3X/m8bT/MVsodI7hVwrXDwwycUK8qDPrXT27cvwBM/z/liSp5KIyf0uLPiziaOA8KstOXJaZ/z0izgDIzIury05cACyksuzE+zNz2eb22dPTk8uWbbZJaWxuPcSRgsqMqESwYUPlZGv4WomeYKuTRURfZva08POasiROO+WnrTXUyfX4M//Jt27/ZWXkAn/MYSPXeDVfqd21Oj81QzfkJqnbjCc3tXQdwsy8Hrh+xLaLhz1O4MxWxtQqfavXct5ND4+6HuKQoSF3Q73rgEOwpCYatiTO26gMW78jIq7LzOEzIA9fEmcBlSVxRk6K1ZWGr1H4nTv7N05wlWy6xuvmRjSY4yRJKkZLC8JuNHSSNHxY6PD7rGpd/Rt5YuRJktRUhS2J00mG7iscme+GDM1I+tlr72XDYNa893RkR1jRw5vLEIfH07rjsVNCUreyIGyioSGiQz3mABOAN8/ZgY8f8TrAP0JSCRS6JE4nGbpa+M4DZmwsDIev5zrarMiDWbma+L9v+yVXLnu0FEuklGGpFo+ndcczsGHQZXEkdS0LwiZaumoN64b1kgcwZfKEF63X5R8eqXBRY1utuZy21KbSsMHL4rSj4YXhyKszn//efRuXqxh5gp6UaImUEsTh8bT2eFwWR1K3siBsot7Z05kyacLGGficdU8qpYYtiQN03LI441Frjdc9X7PdJkXi0HI7Q0Poy7BEShmWavF4Wnc8GzYMuiyOpK5lQdhEQ/fUOCxUKjWXxGmhWkUisPFqYiffo+bxlPt4/DstqVu1dNmJZnDqZKnzFLDsRMOXxAHzk9SJXHZCUhm1zbITklRG3bwkjiRJ6m4Tig5AkiRJklQMC0JJkiRJ6lJtfw9hRDwFrK6z+Q7A000MZ2uUMSYoZ1zGVL8yxjWWmHbLzB2bGUwrjCE/lfH/C8oZVxljgnLGZUz166r8NMZzp2Yq68/DaNotXjDmVilDzFudm9q+IByLiFhWthvByxgTlDMuY6pfGeMqY0xlUdbvTRnjKmNMUM64jKl+ZY2r07Xb973d4gVjbpV2jHk4h4xKkiRJUpeyIJQkSZKkLtVtBeHiogOooYwxQTnjMqb6lTGuMsZUFmX93pQxrjLGBOWMy5jqV9a4Ol27fd/bLV4w5lZpx5g36qp7CCVJkiRJf9RtVwglSZIkSVVdURBGxMKIeCgiVkbEp4qOByAiLouIJyPi3qJjGRIRu0bEzRHxQETcFxEfKzomgIiYGhG3R8Rd1bj+oeiYhkTExIj4fxHxvaJjAYiIX0TEPRGxPCKWFR3PkIjYPiKuiogHqz9fbyw6prIwP9WnjPnJ3DQ2ZcxP5qbmiohXRsSNEbGi+u+0UdptNg9GxF9HREbEDmWPOSLOrf483R0RV0fE9k2MdUvft4iI86uv3x0RB9T73jLFW2T+H8/3uPp66XJxTZnZ0V/AROARYDYwBbgLeEMJ4joEOAC4t+hYhsW0E3BA9fF2wMMl+V4FsG318WTgNqC36Liq8XwS+N/A94qOpRrPL4Adio6jRlzfBE6vPp4CbF90TGX4Mj+NKabS5Sdz05hjKl1+Mjc1/fv7P4BPVR9/CvhSjTabzYPArsAPqayb2PSfn/HGDBwJTKo+/lKt9zcozi3+/QCOBr5fzVW9wG31vrdk8RaS/8cT87DXS5eLa311wxXCg4CVmbkqM9cBVwDHFRwTmflj4DdFxzFcZj6RmXdWHz8LPADsUmxUkBXPVZ9Orn4VfvNrRMwA/hS4pOhYyiwiXk6lwLgUIDPXZeYzhQZVHuanOpUxP5mb2pu5qSWOo1J0U/33HTXabCkP/hPwt7Tud2tcMWfmDZk5UG23FJjRpDjr+ftxHHB5NVctBbaPiJ3qfG9p4i0w/4/ne9xWubgbCsJdgEeHPe+nBEVO2UXELGB/Kj3ehatecl8OPAncmJlliOs8Kn+kBguOY7gEboiIvohYVHQwVbOBp4D/VR02cUlEvKzooErC/LQVypSfzE1jUrb8ZG5qvldn5hNQ6dQBXlWjzah5MCKOBR7LzLuaHegw44p5hA9QuXrUDPXEMFqbIv72jCfejVqc/8cb83mUMxdvohsKwqixrfAe3DKLiG2B7wAfz8zfFR0PQGZuyMz9qPS0HRQR+xQZT0QcAzyZmX1FxlHDmzPzAODtwJkRcUjRAQGTqAw//Fpm7g88T2UYjsxPY1a2/GRuGpOy5SdzUwNExE0RcW+Nr3qvONXMgxGxDXA28NnGRVv9wCbFPOIzzgYGgCXjjXdrY9hMmyL+9own3sqLrc//Wx1zyXPxJiYVHUAL9FMZfz5kBvB4QbGUXkRMpvLLtiQzv1t0PCNl5jMRcQuwEChywos3A8dGxNHAVODlEfEvmfnnBcZEZj5e/ffJiLiaynCHHxcZE5Xfwf5hV06uwpOuIeanMShzfjI3bVkJ85O5qQEy84jRXouIXw8N+asOo3uyRrPR8uBrgd2BuyJiaPudEXFQZv6qpDEP7eNU4Bjg8MxsVqFVz9+P0dpMqeO9jTaeeIvK/+OJ+QRKmotr6YYrhHcAe0TE7hExBTgJuK7gmEopKhn3UuCBzPxK0fEMiYgdozpLV0S8FDgCeLDImDLz05k5IzNnUfmZ+lHRv+QR8bKI2G7oMZUb2wufJbL6h/vRiNizuulw4P4CQyoT81OdypifzE31K2N+Mje1xHXAqdXHpwLX1mhTMw9m5j2Z+arMnFX9ee6nMrHIuIrBZsYMlVkpgbOAYzPzhSbGWc/fj+uAU6ozYfYCv60Ogy3ib89Wx1tg/t/qmMuai0fT8VcIM3MgIj5CZYaqicBlmXlfwWEREd8CDgV2iIh+4HOZeWmxUfFm4C+Ae6r3xAD8XWZeX1xIQGV2qW9GxEQqnRjfzsxyT99bjFcDV1d7UicB/zszf1BsSBv9FbCkmlBXAe8vOJ5SMD+NSRnzk7mpfmXNT+am5voi8O2IOA34JfAugIjYGbgkM48uYR4cb8wXAC8Bbqz+vC/NzDMaHeRoMUTEGdXXLwaupzIL5krgBao/30V8z8cTLwXl/3HG3FaieVeyJUmSJEll1g1DRiVJkiRJNVgQSpIkSVKXsiCUJEmSpC5lQShJkiRJXcqCUJIkSZK6VEcUhBFxWUQ8GRFbXNMoIj4ZEfdHxN0R8e8RsVsrYpQkSSqLsZw71bGv/SLi1oi4r3p+dWIjYpTUGh1REALfABbW2fb/AT2ZORe4CvgfzQpKkiSppL5B/edOW/ICcEpm7l3d53kRsX2D9i2pyTqiIMzMHwO/Gb4tIl4bET+IiL6I+ElEvL7a9ubMfKHabCkwo8Xhapyqi0BLUqmYm9ROxnLuVMe+Hs7MFdXHjwNPAjs2PGhtNfOTNmdS0QE00WLgjMxcERELgIuAt45ocxrw/ZZHpjGLiCuBR4H9gX8H/luxEUmSuUkdp55zp82KiIOAKcAjTYhPY2B+Ur06siCMiG2BNwFXRsTQ5peMaPPnQA/wJ62NTltpX+CBzDys6EAkaRhzkzrC5s6dIuJ44PM13vZYZh41bB87Af8fcGpmDjY3YtXB/KS6RGYWHUNDRMQs4HuZuU9EvBx4KDN3GqXtEcBXgT/JzCdbGKa2QkRMBX4J7JyZA0XHI0lgblL7G8u5Ux37ejlwC/D/y8wrGxeltob5SWPREfcQjpSZvwN+HhHvAoiKedXH+wP/EzjWYrBt7A3cZkKTVDLmJnWMzZ07bUlETAGuBi63GCwN85Pq1hEFYUR8C7gV2DMi+iPiNOBk4LSIuAu4Dziu2vxcYFsqQyKWR8R1hQStsdgXuLvoICRpBHOT2tYYz5225N3AIcD7qudWyyNiv2bErbqZn1S3jhkyqs4VEf8I3J6Z/1p0LJI0xNwkqazMTxoLC0JJkiRJ6lIdMWRUkiRJkjR2bb/sxA477JCzZs0qOgxJDdTX1/d0Zrb9osbmJ6nzdEJ+MjdJnWc8uantC8JZs2axbNmyosOQ1EARsbroGBrB/CR1nk7IT+YmqfOMJzc5ZFSSJEmSulTpCsKIWBgRD0XEyoj4VNHxSOp8W8o71fW4zq++fndEHFBEnJIkSY1WqoIwIiYCFwJvB94AvCci3lBsVJI6WZ155+3AHtWvRcDXWhqkJG2GnemSxqNs9xAeBKzMzFUAEXEFlUVR7y80qg7Wt3otS1etoXf2dACWrlrDtG2msPaFdRv/3dxr7dimLHF04zH3zp7O/N2mNfJHuBHqyTvHAZdnZZ2epRGxfUTslJlPtD7c7lVPvuq03xmPp3XHU9L8tEXDOrXeBvQDd0TEdZk57nOn4b9z7fi9kVSfshWEuwCPDnveDywoKJa2NZTAt/RH8d7Hf8tVff0MbBhk0oSACNYPDJJAAAlMCEZ9rR3blCWObjzmCQFTJk1gyem9ZTuxqCfv1GqzC2BB2CBbKvbqyVed9jvj8bTueAY2DJY1P9WjKZ3pfavXcvIlS1k30Nbfm6ZoZedUmTtRyt6mLHGMt00rOmTKVhBGjW25SaOIRVSGbTFz5sxmx1R6wwvAoZOmoT+A9fxRBFi/IYHc+Hzo38Ec/bV2bFOWOLrxmAcT1g8MsnTVmrKdVNSTd+rKTWB+qletvFVPsQfd8zvj8bT2eEqan+rRlM70pavWsG5gsMy5u2W2Nl91cidK2duUJY7xtmlVZ3rZCsJ+YNdhz2cAj49slJmLgcUAPT09OfL1bjA8OX3+e/fxh/Uv/uEaUs8fxQAmT6z2kg4MMkjtH86Rr7Vjm7LE0Y3HPCFg8qQJG3u/SqSevFNXbgLz05b0rV7Ld+7sf1HH1fC8NZ581Wm/Mx5P645nw4bBsuanekSNbZvknrF2VvXOns6USRNYP9DW35txGW++6vROlDK3KUsc423Tqg6ZshWEdwB7RMTuwGPAScB7iw2pXIYnp4ENg0yIYDA3/eEaUs8f1Xf17MrxB8wAOvuSe9ni6MZjLul9KPXkneuAj1SHYi0Afuv9g/UbrQNrSD3FXr35qtN+Zzwe7yGsQ1M60+fvNo0lp/e2+/dmzBqRr7qhE6XsbcoSx3jbtKozPSpzJJRHRBwNnAdMBC7LzP++ufY9PT3ZLYurDo3nH56cJgATJgSDg7nxB2fopGnvnV/Rrifo6nIR0ZeZPS38vE3yTkScAZCZF0dEABcAC4EXgPdn5hYTTzflp9EMvw9pqANrcMSfnbF0TpmvVLRW56ctiYhJwMPA4VQ6te4A3puZ9432HnNTbY3MV93QiVL2NmWJY7xt6v3bN57cVLqCcKy6Jan1rV7LeTc9zH+sfHpjcgrgJZMn8Nlj9vakSR2lbCdcW6tb8tNoRuatoQ6szGRijY4r85baQRnzk53p42e+UrsbT24q25BR1TDyyuDI3imTkqSyqZW3pkz6YweWJ1RS42Tm9cD1RcfRrsxX6nYWhCU31GO1bmi2IeDNc3bg40e8zuQkqZTMW5LahflKsiAstdF6rExSksrKvCWpXZivpAoLwhIamuHq8Wf+0x4rSW3DnnZJ7WRorUXzlbqdBWHJDJ/hatKEYNLECRvXRzJJSSore9oltYvhS0sMX2vRfKVuZUFYMkO9VYMJGwaTEw/alV22f6k3NEsqNXvaJbWD4R3vThwjVVgQlkjf6rU89sx/vuiq4DudRVRSG+idPd2edkmlN7zjff3AIGtfWMeZh80pOiypUBaEJTFyqOhJB810SQlJpTc09Kp39nSWnN678bG5S1IZjey8GloIXOpmFoQlMXKo6M7bv9QTKkmlNnLo1ZLTe+1pl1RaQx1YDhOVXsyCsCTssZLUbkYOvVq6ao0nV5JKqVYHlvlKqrAgLAF7rCS1IzuyJLULO7Ck0VkQFsweK0ntyI4sSe3EDixpdBaEBbPHSlK7sSNLUjuxA0vaPAvCgtljJand2JElqV3YgSVtmQVhwebvNs2p2qWCRMQrgX8FZgG/AN6dmWtHtNkVuBx4DTAILM7Mf25tpOViR5akdmEHlrRlFoQFGr5+l1O1S4X4FPDvmfnFiPhU9flZI9oMAP81M++MiO2Avoi4MTPvb3WwZWFHlqR2YQeWtGUWhAVxCINUCscBh1YffxO4hREFYWY+ATxRffxsRDwA7AJ0bUEIlaLQnCWp7OzAkrbMgrAgDmGQSuHV1YKPzHwiIl61ucYRMQvYH7itBbGV0vCRDeYsSe3ADixp8ywIC+IQBqk1IuImKvf/jXT2GPezLfAd4OOZ+bvNtFsELAKYOXPmWD6i9BzZIKmd2IEl1ceCsCAOYZBaIzOPGO21iPh1ROxUvTq4E/DkKO0mUykGl2Tmd7fweYuBxQA9PT259ZGXjyMbJLULO7Ck+lkQttjI3iqTk1So64BTgS9W/712ZIOICOBS4IHM/EprwysXRzZIahd2YEn1syBsIXurpNL5IvDtiDgN+CXwLoCI2Bm4JDOPBt4M/AVwT0Qsr77v7zLz+gLiLZQjG6Tu1I5DL+3AkupnQdhC9lZJ5ZKZa4DDa2x/HDi6+vinQLQ4tNJyZIPUXdq1M9sOLKl+FoQtZG+VpHbUjlcHJDVGO3dm24El1ceCsIXsrZLUbtr16oCkxrAzW+p8FoQtZm+VpHbSzlcHJI1fu3VmO6JBGjsLQknSqLw6IKldOrMd0SBtHQvCFrHHSlI7arerA5K6lyMapK1jQdgC9lhJamftcnVAUndzRIO0dSwIW8AeK0mSpOZyRIO0dSwIW8AeK0ntyKHuktqNIxqksbMgbAF7rCS1G4e6S5LUHSwIW8QeK0ntxKHukiR1hwlFBzBcRJwbEQ9GxN0RcXVEbF90TJLUjYaGuk8MHOouSVIHK1VBCNwI7JOZc4GHgU8XHM+49a1ey4U3r6Rv9dqiQ5Gkug0Ndf/kkXs6XFRS6Xm+JW29Ug0Zzcwbhj1dCpxQVCyN4D04ktqZQ90ltQPPt6TxKdsVwuE+AHy/6CDGo9Y9OJIkSWocz7ek8Wl5QRgRN0XEvTW+jhvW5mxgAFgyyj4WRcSyiFj21FNPtSr0MfMeHKncIuKVEXFjRKyo/jtql3JETIyI/xcR32tljJI0GudeqPB8Sxqflg8ZzcwjNvd6RJwKHAMcnpk5yj4WA4sBenp6arYpA5ebkErvU8C/Z+YXI+JT1ednjdL2Y8ADwMtbFZwkbcGNwKczcyAivkRl7oXRcljH8nxLGp9S3UMYEQupJLI/ycwXio6nEbwHRyq144BDq4+/CdxCjZOpiJgB/Cnw34FPtii2wrggvdQeOm3uhfHwfEvaeqUqCIELgJcAN0YEwNLMPKPYkCR1sFdn5hMAmflERLxqlHbnAX8LbNeqwIri5AxS2/oA8K9FByGp/ZSqIMzMOUXHIKmzRMRNwGtqvHR2ne8/BngyM/si4tA62i8CFgHMnDmz/kBLwgXppXLZXA7LzGurbTY790K1TVvnJknNU6qCUJIabXP3LUfEryNip+rVwZ2AJ2s0ezNwbEQcDUwFXh4R/5KZfz7K57XFPc6jGZqcYf3AoJMzSCXQiLkXqvtp69wkqXksCJvEe3CktnAdcCrwxeq/145skJmfpjJRA9UrhH89WjHYCZycQWofnTj3wlh5viWNnwVhE3gPjtQ2vgh8OyJOA34JvAsgInYGLsnMo4sMrihOziC1ja6ee8HzLakxLAibwHtwpPaQmWuAw2tsfxzYpBjMzFuozEQqSYXr9rkXPN+SGqPlC9N3AxdIlSRJai7Pt6TG8AphE3gPjiRJUnN5viU1hgVhk3gPjiRJ6jRlm8TF8y1p/CwIJUlA+U70JJWLk7hIncmCUJLkiZ6kLXISF6kzOamMJKnmiZ4kDeckLlJn8gphAzncSlK7GjrRWz8w6ImepJqcxEXqTBaEDeJwK0ntzBM9SfVwEhep81gQNojj6iW1O0/0JLULR2VJjWNB2CAOt5IkSWo+R2VJjWVB2CAOt5IkSWo+R2VJjWVB2EAOt5IkSWouR2VJjWVBKEmSpLbhqCypsbaqIIyIlwG/z8wNDY5Hkmoy7zSHEzNIrWEOayxHZUmNU1dBGBETgJOAk4EDgT8AL4mIp4DrgcWZuaJpUUrqOuad5nNiBql5zGGS2sWEOtvdDLwW+DTwmszcNTNfBbwFWAp8MSL+vEkxSupOTc87EfHKiLgxIlZU/61ZDUXE9hFxVUQ8GBEPRMQbx/O5ZVFrYgZJDeO5k6S2UO+Q0SMyc/3IjZn5G+A7wHciYnJDI2sjDrmSmqIVeedTwL9n5hcj4lPV52fVaPfPwA8y84SImAJsM87PLQUnZpCaynMnSW2hroJwKKFFxHnAJzIzR2vTbRxyJTVHi/LOccCh1cffBG5hREEYES8HDgHeV/3MdcC6cX5uKTgxg9Q8njtJahf1Dhkd8hxwXfXGaCLiyIj4j8aH1T4cciU1XTPzzqsz8wmA6r+vqtFmNvAU8L8i4v9FxCVDsXSC+btN48zD5lgMSs3juZOkUhvTLKOZ+ZmIeC9wS0T8AXieyhCrruWQK6m5xpt3IuIm4DU1Xjq7zl1MAg4A/iozb4uIf65+/jmjfN4iYBHAzJkz6w1TUofy3ElS2Y2pIIyIw4EPUklmOwGnZeZDzQisXTjkSmqu8eadzDxiM/v+dUTslJlPRMROwJM1mvUD/Zl5W/X5VWzmZC4zFwOLAXp6ejYZIiapu3ju1DjO2SA1x1jXITwbOCczfxoR+wL/GhGfzMwfNSG2tuFaOFJTNTPvXAecCnyx+u+1Ixtk5q8i4tGI2LN6Enc4cH8DPltSd/DcqQGcs0FqnrEOGX3rsMf3RMTbqcyU9aZGByZJ0PS880Xg2xFxGvBL4F0AEbEzcElmHl1t91fAkuoMo6uA9zfgsyV1Ac+dGqPWnA0WhFJj1LswfYwyO9YT1aEQo7aRpK3RiryTmWuoXPEbuf1x4Ohhz5cDPVv7OZK6j+dOjeWcDVLz1L0wfUT8VUS8aIaEam/5GyPim1SGW0lSo5h3mqhv9VouvHklfavXFh2K1KnMYQ00NGfDJ4/c0+GiUoPVO2R0IfAB4FsRMRtYC7yUSkF5A/BP1R50SWoU806TeC+O1BLmsAZzzgapOepdmP73wEXARRGxHbAd8EJmPtPE2ErP2a6k5jHvNI/34kjNZw6T1C7GtDB9RHwU+AVwO3BrRJzZjKDawVAP+z/e8BAnX7LUYVdSk5h3Gm/oXpyJgffiSE3WqTnMYedS56irIIyI8yLiFODjwF6ZOQM4BNg7Ir7QxPhKq1YPu6TGMe80j/fiSM3XyTnMTnGps9R7hfD/AnOAHYCfRcSdwLnAI8BJEbF9c8IrL3vYpaYz7zTR/N2mceZhcywGpebp2Bxmp7jUWeq9h/Bq4OqI6AU+ATwBzAPmAq8EbomIbTNzTiOCioi/ppI0d8zMpxuxz0Yb6mH3HkKpOVqddySpkTo5h7kEhNRZxrQwPXAm8G1gOXAPsBdwT2YeWp1GedwiYlfgbVQWiS41Z7uSWqLpeUeSmqjjcpid4lJnGdOkMpm5AlgAXEVl6uS7gT+rvrauQTH9E/C3gAu1SmpV3pGkpujUHOawc6lzjPUK4VDy+rfqV0NFxLHAY5l5V0Q0eveS2lQz844kNZs5bHxc5ktqrjEXhOMVETcBr6nx0tnA3wFH1rGPRcAigJkzZzY0PkmSJJXD0Iym6wYGmTJpgjMjS03Q8oIwM4+otT0i9gV2B4auDs4A7oyIgzLzVyP2sRhYDNDT0+PQUkmSpA5Ua0ZTC0KpscZ0D2EzZeY9mfmqzJyVmbOAfuCAkcWgJGnruZi01Hki4q8jIiNih6JjaTSX+ZKar+VXCNud49gltSuHXkmdp51mZ98azmgqNV9pC8LqVcJS8WRK6iwR8UrgX4FZwC+Ad2fmJpfOIuITwOlUZj++B3h/Zv6+dZE2hkOvpI40NDv7tUUH0iwu8yU1V2mGjLaDWidTktrap4B/z8w9gH+vPn+RiNgF+CjQk5n7ABOBk1oaZYM49ErqLMNnZy86Fkntq7RXCMto6GRq/cCgJ1NSZzgOOLT6+JvALcBZNdpNAl4aEeuBbYDHWxFcozn0Smo/jZidvbofZ2iXVJMF4Rh4MiV1nFdn5hMAmflERLxqZIPMfCwivkzl/pz/BG7IzBtaHGfDOPRKai+NmJ29uh9naJdUkwXhGHkyJbWXLfSu1/P+aVSuJO4OPANcGRF/npn/Mkp7e+ElNV1m3gNs7MSKiF9QGdr+dGFBSWpLFoSSOtpovesAEfHriNipenVwJ+DJGs2OAH6emU9V3/Nd4E1AzYLQXnhJktROnFRGUje7Dji1+vhUas/S90ugNyK2icq4rMOBB1oUnyTVpbqOs1cHJY2ZBaGkbvZF4G0RsYLKOl5fBIiInSPieoDMvA24CriTypITE6heAZQkSWp3DhmV1LUycw2VK34jtz8OHD3s+eeAz7UwNEnqen2r1zqRn9QCFoR1MilJamfmMEntpG/1Wk6+ZCnrBgaZMmkCS07vNXdJTWJBWAeTkqR2Zg6T1G6WrlrDuoFBBhPWDwyydNUa85bUJN5DWIdaSUmS2oU5TFKz9K1ey4U3r6Rv9dqG7rd39nSmTJrAxIDJkybQO3t6Q/cv6Y+8QliHoaS0fmDQpCSp7ZjDJDVDM0cfzN9tGktO73Wou9QCFoR1MClJamfmMEnN0OxhnfN3m2a+klrAgrBOJiVJ7cwcJqnRHH0gdQYLQkmSJI2Zow+kzmBBKEmSpK3i6AOp/TnLqCRJkiR1KQtCSZIkSepSFoRb0Kz1dSRJkiSpaN5DuBnNXF9Hkpqtb/VaJ3uQ1HbMXVJrWRBuRrPX15GkZrFDS1I7MndJreeQ0c0YWl9nYuD6OpLaSq0OLUkqO3OX1HoWhJsxtL7OJ4/c0x4qqQNFxLsi4r6IGIyIns20WxgRD0XEyoj4VCtj3Fp2aElqR+YuqfUcMroFrq8jdbR7geOB/zlag4iYCFwIvA3oB+6IiOsy8/7WhLh1XDBaUjsyd0mtZ0EoqWtl5gMAEbG5ZgcBKzNzVbXtFcBxQKkLQrBDS1J7MndJreWQUUnavF2AR4c9769ukyRJanteIZTU0SLiJuA1NV46OzOvrWcXNbblZj5vEbAIYObMmXXFKEmSVBQLQkkdLTOPGOcu+oFdhz2fATy+mc9bDCwG6OnpGbVwlCRJKgOHjI6ib/VaLrx5JX2r1xYdiqRi3QHsERG7R8QU4CTguoJjkqTS8dxJak9eIazBRVGl7hARfwZ8FdgR+LeIWJ6ZR0XEzsAlmXl0Zg5ExEeAHwITgcsy874Cw96ivtVrnaFPUkt57iS1LwvCGmotimpSkzpPZl4NXF1j++PA0cOeXw9c38LQtponZZKK4LmT1L4cMlqDi6JKale1TsokqdnGe+7kcFOpOF4hrMFFUSW1q6GTsvUDg3ZoSWqZ8Zw7ObJBKlbpCsKI+CvgI8AA8G+Z+bdFxOGiqJLakR1akoqytedODjeVilWqgjAiDgOOA+Zm5h8i4lVFxyRJ7cYOLUntxJENUrFKVRACHwK+mJl/AMjMJwuOR5IkSU3kyAapWGUrCF8HvCUi/jvwe+CvM/OOVn24U7VLkiS1niMbpOK0vCCMiJuA19R46Wwq8UwDeoEDgW9HxOzMzBH7WAQsApg5c2ZD4vKGZklFsTNKkiQVpeUFYWYeMdprEfEh4LvVAvD2iBgEdgCeGrGPxcBigJ6entxkR1vBG5olFaGRnVEWlpIkaazKNmT0GuCtwC0R8TpgCvB0Kz7YG5olFaFRnVGOcpAkSVujbAXhZcBlEXEvsA44deRw0WbxhubWWb9+Pf39/fz+978vOhQVbOrUqcyYMYPJkycXHUphGtUZ5SiH8TM3aTjzk1rNHKR6NCM3laogzMx1wJ8X9fne0Nwa/f39bLfddsyaNYuIKDocFSQzWbNmDf39/ey+++5Fh1OYRnVGOcph/MxNGmJ+Gp+xDF93qPsfmYO0Jc3KTaUqCNUdfv/735vsREQwffp0nnrqqS037nCN6IxylMP4mZs0xPy09cYyfN2h7i9mDtKWNCs3TWjo3tpU3+q1XHjzSvpWry06lK5hshP4czDSeHPR/N2mceZhc7r6hGq8/JnUkHb5WYiIv4qIhyLivoj4H0XHU2v4eiPadot2+blTcZrxM9L1BeFQ79Q/3vAQJ1+y1KKwS2y77bZN/4yLL76Yyy+/vOmfM9w111zD/fffP6b3ZCYf/ehHmTNnDnPnzuXOO++s2e7nP/85CxYsYI899uDEE09k3bp1W3z/rFmz2Hfffdlvv/3o6enZ+gPrAuYigblpuGbmpg984AO86lWvYp999tn6gyqBiDgMOA6Ym5l7A18uOKSNw9cnBlscvj6WtmoNc9AfNTMH/eAHP2DPPfdkzpw5fPGLX9y4/e///u/ZZZdd2G+//dhvv/24/vrrt+Jox67rC0J7pzQeGzZsGPW1M844g1NOOaWln7k1Ce/73/8+K1asYMWKFSxevJgPfehDNdudddZZfOITn2DFihVMmzaNSy+9tK7333zzzSxfvpxly5aNKa5WiIh3VXvVByOiZsUaEbtGxM0R8UC17ceaEct4cpGjHDSSuWnz73/f+97HD37wgzHFU1IfAr6YmX8AyMwnC45n4/D1Tx655xaHgI6lrdqLOWj092/YsIEzzzyT73//+9x///1861vfelFsn/jEJ1i+fDnLly/n6KOPHlPMW6vrC0J7p9pDM094zz33XA488EDmzp3L5z73uY3b3/GOdzB//nz23ntvFi9evHH7tttuy2c/+1kWLFjArbfeyrbbbsvZZ5/NvHnz6O3t5de//jVQ6eX58pcrnbWHHnooZ511FgcddBCve93r+MlPfgLACy+8wLvf/W7mzp3LiSeeyIIFC2oWTrNmzeLzn/88Bx98MFdeeSVf//rXOfDAA5k3bx7vfOc7eeGFF/jZz37Gddddx9/8zd+w33778cgjj/DII4+wcOFC5s+fz1ve8hYefPDBTfZ97bXXcsoppxAR9Pb28swzz/DEE0+8qE1m8qMf/YgTTjgBgFNPPZVrrrmm7veX2L3A8cCPN9NmAPivmbkX0AucGRFvaHQgW5uLvLJYLHNTe+amQw45hFe+8pVb+19TJq8D3hIRt0XE/42IA4sOCMY2fN2h7uNjDmq/HHT77bczZ84cZs+ezZQpUzjppJO49tprx/E/NX5dXxDaO1V+zTzhveGGG1ixYgW33347y5cvp6+vjx//uFIbXHbZZfT19bFs2TLOP/981qypXLF5/vnn2Weffbjttts4+OCDef755+nt7eWuu+7ikEMO4etf/3rNzxoYGOD222/nvPPO4x/+4R8AuOiii5g2bRp3330355xzDn19faPGOnXqVH76059y0kkncfzxx3PHHXdw1113sddee3HppZfypje9iWOPPZZzzz2X5cuX89rXvpZFixbx1a9+lb6+Pr785S/z4Q9/eJP9PvbYY+y6664bn8+YMYPHHnvsRW3WrFnD9ttvz6RJkzZps7n3RwRHHnkk8+fPf9EfjbLIzAcy86EttHkiM++sPn4WeADYpdGxbG0ucpRDccxNFe2Ym9pJRNwUEffW+DqOyuSA06h0Vv0N8O0Y5QajiFgUEcsiYpmT5XQGc1BFu+WgLe33ggsuYO7cuXzgAx9g7drWdPI6yyguN1F2zVxf7YYbbuCGG25g//33B+C5555jxYoVHHLIIZx//vlcffXVADz66KOsWLGC6dOnM3HiRN75zndu3MeUKVM45phjAJg/fz433nhjzc86/vjjN7b5xS9+AcBPf/pTPvaxygjEffbZh7lz544a64knnrjx8b333stnPvMZnnnmGZ577jmOOuqoTdo/99xz/OxnP+Nd73rXxm1/+MMfNmlXa6nPkecTm2uzudf+4z/+g5133pknn3ySt73tbbz+9a/nkEMOGe0QSy8iZgH7A7c1Y/9bk4tcbqI45qaKdsxN7SQzjxjttYj4EPDd6prNt0fEILADsEnFl5mLgcUAPT09LVnjWc1lDqpotxy0ufd86EMf4pxzziEiOOecc/iv//W/ctlll23SvtG6uiB07Zv20MwT3szk05/+NH/5l3/5ou233HILN910E7feeivbbLMNhx566MaFYqdOncrEiRM3tp08efLGX+SJEycyMDBQ87Ne8pKXbNKmVlIYzcte9rKNj9/3vvdxzTXXMG/ePL7xjW9wyy23bNJ+cHCQ7bffnuXLl292vzNmzODRRx/d+Ly/v5+dd975RW122GEHnnnmGQYGBpg0adKL2mzu/UP/vupVr+LP/uzPuP3221teEEbETcBrarx0dmbWPUYjIrYFvgN8PDN/t5l2i4BFADNnzhxjtBVjyU0uN1Ecc1NFO+amDnIN8Fbgloh4HTAFeLrQiOrkOdj4mYMq2i0HrVu3btT9vvrVr964/YMf/ODGgrrZunbIqPfdtI9mDus96qijuOyyy3juueeAyuX9J598kt/+9rdMmzaNbbbZhgcffJClS5c27DOHO/jgg/n2t78NwP33388999xT1/ueffZZdtppJ9avX8+SJUs2bt9uu+149tlnAXj5y1/O7rvvzpVXXglUkutdd921yb6OPfZYLr/8cjKTpUuX8opXvIKddtrpRW0igsMOO4yrrroKgG9+85scd9xxm33/888/vzGW559/nhtuuKGQGf0y84jM3KfG11iKwclUisElmfndLXze4szsycyeHXfccczx1pubht834j04xTA3baodclOHuQyYHRH3AlcAp+ZYzqSbbLT72zwHawxz0KbaIQcdeOCBrFixgp///OesW7eOK664gmOPPRbgRfcoXn311S07b+ragtD7btpLs054jzzySN773vfyxje+kX333ZcTTjiBZ599loULFzIwMMDcuXM555xz6O3tbejnDvnwhz/MU089xdy5c/nSl77E3LlzecUrXrHF933hC19gwYIFG4dhDjnppJM499xz2X///XnkkUdYsmQJl156KfPmzWPvvfeuedPy0UcfzezZs5kzZw4f/OAHueiii1702uOPPw7Al770Jb7yla8wZ84c1qxZw2mnnbbZ9//617/m4IMPZt68eRx00EH86Z/+KQsXLhzX96sI1ftxLgUeyMyvNPvz6slNnkyVh7npxdohNwG85z3v4Y1vfCMPPfQQM2bM2DgrYLvJzHWZ+efVTq4DMvNHRcc0ZHN5ynOwxjEHvVg75KBJkyZxwQUXcNRRR7HXXnvx7ne/m7333huAv/3bv2Xfffdl7ty53HzzzfzTP/3T1n8TxyBK1JG0VXp6enKs09n3rV7Ld+7s56q+fjZsqFxmd0KZ1nnggQfYa6+9ig6jFDZs2MD69euZOnUqjzzyCIcffjgPP/wwU6ZMKTq0lqn18xARfZnZ9IULI+LPgK8COwLPAMsz86iI2Bm4JDOPjoiDgZ8A9wCD1bf+XWZucXGgrc1PJ1+ydOMQoM8eszdrX1j3omFVF968kn+84SEGEyYGfPLIPTnzsDlj+hxtytz0R+amiiLzUzNtTW4aq83lqZF5znOwCnPQH5mDNq/Ruanr7iEcSkLrBgaZNCE46aCZHH/ADBORCvHCCy9w2GGHsX79ejKTr33taya7FsrMq4Gra2x/HDi6+vinQMtmohh+T+C0babw+e/dx7qBQaZUT5oAHnvmP5k0ccLGDi0nklGjmZs0XqPd3zZ072Ctzi5piDmotbqmIBxKQI8/858bhylsGEx23v6lJiIVZrvttivlgu0q1tBsoxfevHJjvlq3fpDP/5/7eOBXzzKwwQ4tNZe5SeM1snNr6ao1PPSrZzfp5DJ/qRZzUGt1RUE48qqgPeuS2sFQD/u69YMMAnf3/5ahQf52aEkqu6H8NHQONiGCwcymLJMgaet1RUE4/OblDYPJiQftyi7bv9RhCgXKzLZcD0qN1e73MDfbUA/7eTc9zH+sfJrB6rcrwA6tJjE3aYj5qTGGn4ORyYQJQZDmsFGYg7QlzchNXVEQjhzH/k6HWBVq6tSprFmzhunTp5v0ulhmsmbNGqZOnVp0KKU2f7dpfPyI13HHL37D+oFBJk4I3tWzq0NFm8DcpCHmp8YZeQ7mvYOjMwdpS5qVm7qiIHTh5nKZMWMG/f39PPXUU0WHooJNnTqVGTNmFB1G6ZnDWsPcpOHMT41h/qqfOUj1aEZu6oqCEP44SYOKN3nyZHbfffeiw5Daijms+cxNUnOYv+pjDlJRunZhekmSJEnqdhaEkiRJktSlLAglSZIkqUtFu0+rHBFPAavrbL4D8HQTw9kaZYwJyhmXMdWvjHGNJabdMnPHZgbTCmPIT2X8/4JyxlXGmKCccRlT/boqP3nu1DRljMuY6lfGuFqSm9q+IByLiFiWmT1FxzFcGWOCcsZlTPUrY1xljKksyvq9KWNcZYwJyhmXMdWvrHGVQRm/N2WMCcoZlzHVr4xxtSomh4xKkiRJUpeyIJQkSZKkLtVtBeHiogOooYwxQTnjMqb6lTGuMsZUFmX93pQxrjLGBOWMy5jqV9a4yqCM35syxgTljMuY6lfGuFoSU1fdQyhJkiRJ+qNuu0IoSZIkSarqioIwIhZGxEMRsTIiPlV0PAARcVlEPBkR9xYdy5CI2DUibo6IByLivoj4WNExAUTE1Ii4PSLuqsb1D0XHNCQiJkbE/4uI7xUdC0BE/CIi7omI5RGxrOh4hkTE9hFxVUQ8WP35emPRMZWF+ak+ZcxP5qaxKWN+MjeNztxUH3PT2JUtP5UxN0Fr81PHDxmNiInAw8DbgH7gDuA9mXl/wXEdAjwHXJ6Z+xQZy5CI2AnYKTPvjIjtgD7gHSX4XgXwssx8LiImAz8FPpaZS4uMCyAiPgn0AC/PzGNKEM8vgJ7MLNU6OhHxTeAnmXlJREwBtsnMZwoOq3Dmp/qVMT+Zm8amjPnJ3FSbual+5qaxK1t+KmNugtbmp264QngQsDIzV2XmOuAK4LiCYyIzfwz8pug4hsvMJzLzzurjZ4EHgF2KjQqy4rnq08nVr8J7MiJiBvCnwCVFx1JmEfFy4BDgUoDMXOcJ10bmpzqVMT+Zm9qbuWmzzE11MjeNjfmpPq3OT91QEO4CPDrseT8lKHLKLiJmAfsDtxUcCrBxeMFy4EngxswsQ1znAX8LDBYcx3AJ3BARfRGxqOhgqmYDTwH/qzpE5JKIeFnRQZWE+WkrlCk/mZvGpGz5ydw0OnPTVjA31eU8ypefypaboMX5qRsKwqixrRS9JGUVEdsC3wE+npm/KzoegMzckJn7ATOAgyKi0KEiEXEM8GRm9hUZRw1vzswDgLcDZ1aH1xRtEnAA8LXM3B94HijF/SglYH4ao7LlJ3PTmJQtP5mbRmduGiNz05aVOD+VLTdBi/NTNxSE/cCuw57PAB4vKJbSq441/w6wJDO/W3Q8I1Uvl98CLCw2Et4MHFsdd34F8NaI+JdiQ4LMfLz675PA1VSG/RStH+gf1jt5FZUkJ/PTmJQ5P5mbtqyE+cncNDpz0xiYm+pWyvxUwtwELc5P3VAQ3gHsERG7V2/IPAm4ruCYSql6E/KlwAOZ+ZWi4xkSETtGxPbVxy8FjgAeLDKmzPx0Zs7IzFlUfqZ+lJl/XmRMEfGy6g3tVIcVHAkUPhNbZv4KeDQi9qxuOhwodGKCEjE/1amM+cncVL8y5idz02aZm+pkbqpfGfNTGXMTtD4/TWrWjssiMwci4iPAD4GJwGWZeV/BYRER3wIOBXaIiH7gc5l5abFR8WbgL4B7quPOAf4uM68vLiQAdgK+WZ31bALw7cwsxVTFJfNq4OrK3yYmAf87M39QbEgb/RWwpHpisQp4f8HxlIL5aUzKmJ/MTfUra34yN9VgbhoTc1N7K2tughbmp45fdkKSJEmSVFs3DBmVJEmSJNVgQShJkiRJXcqCUJIkSZK6lAWhJEmSJHUpC0JJkiRJ6lIdURBGxGUR8WRENGTdkIj4QUQ8ExFO0StJkiSpY3VEQQh8A1jYwP2dS2VNGUmSJEnqWB1REGbmj4HfDN8WEa+tXunri4ifRMTrx7C/fweebXScaozqQquSVCrmJkllZX7S5kwqOoAmWgyckZkrImIBcBHw1oJj0laKiCuBR4H9gX8H/luxEUmSuUlSeZmfVK+OLAgjYlvgTcCVETG0+SXV144HPl/jbY9l5lGtiVBbYV/ggcw8rOhAJGkYc5OksjI/qS4dWRBSGQr7TGbuN/KFzPwu8N2WR6StFhFTgVdSu5CXpEKYmySVlflJY9ER9xCOlJm/A34eEe8CiIp5BYelrbc3cFtmDhQdiCQNY26SVFbmJ9WtIwrCiPgWcCuwZ0T0R8RpwMnAaRFxF3AfcNwY9vcT4Erg8Or+HEparH2Bu4sOQp1rS0vXVDuVzo+IlRFxd0Qc0OoYVUrmJjWVuUnjYH5S3TpiyGhmvmeUl7ZqKYrMfMs4wlHj7QvcXnQQ6mjfAC4ALh/l9bcDe1S/FgBfq/6r7mZuUrN9A3OTto75SXWLzCw6BkkqXETMAr6XmfvUeO1/Ardk5reqzx8CDs3MJ1obpaRuY26S1GwdMWRUkppsFypTdw/pr26TpCKZmySNW9sPGd1hhx1y1qxZRYchqYH6+vqezswdi45jmKixrebwiohYBCwCeNnLXjb/9a9/fTPjktRiJctP5iZJwPhyU9sXhLNmzWLZsmVFhyGpgSJiddExjNAP7Drs+Qzg8VoNM3MxsBigp6cnzU9SZylZfjI3SQLGl5scMipJW3YdcEp1Rr9e4LfeoyOpBMxNksat7a8QStJ4VZeuORTYISL6gc8BkwEy82LgeuBoYCXwAvD+YiKV1E3MTZJawYJQUtfbzNI1Q68ncGaLwpEkwNwkqTW6piDsW72WpavW0Dt7OvN3m1Z0OF1h/fr19Pf38/vf/77oUFRSU6dOZcaMGUyePLnoUCRJkrpSVxSEfavXcvIlS1k3MMiUSRNYcnqvRWEL9Pf3s9122zFr1iwiak2Epm6WmaxZs4b+/n523333osORJEnqSl0xqczSVWtYNzDIYML6gUGWrlpTdEhd4fe//z3Tp0+3GFRNEcH06dO9gixJklSgrigIe2dPZ8qkCUwMmDxpAr2zpxcdUtewGNTm+PMhSZJUrK4oCOfvNo0lp/fyySP3dLhol9l2222b/hkXX3wxl19+edM/Z7hrrrmG+++/f0zvyUw++tGPMmfOHObOncudd95Zs93Pf/5zFixYwB577MGJJ57IunXrtvj+H/zgB+y5557MmTOHL37xixu3X3nlley9995MmDDB9UIlSZJKqCsKQqgUhWceNsdiUFtlw4YNo752xhlncMopp7T0M7emIPz+97/PihUrWLFiBYsXL+ZDH/pQzXZnnXUWn/jEJ1ixYgXTpk3j0ksv3ez7N2zYwJlnnsn3v/997r//fr71rW9tjG2fffbhu9/9LocccsiYYpUkSVJrdE1BqPbQt3otF968kr7Vaxu+73PPPZcDDzyQuXPn8rnPfW7j9ne84x3Mnz+fvffem8WLF2/cvu222/LZz36WBQsWcOutt7Ltttty9tlnM2/ePHp7e/n1r38NwN///d/z5S9/GYBDDz2Us846i4MOOojXve51/OQnPwHghRde4N3vfjdz587lxBNPZMGCBTWvmM2aNYvPf/7zHHzwwVx55ZV8/etf58ADD2TevHm8853v5IUXXuBnP/sZ1113HX/zN3/DfvvtxyOPPMIjjzzCwoULmT9/Pm95y1t48MEHN9n3tddeyymnnEJE0NvbyzPPPMMTT7x4/eLM5Ec/+hEnnHACAKeeeirXXHPNZt9/++23M2fOHGbPns2UKVM46aSTuPbaawHYa6+92HPPPbf2v0ySJElNZkGo0hiaDfYfb3iIky9Z2tCi8IYbbmDFihXcfvvtLF++nL6+Pn784x8DcNlll9HX18eyZcs4//zzWbOmMunQ888/zz777MNtt93GwQcfzPPPP09vby933XUXhxxyCF//+tdrftbAwAC333475513Hv/wD/8AwEUXXcS0adO4++67Oeecc+jr6xs11qlTp/LTn/6Uk046ieOPP5477riDu+66i7322otLL72UN73pTRx77LGce+65LF++nNe+9rUsWrSIr371q/T19fHlL3+ZD3/4w5vs97HHHmPXXXfd+HzGjBk89thjL2qzZs0att9+eyZNmrRJm9HeX89+JUmSVE6lW3YiIi4DjgGezMx9io5HrVNrNthGDfG94YYbuOGGG9h///0BeO6551ixYgWHHHII559/PldffTUAjz76KCtWrGD69OlMnDiRd77znRv3MWXKFI455hgA5s+fz4033ljzs44//viNbX7xi18A8NOf/pSPfexjQGUY5dy5c0eN9cQTT9z4+N577+Uzn/kMzzzzDM899xxHHXXUJu2fe+45fvazn/Gud71r47Y//OEPm7SrrF/8YiMnddlcm9Feq2e/kiRJKqfSFYTAN4ALgNbO0qHCDc0Gu35gsOGzwWYmn/70p/nLv/zLF22/5ZZbuOmmm7j11lvZZpttOPTQQzcugzB16lQmTpy4se3kyZM3FjoTJ05kYGCg5me95CUv2aRNraJpNC972cs2Pn7f+97HNddcw7x58/jGN77BLbfcskn7wcFBtt9+e5YvX77Z/c6YMYNHH3104/P+/n523nnnF7XZYYcdeOaZZxgYGGDSpEkvajPa+9etW7fF/UqSJKmcSjdkNDN/DPym6DjUes2cDfaoo47isssu47nnngMqwx+ffPJJfvvb3zJt2jS22WYbHnzwQZYuXdqwzxzu4IMP5tvf/jYA999/P/fcc09d73v22WfZaaedWL9+PUuWLNm4fbvttuPZZ58F4OUvfzm77747V155JVApPu+6665N9nXsscdy+eWXk5ksXbqUV7ziFey0004vahMRHHbYYVx11VUAfPOb3+S4447b7PsPPPBAVqxYwc9//nPWrVvHFVdcwbHHHjvG75AkSZKKULqCsBWaOXGJxqdZs8EeeeSRvPe97+WNb3wj++67LyeccALPPvssCxcuZGBggLlz53LOOefQ29vb0M8d8uEPf5innnqKuXPn8qUvfYm5c+fyile8Yovv+8IXvsCCBQt429vexutf//qN20866STOPfdc9t9/fx555BGWLFnCpZdeyrx589h77703Tuoy3NFHH83s2bOZM2cOH/zgB7nooote9Nrjjz8OwJe+9CW+8pWvMGfOHNasWcNpp5222fdPmjSJCy64gKOOOoq99tqLd7/73ey9994AXH311cyYMYNbb72VP/3TP6055FWSJEnFibEMZWuViJgFfG+0ewgjYhGwCGDmzJnzV69eXfe+hyYuWTcwyJRJE1yXsIkeeOAB9tprr6LDKIUNGzawfv16pk6dyiOPPMLhhx/Oww8/zJQpU4oOrXC1fk4ioi8zewoKqWF6enrS9RelztIJ+cncJHWe8eSmMt5DuEWZuRhYDJWkNpb3NnPiEmk0L7zwAocddhjr168nM/na175mMShJkqTCtWVBOB7NnLhEGs12221Xc91BSZIkqUilKwgj4lvAocAOEdEPfC4zL23U/ocmLlm6ag29s6d7dVCSJElS1ypdQZiZ72n2Z8zfbZqFYItkpmvSaVRlvIdZkiSpm3TlLKNqjalTp7JmzRpP+lVTZrJmzRqmTp1adCiSJEldq3RXCNU5ZsyYQX9/P0899VTRoaikpk6dyowZM4oOQ5IkqWtZEKppJk+ezO677150GJIkSZJG4ZBRSZIkSepSFoSSJEmS1KUsCCVJkiSpS3V1Qdi3ei0X3rySvtVriw5FUoEiYmFEPBQRKyPiUzVef0VE/J+IuCsi7ouI9xcRp6TuY36S1GxdO6lM3+q1nHzJUtYNDDJl0gSWnN7r2oRSF4qIicCFwNuAfuCOiLguM+8f1uxM4P7M/C8RsSPwUEQsycx1BYQsqUuYnyS1QtdeIVy6ag3rBgYZTFg/MMjSVWuKDklSMQ4CVmbmquoJ1BXAcSPaJLBdRASwLfAbYKC1YUrqQuYnSU3XtQVh7+zpTJk0gYkBkydNoHf29KJDklSMXYBHhz3vr24b7gJgL+Bx4B7gY5k52JrwJHUx85OkpuvaIaPzd5vGktN7WbpqDb2zpztcVOpeUWNbjnh+FLAceCvwWuDGiPhJZv5uk51FLAIWAcycObOxkUrqNg3LT+YmSaPp2iuEUCkKzzxsjsWg1N36gV2HPZ9Bpad9uPcD382KlcDPgdfX2llmLs7Mnszs2XHHHZsSsKSu0bD8ZG6SNJquLgglCbgD2CMido+IKcBJwHUj2vwSOBwgIl4N7AmsammUkrqR+UlS03XtkFFJAsjMgYj4CPBDYCJwWWbeFxFnVF+/GPgC8I2IuIfKEK6zMvPpwoKW1BXMT5JawYJQUtfLzOuB60dsu3jY48eBI1sdlySZnyQ1m0NGJUmSJKlLWRBKkiRJUpeyIJQkSZKkLmVBKEmSJEldyoJQkiRJkrqUBSHQt3otF968kr7Va4sORZIkSZJapuuXnehbvZaTL1nKuoFBpkyawJLTe5m/27Siw5IkSZKkpuv6K4RLV61h3cAggwnrBwZZumpN0SFJkiRJUkt0fUHYO3s6UyZNYGLA5EkT6J09veiQJEmSJKklun7I6PzdprHk9F6WrlpD7+zpDheVJEmS1DW6viCESlFoIShJkiSp23T9kFFJkiRJ6lYWhJIkSZLUpSwIJUmSJKlLWRBKkiRJUpeyIJQkSZKkLmVBKEmSJEldyoJQkiRJkrqUBaEkSZIkdanSFYQRsTAiHoqIlRHxqaLjkSRJkqROVaqCMCImAhcCbwfeALwnIt7Qqs/vW72WC29eSd/qta36SEmSJEkqzKSiAxjhIGBlZq4CiIgrgOOA+5v9wX2r13LyJUtZNzDIlEkTWHJ6L/N3m9bsj207favXsnTVGqZtM4W1L6zb+G/v7OkANV8rW5uyxNGNx9w7e7q/V5IkSSVStoJwF+DRYc/7gQWt+OClq9awbmCQwYT1A4MsXbWm609ch4q/oRP879zZz1V9/awfGCSBABKYEDBpQkDEJq+VrU1Z4ujGY54Q2NkiSZJUMmUrCKPGttykUcQiYBHAzJkzG/LBvbOnM2XSBNYPDDJ50oSNRVA36lu9dmPxN7BhcJMT/CFDjwcT1m9IIDduG/lvWdqUJY5uPOYyd7ZExELgn4GJwCWZ+cUabQ4FzgMmA09n5p+0MERJXcr8JKnZylYQ9gO7Dns+A3h8ZKPMXAwsBujp6dmkYNwa83ebxpLTezdeESvbCWsrDC8Ehxd/I0/wh9S6KjQwMMggm79yVGSbssTRjcc8IShlZ8uwe5ffRiUH3RER12Xm/cPabA9cBCzMzF9GxKsKCVZSVzE/SWqFshWEdwB7RMTuwGPAScB7W/Xh83eb1nWF4PB7Aj//vfv4w/oXXwUMYPLEygn+hg2DTJwQvKtnV/be+RWlvEetne6n68ZjLmlnSz33Lr8X+G5m/hIgM59seZSSupH5SVLTlaogzMyBiPgI8EMqQyMuy8z7Cg6rYw2fSGdCBIP5x6uAQ4Xgu3p25fgDZgDUdfW0npP9srQpSxytbFOWOEqmnnuXXwdMjohbgO2Af87My1sTnqQuZn6S1HSlKggBMvN64Pqi4+h0favXct5ND2+cSIdMJkwIgtx4FfD4A2a86KS+jU7wpbGo597lScB84HDgpcCtEbE0Mx/eZGdNuMdZUtdqWH4yN0kaTekKQjXf0JXBoeGhQ7M/fvaYvcs8rE9qlnruXe6nMlHD88DzEfFjYB6wSUHYjHucJXWthuUnc5Ok0VgQdpnhVwYTmAC8ec4OfPyI11kEqlvVc+/ytcAFETEJmEJlyNY/tTRKSd3I/CSp6SwIu8hoVwYtBtXNRrt3OSLOqL5+cWY+EBE/AO4GBqlM/X5vcVFL6gbmJ0mtYEHYRZauWuOVQamGWvcuZ+bFI56fC5zbyrgkyfwkqdkmFB2AWqd39nSmTJrAxIApk70yKEmSJHU7rxB2iaH1Bp04RpIkSdKQrSoII+JlwO8zc0OD41ETDF9vcMqkCSw5vddiUJIkSVJ9Q0YjYkJEvDci/i0ingQeBJ6IiPsi4tyI2KO5YWo8hu4dHExYPzDI0lVrig5JkiRJUgnUew/hzcBrgU8Dr8nMXTPzVcBbgKXAFyPiz5sUYyH6Vq/lwptX0rd6bdGhjNvwewcnT5pA7+zpRYckSZIkqQTqHTJ6RGauH7kxM38DfAf4TkRMbmhkBeqUIZZD9w32zp7OktN7Nz5ux2ORJEmS1Hh1FYRDxWBEnAd8IjNztDadoNYQy3YromoVtWceNqfosCRJkiSVyFiXnXgOuK46qQwRcWRE/EfjwypWJwyx9L5BSZIkSVsypllGM/MzEfFe4JaI+APwPPCppkRWoPm7TWv7IZZDRe36gcG2LWolSZIkNdeYCsKIOBz4IJVCcCfgtMx8qBmBFW3+btPashAc0glFrSRJkqTmGus6hGcD52TmTyNiX+BfI+KTmfmjJsSmrTR8MhnvG5QkSZI0mrEOGX3rsMf3RMTbqcwy+qZGB6at0ykzpEqSJElqvnoXpo9a2zPzCeDwzbVRazmZjCRJkqR61b0wfUT8VUTMHL4xIqYAb4yIbwKnNjw6jVknzJAqSZIkqTXqHTK6EPgA8K2ImA2sBV5KpaC8AfinzFzelAg1Jk4mI0mSJKle9S5M/3vgIuCiiNgO2A54ITOfaWJsGiMnk5EkSZI0FmNdduKjwOeA/wSejYgLMvPCpkSmMXEyGUmSJEljVe+kMudFxCnAx4G9MnMGcAiwd0R8oYnxqU5OJiNJkiRprOqdVOb/AnOAHYCfRcSdwLnAI8BJEbF9c8JTvZxMRpIkSdJY1XsP4dXA1RHRC3wCeAKYB8wFXgncEhHbZmbH3bg2/L68Mg/BdDIZSZIkSWM1pnsIgTOBbwPLgXuAvYB7MvPQ6hIUHaXd7subv9u0UscnSZIkqVzqHTIKQGauABYAV1FZduJu4M+qr61reHQF8748SZIkSZ1srFcIhwq/f6t+dbSh+/LWDwyW+r68dhnWKkmSJKlcxnSFsNsM3Zf3ySP3LO1w0aFhrf94w0OcfMlS+lavLTokqe1ExMKIeCgiVkbEpzbT7sCI2BARJ7QyPkndy/wkqdnGfIWw25T9vrxaw1rLHK9UNhExEbgQeBvQD9wREddl5v012n0J+GHro5TUjcxPklrBK4RtzuUmpHE7CFiZmauqQ+KvAI6r0e6vgO8AT7YyOEldzfwkqem8QtjmXG5CGrddgEeHPe+nMnnWRhGxC5UJtN4KHNi60CR1OfOTpKazIOwAZR/WKpVc1NiWI56fB5yVmRsiajUftrOIRcAigJkzZzYiPkndq2H5ydwkaTQWhJK6XT+w67DnM4DHR7TpAa6onmztABwdEQOZec3InWXmYmAxQE9Pz8gTN0kai4blJ3OTpNFYELYpl5qQGuYOYI+I2B14DDgJeO/wBpm5+9DjiPgG8L1axaAkNZj5SVLTlaogjIh3AX8P7AUclJnLio2onIaWmlg3MMiUSRNKuySG1A4ycyAiPkJldr6JwGWZeV9EnFF9/eJCA5TUtcxPklqhVAUhcC9wPPA/iw6kzFxqQmqszLweuH7EtponWpn5vlbEJElgfpLUfKUqCDPzAYAtTdrQ7YaWmlg/MOhSE5IkSZK2WqkKQtXHpSYkSZIkNULLC8KIuAl4TY2Xzs7Ma+vcR8unTi7bJC4uNSFJkiRpvFpeEGbmEQ3YR0unTnYSF0mSJEmdaELRAbSDWpO4FKVv9VouvHklfavXFhaDJEmSpM5QqnsII+LPgK8COwL/FhHLM/OogsMqzSQuXqmUJEmS1EilKggz82rg6qLjGKksk7i43IQkSZKkRipVQVhmZZjEpSxXKiVJkiR1BgvCNlKWK5WSJEmSOoMFYZspw5VKSZIkSZ3BWUYlSZIkqUtZEEqSJElSl7IgbBOuPyhJkiSp0byHsA24/qAkSZKkZvAKYRuotf6gJEmSJI2XBeEYFTF0c2j9wYmB6w9KkiRJahiHjI5BUUM3XX9QkiRJUjNYEI5BraGbrSrOXH9QkiRJUqM5ZHQMHLopSZIkqZN4hXAMihi62bd6rUNFJUmSJDWFBeEYtXLopstNSJIkSWomh4yWmMtNSJIkSWomC8IS855FSZIkSc1kQVhiQ/csfvLIPR0uKjVRRCyMiIciYmVEfKrG6ydHxN3Vr59FxLwi4pTUfcxPkprNewhLzuUmpOaKiInAhcDbgH7gjoi4LjPvH9bs58CfZObaiHg7sBhY0PpoJXUT85OkVvAKoaRudxCwMjNXZeY64ArguOENMvNnmbm2+nQpMKPFMUrqTuYnSU1nQTgOfavXcuHNK+lbvXbLjSWV1S7Ao8Oe91e3jeY04PtNjUiSKsxPkprOIaNbqZlLQrj2oNRSUWNb1mwYcRiVE66DR91ZxCJgEcDMmTMbEZ+k7tWw/GRukjQarxBupWYtCTFUaP7jDQ9x8iVLvfooNV8/sOuw5zOAx0c2ioi5wCXAcZk56i98Zi7OzJ7M7Nlxxx0bHqykrtKw/GRukjQaC8Kt1KwlIVx7UGq5O4A9ImL3iJgCnARcN7xBRMwEvgv8RWY+XECMkrqT+UlS0zlkdCsNLQnR6KGdQ4Xm+oFB1x6UWiAzByLiI8APgYnAZZl5X0ScUX39YuCzwHTgoogAGMjMnqJiltQdzE+SWiEyaw5Fbxs9PT25bNmyosNoKO8hVLeLiL5OOKHpxPwkdbtOyE/mJqnzjCc3eYWwhFx7UJIkSVIreA9hibiMhSRJkqRW8gphSTRzGQtJkiRJqsUrhCXh7KKSJEmSWs2CsAEaMdSzWctYSJIkSdJoHDI6To0a6tmsZSwkSZIkaTQWhONUa6jn1hZzzi4qSZIkqZUcMjpOjRjq6eyikiRJkorgFcJxGu9QT2cXlSRJklSUUhWEEXEu8F+AdcAjwPsz85lCg6rDeIZ6NnLIqSRJkiSNRdmGjN4I7JOZc4GHgU8XHE/TObuoJEmSpKKU6gphZt4w7OlS4ISiYtkafavXjnnoqLOLSpIkSSpKqQrCET4A/GvRQdRra+4FHF5AnnnYnBZFKkmSJEkVLS8II+Im4DU1Xjo7M6+ttjkbGACWjLKPRcAigJkzZzYp0rEZ672ATiYjSZIkqWgtLwgz84jNvR4RpwLHAIdnZo6yj8XAYoCenp6abVpt6F7A9QODdd0L6GQykiRJkopWqiGjEbEQOAv4k8x8oeh4xmLkvYAAF968ctT7AsdaQEqSJElSo5WqIAQuAF4C3BgRAEsz84xiQ6rf0PITmxsOOvy+QSeTkSRJklSkUhWEmdkRM6sMHw66bv0g5930MB8/4nUAmxSKTiYjSZIkqSilKgg7xdBw0HXrBxkE/mPl09y2ag177fRy7xuUJEmSVBplW5i+IwzdT/jmPXZgQlC5Urghuav/twwmTHARekmSJEklYEHYJPN3m8bHj3gdUyZNIIZtnwC8ec4OLjMhSZIkqXAWhE00dKXwPQtmMmXSBCYGTJk8gY8f8TqLQUmSJEmF8x7CJhuaefSdB8xwRlFJkiRJpeIVwhaZv9s0zjxsjsWgVEIRsTAiHoqIlRHxqRqvR0ScX3397og4oIg4JXUf85OkZrMglNTVImIicCHwduANwHsi4g0jmr0d2KP6tQj4WkuDlNSVzE+SWsGCUFK3OwhYmZmrMnMdcAVw3Ig2xwGXZ8VSYPuI2KnVgUrqOuYnSU1nQSip2+0CPDrseX9121jbSFKjmZ8kNV3bTyrT19f3dESsrrP5DsDTzYxnK5QxJihnXMZUvzLGNZaYdmtmICNEjW25FW0qDSMWURm2BfCHiLh3HLGVQRl/lsbKYyiPTjiOPVv4WQ3LT+amUuqEY4DOOI5OOIatzk1tXxBm5o71to2IZZnZ08x4xqqMMUE54zKm+pUxrjLGVNUP7Drs+Qzg8a1oA0BmLgYWQ6mPuW4eQzl0wjFAZxxHRCxr4cc1LD+Zm8qnE44BOuM4OuUYtva9DhmV1O3uAPaIiN0jYgpwEnDdiDbXAadUZ/PrBX6bmU+0OlBJXcf8JKnp2v4KoSSNR2YORMRHgB8CE4HLMvO+iDij+vrFwPXA0cBK4AXg/UXFK6l7mJ8ktUK3FYSLiw6ghjLGBOWMy5jqV8a4yhgTAJl5PZWTquHbLh72OIEzt2LXpT3mMfAYyqETjgE64zhaegxNyk/+P5RDJxwDdMZxdPUxRCWPSJIkSZK6jfcQSpIkSVKX6oqCMCIWRsRDEbEyIj5VdDwAEXFZRDxZpmmfI2LXiLg5Ih6IiPsi4mNFxwQQEVMj4vaIuKsa1z8UHdOQiJgYEf8vIr5XdCwAEfGLiLgnIpa3eCa8zYqI7SPiqoh4sPrz9caiY2qULeWX6kQP51dfvzsiDigizs2p4xhOrsZ+d0T8LCLmFRHnltSb6yPiwIjYEBEntDK+etRzDBFxaPV3/L6I+L+tjnFL6vh5ekVE/J9hOb1097xt6W90O/xeg/mpLMxN5dHu+alpuSkzO/qLyk3YjwCzgSnAXcAbShDXIcABwL1FxzIspp2AA6qPtwMeLsn3KoBtq48nA7cBvUXHVY3nk8D/Br5XdCzVeH4B7FB0HDXi+iZwevXxFGD7omNq0HFtMb9Qmezh+9Wf417gtqLj3opjeBMwrfr47WU7hnqPY1i7H1G5J+uEouPeiv+L7YH7gZnV568qOu6tOIa/A75Ufbwj8BtgStGxj4hxs3+jy/57PYb/i1IfRyfkJ3NTeb46IT81Kzd1wxXCg4CVmbkqM9cBVwDHFRwTmfljKj9kpZGZT2TmndXHzwIPALsUG1XlhvnMfK76dHL1q/CbXyNiBvCnwCVFx1JmEfFyKgnsUoDMXJeZzxQaVOPUk1+OAy6v/hwvBbaPiJ1aHehmbPEYMvNnmbm2+nQplXXOyqbeXP9XwHeAJ1sZXJ3qOYb3At/NzF8CZGbZjqOeY0hgu4gIYFsqfwsHWhvm5tXxN7rsv9dgfioLc1N5tH1+alZu6oaCcBfg0WHP+ylBkVN2ETEL2J/K1bjCRWVo5nIqifLGzCxDXOcBfwsMFhzHcAncEBF9EbGo6GCqZgNPAf8rKsNrL4mIlxUdVIPUk1/KnoPGGt9pVHofy2aLxxERuwB/BlxMOdXzf/E6YFpE3FL9PT+lZdHVp55juADYi8ri6fcAH8vMMuXRepT99xrMT2VhbiqPbshPW/U73Q0FYdTYVvjVpTKLiG2p9FJ9PDN/V3Q8AJm5ITP3o9Lzd1BE7FNkPBFxDPBkZvYVGUcNb87MA6gMmzkzIg4pOiAqy9scAHwtM/cHngdKcS9vA9STX8qeg+qOLyIOo3LCdVZTI9o69RzHecBZmbmh+eFslXqOYRIwn8rohKOAcyLidc0ObAzqOYajgOXAzsB+wAXVkQTtpOy/12B+KgtzU3l0Q37aqt/pbigI+4Fdhz2fQaXqVw0RMZlKMbgkM79bdDwjVYca3gIsLDYS3gwcGxG/oDLk4K0R8S/FhgSZ+Xj13yeBq6kMjyhaP9A/7KruVVQKxE5QT34pew6qK76ImEtlePRxmbmmRbGNRT3H0QNcUf29PQG4KCLe0ZLo6lPvz9MPMvP5zHwa+DFQpkk06jmG91MZWpaZuRL4OfD6FsXXKGX/vQbzU1mYm8qjG/LTVv1Od0NBeAewR0TsHhFTgJOA6wqOqZSq46UvBR7IzK8UHc+QiNgxIravPn4pcATwYJExZeanM3NGZs6i8jP1o8z88yJjioiXRcR2Q4+BI4HCZ7HNzF8Bj0bEntVNh1O58bwT1JNfrgNOqc781Qv8NjOfaHWgm7HFY4iImcB3gb/IzIcLiLEeWzyOzNw9M2dVf2+vAj6cmde0PNLR1fPzdC3wloiYFBHbAAuo3O9dFvUcwy+p5AEi4tXAnsCqlkY5fmX/vQbzU1mYm8qjG/LTVv1OT2p+XMXKzIGI+AjwQyqzC12WmfcVHBYR8S3gUGCHiOgHPpeZlxYbFW8G/gK4p3q/HsDfZeb1xYUEVGY//WZETKTSifHtzCzFMg8l82rg6kpdzyTgf2fmD4oNaaO/ApZUE/AqKj1wbW+0/BIRZ1Rfv5jKjHFHAyuBFyjZsdd5DJ8FplPptQYYyMyeomKupc7jKLV6jiEzH4iIHwB3U7l/+ZLMLLzjZ0id/w9fAL4REfdQGd50VvWKQmnU+htNZUKztvi9BvNTUTGPZG4qj07IT83KTZFZpqHikiRJkqRW6YYho5IkSZKkGiwIJUmSJKlLWRBKkiRJUpeyIJQkSZKkLmVBKEmSJEldyoJQkiRJkrqUBaEkSZIkdSkLQrWd6gL1kiRJksZpUtEBSPWIiCuBR4H9gX8H/luxEUmSJEntz4JQ7WJf4IHMPKzoQCRJkqROEZlZdAzSZkXEVOCXwM6ZOVB0PJIkSVKn8B5CtYO9gdssBiVJkqTGsiBUO9gXuLvoICRJkqROY0GodmBBKEmSJDWB9xBKkiRJUpfyCqEkSZIkdSkLQkmSJEnqUhaEkiRJktSlLAglSZIkqUtZEEqSJElSl7IglCRJkqQuZUEoSZIkSV3KglCSJEmSutT/H7Ycy7wjBih9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = np.linspace(lower_r, upper_r, steps)[:,None]\n",
    "fig, axs = plt.subplots(3,3,figsize=(15,10))\n",
    "\n",
    "fil = 0\n",
    "col = 0\n",
    "for i in range(len(Es)):\n",
    "    yy = Phis_t[i]\n",
    "    axs[fil,col].plot(rr, yy.squeeze(), \".\", label=f\"learning rate {lrs[i]}\")\n",
    "    axs[fil,col].set_xlabel(\"$r$\")\n",
    "    axs[fil,col].set_ylabel(\"$\\phi(x)$\")\n",
    "    axs[fil,col].legend(loc=\"best\")\n",
    "    axs[fil,col].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    if col == 2:\n",
    "       col = 0\n",
    "       fil = fil+1\n",
    "    else:\n",
    "       col = col+1\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "803f019e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-2.4352], grad_fn=<DivBackward0>),\n",
       " tensor([-2.3573], grad_fn=<DivBackward0>),\n",
       " tensor([nan], grad_fn=<DivBackward0>),\n",
       " tensor([-16.6694], grad_fn=<DivBackward0>),\n",
       " tensor([-9.3706], grad_fn=<DivBackward0>),\n",
       " tensor([0.8056], grad_fn=<DivBackward0>),\n",
       " tensor([-1.5839], grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa85a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64b99667",
   "metadata": {},
   "source": [
    "## With Xavier initialization and gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a1389fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x, loss_fn, optimizer):\n",
    "    x = x.to(device)\n",
    "    def closure():\n",
    "        loss = loss_fn(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fd19a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------- loss: tensor([19311.0273], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([163.5001], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([65.7142], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([64.6293], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([64.6129], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([64.6100], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([64.2555], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([63.9766], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([63.1931], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([63.1849], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([63.1849], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([63.1832], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([61.9904], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([60.5408], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([60.4135], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([60.2770], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([59.4695], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([59.4424], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([59.0265], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([54.0843], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([53.6277], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([53.6064], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([55.1691], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([52.5661], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([51.5270], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([44.5574], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([34.7434], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([23.5786], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([23.1018], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([22.9349], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([22.7106], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([21.7888], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([21.6611], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([21.6244], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([21.6078], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([21.5684], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([21.3773], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([21.2604], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([21.2308], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([21.2361], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([21.2112], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([21.2234], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([21.2106], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([21.2163], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([21.2156], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([21.2095], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([21.2184], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([21.2167], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([21.2124], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([21.2117], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([22.3659], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([21.3265], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([21.2746], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([21.2050], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([21.1852], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([34243.7695], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([14692.6533], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([17885.], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([17465.1465], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([14538.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([17516.1289], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([18776.9766], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([52371.8711], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([17595.3984], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([12654.0781], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([12003.8086], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([11929.1455], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([11921.6367], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([10519.7861], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([18182.0781], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([147.3471], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([97.7337], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([6.4600], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([15227.0303], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([15745.2529], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([16847.7090], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([11168.1221], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([7652.3569], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([4497.4263], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([21158.3301], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([125.6160], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([124.3274], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([117.8028], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([24674.5469], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([13349.6172], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([18002.7031], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([301.7223], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([97.8494], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([81.2480], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([79.2946], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([78.9716], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([78.7833], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([77.7329], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([73.2167], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([72.6383], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([67.1505], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([62.8207], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([62.4871], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([62.3351], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([62.2258], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([62.1668], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([62.1057], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([62.0679], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([62.0546], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([62.0543], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([62.0514], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([62.0525], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([62.0505], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([62.0494], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([61.8135], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([61.5744], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([61.5203], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([61.4930], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([12811.3018], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([63.3867], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([62.1020], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([61.9106], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([61.8349], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([61.7897], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([61.6823], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([61.3357], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([16587.8828], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([17668.0469], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([5475.1533], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([874.4505], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([403.3385], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([241.9328], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([168.5274], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([130.6237], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([109.5741], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([97.2941], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([89.8385], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([85.2289], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([82.3677], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([80.5946], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([79.4993], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([78.8226], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([78.4013], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([78.1331], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([77.9517], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([77.8059], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([77.6461], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([77.4780], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([77.3644], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([77.2975], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([77.2504], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([77.1769], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([76.7255], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([75.3993], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([73.6501], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([71.6488], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([69.3170], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([67.3271], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([65.6711], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([64.2733], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([62.9154], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([58.8831], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([50.8483], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([45.6782], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([40.9386], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([37.7020], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([35.2507], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([33.2742], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([31.4209], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([29.4759], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([27.5089], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([25.7995], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([24.5620], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([23.7256], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([23.1802], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([22.7910], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([22.5403], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([22.3702], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([22.2546], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([22.1769], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([22.1264], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([22.0899], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([22.0622], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([22.0410], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([22.0230], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([21.9339], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([959472.], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([660268.0625], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([431597.2188], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([252660.8281], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([168944.0781], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([122339.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([92118.8984], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([71010.4062], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([55022.3047], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([40917.5195], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([28933.3633], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([20776.9316], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([15497.9727], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([11752.2852], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([9009.6904], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([6794.1602], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([4664.2031], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([3617.0708], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([2216.3242], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([1850.9838], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([1361.0074], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([1268.5702], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([1223.5879], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([1092.3967], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([1047.2821], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85\n",
      " ---------------------- loss: tensor([1007.0178], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([957.4937], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([958.6854], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([959.8870], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([962.8187], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([978.1223], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([913.7145], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([914.4216], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([915.1309], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([915.8453], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([917.5476], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([921.5875], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([876.3181], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([889.1479], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([841.5455], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([747.7269], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([695.5972], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([655.0314], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([655.3206], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([655.4693], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([655.7613], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([656.0633], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([656.3751], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([656.6951], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([656.9404], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([657.3569], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([657.7857], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([658.2365], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([658.6279], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([659.4323], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([660.3013], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([661.2993], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([664.5554], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([4029.2124], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([4029.2129], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([4029.2129], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([4029.2139], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([4029.2144], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([4029.2144], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([4029.2151], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([4029.2151], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([4029.2151], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([4029.2151], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([4029.2161], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([4029.2161], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([4029.2166], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([4029.2178], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([4029.2183], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([4029.2183], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([4029.2188], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([4029.2195], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([4029.2205], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([4029.2205], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([4029.2209], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([4029.2209], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([4029.2217], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([4029.2222], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([4029.2222], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([4029.2222], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([4029.2222], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([37649.3945], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([37649.0078], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([37648.6211], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([37648.2266], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([37647.8359], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([37647.4609], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([37647.0586], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([37646.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([37646.4805], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([37646.0781], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([37645.6914], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([37645.2852], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([37644.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([37644.4883], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([37644.0938], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([37643.6914], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([37643.2930], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([37642.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([37642.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([37642.0820], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([37641.6719], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([37641.2734], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([37640.8555], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([37640.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([37640.0312], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([37639.6289], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([37639.2070], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([37638.7930], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([37638.3828], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([37637.9648], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([37637.5430], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([37637.1289], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([37636.7070], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([37636.2891], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([37635.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([37635.4375], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([37635.0078], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([37634.5742], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([37634.1445], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184\n",
      " ---------------------- loss: tensor([37633.7227], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([37633.2891], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([37632.8555], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([37632.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([37631.9766], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([37631.5469], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([37631.1055], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([37630.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([37630.2383], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([37629.7773], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([37629.3320], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([37628.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([37628.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([37627.9844], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([37627.5312], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([37627.0898], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([37626.6250], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([37626.1602], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([37625.7188], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([37625.2500], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([37624.7969], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([37624.3281], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([37623.8672], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([37623.3906], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([37622.9258], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([37622.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([37621.9805], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([37621.5000], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([37621.0234], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([37620.5469], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([37620.0664], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([37619.5859], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([37619.0938], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([37618.6094], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([37618.1133], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([37617.6250], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([37617.1289], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([37616.6367], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([37616.1484], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([37615.6328], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([37615.1406], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([37614.6250], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([37614.1250], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([37613.6250], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([37613.0977], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([37612.5820], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([37612.0742], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([37611.5586], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([37611.0312], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([37610.5195], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([37609.9805], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([37609.4609], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([37608.9180], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([37608.3906], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([37607.8516], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([37607.3008], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([37606.7578], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([37606.2070], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([37605.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([37605.1055], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([37604.5469], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([37603.9961], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([37603.4414], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([37602.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([37602.3047], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([37601.7383], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([37601.1641], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([37600.5820], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([37600.0117], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([37599.4180], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([37598.8438], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([37598.2383], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([37597.6484], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([37597.0508], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([37596.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([37595.8477], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([37595.2266], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([37594.6211], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([37593.9961], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([37593.3750], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([37592.7539], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([37592.1250], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([37591.4805], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([37590.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([37590.2148], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([37589.5664], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([37588.9023], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([37588.2578], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([37587.6094], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([37586.9414], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([37586.2578], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([37585.5938], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([37584.9062], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([37584.2266], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([37583.5391], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([37582.8438], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([37582.1406], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([37581.4375], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([37580.7305], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283\n",
      " ---------------------- loss: tensor([37580.0156], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([37579.2930], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([37578.5742], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([37577.8359], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([37577.1055], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([37576.3438], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([37575.6016], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([37574.8398], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([37574.0859], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([37573.3203], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([37572.5391], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([37571.7461], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([37570.9727], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([37570.1719], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([37569.3633], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([37568.5586], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([37567.7422], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([37566.9062], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([15711.7881], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([27617.9609], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([19514.5371], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([11388.5957], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([5903.0854], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([2483.3669], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([1249.3102], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([776.6931], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([547.2509], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([411.6884], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([319.0892], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([252.7439], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([207.0050], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([177.2007], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([159.4997], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([149.2835], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([142.9927], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([138.7460], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([135.4767], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([132.6553], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([130.6867], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([129.3706], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([128.2489], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([127.0857], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([125.8085], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([122.2137], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([117.6896], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([112.6637], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([103.9572], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([95.4610], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([81.3218], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([66.6376], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([60.5396], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([57.2194], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([55.0644], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([53.0858], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([51.2743], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([49.2468], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([46.3615], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([42.9270], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([39.8382], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([37.3140], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([35.2312], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([33.4879], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([32.0324], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([30.8353], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([29.8832], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([29.1242], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([28.5299], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([28.0569], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([27.6699], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([27.3095], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([26.9944], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([26.7226], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([26.4900], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([26.2591], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([25.9684], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([25.5815], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([24.8115], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([23.8527], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([22.9710], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([21.8469], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([21.1513], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([20.7027], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([4615.7246], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([4457.4810], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([4253.7905], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([3950.9319], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([3262.4368], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([38.3888], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([30.4004], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([26.7202], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([24.2537], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([21.5351], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([20.8696], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([21.1792], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([20.7045], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([20.0322], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([20.0253], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([19.9177], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([19.6430], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([19.7011], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83\n",
      " ---------------------- loss: tensor([19.6700], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([19.6058], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([993.4206], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([644.9944], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([133.4100], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([86.4530], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([7222.4194], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([7006.9419], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([6786.6304], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([6558.3672], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([6318.9224], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([6065.0840], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([5792.7905], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([5496.2520], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([5168.4150], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([4800.1147], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([4380.6294], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([3896.7993], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([3333.4417], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([2681.9727], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([1949.9358], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([29951.6758], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([16647.5703], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([82.0186], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([81.5653], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([81.0880], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([80.5883], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([80.0628], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([79.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([78.9428], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([78.2342], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([77.2441], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([75.9254], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([74.5777], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([73.4567], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([72.5567], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([71.7702], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([71.0247], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([70.3168], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([69.6848], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([69.1636], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([68.7477], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([68.3884], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([68.0299], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([67.6591], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([67.2879], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([66.8954], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([66.5759], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([66.3455], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([66.1099], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([65.8821], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([65.6872], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([65.3319], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([64.9810], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([64.7696], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([64.5729], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([64.4285], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([64.3274], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([64.2302], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([64.1649], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([64.0820], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([64.0302], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([63.9870], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([63.9302], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([63.8700], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([63.8064], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([70.9730], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([64.0454], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([63.8897], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([63.8195], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([63.7701], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([63.7344], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([63.6834], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([63.6280], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([63.5671], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([65.2822], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([65.2262], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([65.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([65.1173], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([65.0624], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([65.0058], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([64.9379], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([64.8722], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([64.8084], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([64.7488], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([64.6913], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([64.6342], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([64.5790], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([64.5281], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([64.4791], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([64.4316], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([64.3856], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([64.3415], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([64.2992], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([64.2572], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([64.2189], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([64.1809], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([64.1452], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([64.1101], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([64.0767], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([64.0447], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([64.0135], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([63.9831], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([63.9550], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([63.9268], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([63.8995], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([63.8735], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([63.8495], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([63.8260], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([63.8036], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([63.7795], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([63.7586], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91\n",
      " ---------------------- loss: tensor([63.7391], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([63.7195], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([63.7011], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([63.6840], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([63.6638], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([63.6453], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([63.6297], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([63.6125], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([63.5977], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([63.5837], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([63.5698], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([63.5571], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([63.5440], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([63.5318], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([63.5203], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([63.5071], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([63.4968], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([63.4855], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([63.4748], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([63.4645], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([63.4552], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([63.4458], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([63.4367], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([63.2912], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([63.2870], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([63.2828], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([63.2786], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([63.2737], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([63.2694], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([63.2685], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([63.2638], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([63.2592], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([63.2545], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([63.2486], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([63.2407], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([63.2309], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([63.2192], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([63.1990], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([893.4369], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([525.4142], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([19102.0156], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([19098.5547], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([19095.0820], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([19091.5996], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([19088.1055], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([19084.5938], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([19081.0742], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([19077.5410], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([19073.9922], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([19070.4414], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([19066.8730], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([19063.2930], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([19059.7070], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([19056.1016], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([19052.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([19048.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([19045.2227], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([19041.5703], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([19037.9160], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([19034.2441], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([19030.5723], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([19026.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([19023.1680], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([19019.4609], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([19015.7344], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([19011.9883], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([19008.2500], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([19004.4824], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([19000.7227], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([18996.9434], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([18993.1523], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([18989.3574], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([18985.5410], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([18981.7227], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([18977.8848], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([18974.0410], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([18970.2031], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([18966.3301], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([18962.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([18958.5723], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([18954.6875], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([18950.7832], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([18946.8770], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([18942.9570], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([18939.0215], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([18935.0801], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([18931.1270], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([18927.1719], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([18923.1992], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([18919.2188], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([18915.2266], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([18911.2285], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([18907.2148], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([18903.2012], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([18899.1738], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([18895.1328], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([18891.0879], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([18887.0352], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189\n",
      " ---------------------- loss: tensor([18882.9688], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([18878.9023], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([18874.8125], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([18870.7227], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([18866.6211], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([18862.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([18858.3906], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([18854.2617], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([18850.1289], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([18845.9844], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([18841.8359], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([18837.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([18833.5098], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([18829.3301], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([18825.1504], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([18820.9609], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([18816.7598], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([18812.5449], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([18808.3223], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([18804.1113], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([18799.8730], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([18795.6328], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([18791.3848], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([18787.1348], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([18782.8633], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([18778.6016], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([18774.3164], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([18770.0410], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([18765.7441], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([18761.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([18757.1367], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([18752.8223], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([18748.5059], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([18744.1895], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([18739.8457], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([18735.4922], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([18731.1562], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([18726.7969], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([18722.4336], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([18718.0742], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([18713.6973], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([18709.3184], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([18704.9375], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([18700.5371], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([18696.1387], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([18691.7344], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([18687.3262], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([18682.9004], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([18678.4805], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([18674.0488], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([18669.6055], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([18665.1641], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([18660.7227], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([18656.2754], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([18651.8105], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([18647.3535], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([18642.8809], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([18638.4043], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([18633.9238], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([18629.4336], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([18624.9453], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([18620.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([18615.9551], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([18611.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([18606.9336], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([18602.4160], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([18597.8965], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([18593.3672], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([18588.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([18584.2910], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([18579.7598], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([18575.2090], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([18570.6582], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([18566.1133], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([18561.5488], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([18556.9883], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([18552.4199], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([18547.8438], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([18543.2734], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([18538.6934], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([18534.0996], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([18529.5215], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([18524.9316], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([18520.3340], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([18515.7383], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([18511.1230], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([18506.5215], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([18501.9023], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([18497.2910], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([18492.6777], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([18488.0508], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([18483.4297], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([18478.8008], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([18474.1719], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([18469.5293], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([18464.8926], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([18460.2500], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286\n",
      " ---------------------- loss: tensor([18455.6035], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([18450.9551], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([18446.3027], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([18441.6484], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([18436.9902], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([18432.3418], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([18427.6699], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([18423.0078], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([18418.3438], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([18413.6738], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([18408.9980], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([18404.3203], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([18399.6504], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([18394.9668], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([18390.2852], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([17228.6914], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([815.2930], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([759.8396], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([652.9622], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([568.0397], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([508.6090], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([463.7617], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([427.6704], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([392.5691], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([349.5373], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([310.5845], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([280.8311], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([257.5286], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([238.5510], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([221.9931], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([205.2848], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([188.8388], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([175.1510], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([163.9726], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([154.1884], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([145.8666], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([139.0184], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([132.4173], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([125.7594], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([120.6722], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([116.3054], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([110.7815], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([106.9322], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([104.3439], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([101.4217], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([98.6296], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([96.7757], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([95.1986], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([93.6888], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([92.5591], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([91.6899], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([90.8870], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([90.2473], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([89.7713], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([89.3884], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([89.0828], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([88.8600], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([88.6833], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([88.5499], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([88.4515], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([88.3649], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([88.2848], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([88.2187], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([88.1512], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([88.0673], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([87.9645], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([87.8460], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([87.7243], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([87.5529], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([87.3205], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([87.0280], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([86.7968], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([86.5476], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([86.1544], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([85.7816], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([85.4895], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([85.2299], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([84.9128], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([84.3460], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([83.8932], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([82.9012], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([413.0392], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([404.9336], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([386.6342], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([354.9254], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([326.7651], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([306.2348], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([288.9115], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([270.8887], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([253.7941], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([240.1992], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([227.3374], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([215.6565], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([205.7699], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([190.0628], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([178.5509], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([171.8988], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([166.9424], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([162.8752], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([149.2193], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86\n",
      " ---------------------- loss: tensor([139.1024], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([133.2950], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([128.4193], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([121.7010], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([105.8119], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([99.4365], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([96.1829], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([93.9869], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([92.3515], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([91.0437], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([89.9703], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([88.9448], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([87.9992], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([86.9344], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([85.2859], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([84.5051], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([83.9472], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([83.1514], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([82.2307], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([81.3230], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([80.9684], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([80.1661], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([77.6362], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([76.8855], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([75.7485], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([74.7831], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([73.8218], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([72.4412], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([69.9514], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([67.8632], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([66.1970], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([64.3947], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([60.7466], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([56.8983], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([53.3649], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([50.5764], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([48.3166], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([47.0898], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([46.0685], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([45.1301], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([44.0632], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([42.8932], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([41.7893], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([40.9149], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([40.2179], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([39.6112], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([39.0107], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([38.5231], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([37.7927], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([37.3868], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([36.7192], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([36.2030], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([35.9128], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([35.5580], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([34.7954], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([34.7043], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([34.6290], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([34.5284], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([34.4416], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([33.1064], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([33.0826], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([33.0223], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([32.9916], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([32.9476], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([32.7927], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([32.7448], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([32.7103], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([32.6684], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([32.6031], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([32.5742], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([32.5145], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([32.4309], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([30.6173], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([26.0192], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([25.2291], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([24.7369], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([24.2799], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([23.8903], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([23.0840], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([22.5144], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([22.1938], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([21.9219], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([21.7237], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([21.5138], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([21.1597], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([20.8297], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([20.7716], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([20.6851], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([20.5370], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([20.4198], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([19.9319], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([19.6144], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([19.4671], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([19.3908], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([19.3466], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([19.2517], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([19.1368], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([2693.8054], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([753.0667], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([87.2732], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([73.9730], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([58.5548], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188\n",
      " ---------------------- loss: tensor([54.2221], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([214.5185], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([188.2704], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([157.3851], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([132.4431], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([122.3929], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([116.0927], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([110.1421], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([106.0636], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([102.6397], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([97.1274], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([92.9251], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([90.8984], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([88.3115], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([76.8684], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([73.9563], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([73.1088], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([72.2051], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([70.7104], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([69.4002], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([51.3296], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([51.0381], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([50.5191], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([50.0974], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([49.9323], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([49.6689], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([49.3311], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([47.6310], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([47.3667], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([46.9729], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([46.6434], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([46.3341], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([45.7048], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([45.2091], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([44.3039], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([44.0168], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([43.9455], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([43.7390], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([43.1202], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([42.9803], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([42.8647], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([42.7380], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([42.5283], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([37.1439], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([36.8983], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([32.6211], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([31.7230], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([30.2678], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([29.7105], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([29.5906], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([29.0782], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([28.5110], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([28.2143], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([28.0792], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([27.9816], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([27.8617], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([27.5482], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([867.3826], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([520.7431], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([424.2339], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([374.4187], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([339.2026], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([317.6076], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([298.1828], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([238.2024], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([230.0914], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([220.2562], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([210.5639], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([200.5788], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([193.0086], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([165.1829], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([160.7227], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([157.2280], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([150.5539], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([143.7601], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([140.0070], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([137.3723], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([134.4949], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([1775.8575], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([1477.3367], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([1352.7389], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([1268.8191], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([1202.7986], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([1147.6783], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([1095.9661], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([1017.6841], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([931.7105], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([870.2071], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([823.5717], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([785.1307], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([746.4991], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([709.7009], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([658.7757], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([610.7195], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([578.1612], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([552.6918], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([525.4096], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([499.2748], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([470.9696], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([434.4373], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([410.1805], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([392.2027], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290\n",
      " ---------------------- loss: tensor([375.3122], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([351.7608], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([333.6014], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([307.8561], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([284.4201], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([268.8671], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([254.8122], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([231.8185], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([216.9840], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([198.0767], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([181.8307], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([19423.9980], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([18817.3848], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([18144.7832], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([17689.], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([17325.7988], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([17010.4922], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([16721.9824], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([16246.2803], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([15632.0693], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([15122.4141], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([14671.7041], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([14239.5811], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([13787.6045], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([13277.3311], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([12769.8711], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([12317.9023], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([11878.4814], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([11331.4883], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([10612.9375], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([9881.7852], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([9265.8535], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([8497.7217], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([6652.6587], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([5412.8125], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([4442.0566], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([3727.8008], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([3228.6875], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([2847.7590], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([2534.4661], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([2309.7703], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([2136.1921], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([1994.9042], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([1877.8364], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([1775.2787], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([1674.2793], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([1568.7659], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([1464.7092], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([1370.4314], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([1287.2886], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([1213.7775], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([1149.6635], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([1093.9764], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([1039.8776], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([979.5723], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([920.2255], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([865.4346], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([813.7036], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([771.4500], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([739.5190], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([713.0060], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([668.2253], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([622.5139], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([587.3519], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([512.3933], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([473.9653], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([445.6735], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([406.7470], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([373.0240], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([347.7878], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([324.3879], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([303.2350], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([284.1327], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([267.1622], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([251.4435], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([238.3233], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([225.7904], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([213.9477], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([203.3202], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([194.3271], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([185.4422], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([177.1502], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([169.7266], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([163.2459], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([156.8971], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([151.1061], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([145.7998], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([141.0713], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([136.5547], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([132.3300], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([128.3252], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([124.8073], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([121.4791], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([118.1693], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([115.0710], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([112.2718], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([109.7090], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([106.9489], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([104.4365], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([101.9737], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([99.9945], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91\n",
      " ---------------------- loss: tensor([97.5597], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([95.5335], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([93.3399], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([91.6788], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([89.6151], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([87.9871], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([86.0599], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([84.7077], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([83.1896], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([81.8790], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([80.3560], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([79.2974], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([78.2724], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([77.2948], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([76.2128], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([75.3857], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([74.6694], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([73.9696], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([73.2098], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([72.5906], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([72.0687], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([71.5665], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([71.0202], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([70.5616], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([70.1936], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([69.8217], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([69.4284], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([69.1087], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([68.7800], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([68.5680], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([68.2654], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([68.0411], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([67.7906], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([67.6359], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([67.3063], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([67.1908], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([67.0387], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([66.9077], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([66.7821], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([66.6443], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([66.4299], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([66.3870], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([66.2943], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([66.1635], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([66.0877], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([66.0138], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([65.8819], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([65.7986], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([65.7403], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([65.6461], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([65.5929], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([65.5173], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([65.3343], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([65.2138], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([65.1856], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([64.5397], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([64.5348], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([64.5263], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([64.5162], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([64.5060], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([64.4962], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([64.4798], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([64.4655], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([64.1365], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([64.0005], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([63.9283], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([63.8782], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([63.8382], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([63.8025], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([63.7691], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([63.7322], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([63.6999], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([63.6717], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([63.6305], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([63.5993], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([63.5504], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([63.5053], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([63.4719], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([63.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([63.4193], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([63.3981], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([63.3777], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([63.3601], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([63.3437], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([63.3280], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([63.3137], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([63.3007], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([63.2883], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([63.2756], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([63.2642], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([63.2537], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([63.2432], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([63.1707], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([63.1513], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([63.1364], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([63.1224], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([63.1073], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([63.0972], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([16587.8906], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([15802.4834], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([18175.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([17698.9629], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([17485.9902], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([17316.7676], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([17161.9961], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([17008.3574], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([16829.0508], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([16615.2754], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([16421.9316], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      " ---------------------- loss: tensor([16225.3359], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([15959.7109], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([15549.4971], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([15115.0264], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([14535.2393], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([13558.0869], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([12763.1816], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([12121.7637], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([11547.9863], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([11069.5088], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([10664.1387], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([10270.1514], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([9890.9756], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([9521.3633], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([9045.5986], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([8646.5664], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([8331.5918], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([8055.4355], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([7791.3872], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([7523.0615], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([7256.0044], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([6999.1470], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([6706.6021], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([6042.4692], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([2958.1687], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([2597.3535], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([2383.2227], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([2208.3982], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([2047.4957], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([1882.3986], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([1726.7736], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([1565.6438], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([1342.4141], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([1141.1179], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([1006.5760], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([906.0153], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([824.7898], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([757.9489], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([706.5645], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([666.3822], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([631.5841], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([600.4261], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([573.2881], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([550.0988], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([530.5472], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([513.7714], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([498.7959], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([485.0151], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([472.3601], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([460.7245], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([450.6788], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([442.5126], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([435.6626], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([429.2128], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([422.6350], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([415.8962], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([409.2224], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([403.5357], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([399.2636], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([395.9133], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([393.0610], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([389.3398], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([385.3040], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([381.4619], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([377.2716], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([373.8423], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([371.3553], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([368.5062], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([365.0202], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([361.8854], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([358.7477], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([355.1243], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([351.3194], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([347.4255], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([343.3219], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([338.9680], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([334.5615], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([329.9965], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([323.5337], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([314.2127], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([308.3286], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([304.1557], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([300.8916], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([298.6296], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([296.6915], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([295.0472], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([293.9016], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([293.1091], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([292.2654], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([291.4767], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([290.3979], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([289.0079], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([287.2966], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([285.1721], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([282.7740], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([276.0398], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([268.6176], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([260.9263], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([255.0000], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([250.3829], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([246.4835], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([241.9249], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113\n",
      " ---------------------- loss: tensor([236.2513], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([232.2421], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([229.1885], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([226.5193], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([222.7535], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([219.8243], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([217.8792], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([216.4976], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([215.4262], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([214.4104], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([213.6786], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([213.2032], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([212.8579], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([212.4916], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([212.1882], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([211.9557], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([211.4402], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([209.3816], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([207.5225], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([205.1160], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([201.9928], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([199.0753], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([196.8100], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([195.1589], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([193.7172], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([190.2624], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([187.4815], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([185.5834], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([184.3903], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([183.4461], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([182.4569], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([180.6072], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([179.2830], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([178.2329], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([177.3090], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([176.4269], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([175.5764], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([174.8174], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([174.1361], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([173.5289], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([172.9700], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([172.2641], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([171.1824], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([169.8106], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([167.9630], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([166.5002], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([165.3293], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([163.9298], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([162.0280], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([160.0773], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([158.0301], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([155.9444], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([153.9424], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([151.9265], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([149.7613], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([147.5547], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([145.4271], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([143.4497], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([141.5819], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([139.8671], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([138.3308], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([137.0013], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([135.6896], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([133.3670], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([131.3579], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([128.8119], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([126.7261], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([125.2865], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([124.2250], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([123.3726], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([122.6364], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([120.9569], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([119.3490], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([118.2745], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([116.1936], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([114.6434], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([113.6756], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([112.6959], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([111.5844], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([110.7787], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([110.1836], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([109.6874], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([109.2472], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([108.8654], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([108.4794], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([107.2292], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([105.8378], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([103.7539], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([102.3781], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([101.3356], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([100.4055], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([99.1832], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([97.9085], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([96.8433], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([95.8932], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([95.0508], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([94.3384], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([93.7116], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([93.1619], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212\n",
      " ---------------------- loss: tensor([92.6910], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([92.2935], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([91.9605], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([91.6785], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([90.7549], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([89.8169], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([89.1672], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([88.6129], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([88.2261], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([87.9335], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([87.6653], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([87.4135], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([87.1969], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([87.0181], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([86.8616], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([86.7015], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([86.3354], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([85.9340], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([85.5513], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([85.3437], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([85.1977], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([85.0484], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([84.9648], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([84.8832], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([84.7722], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([84.5941], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([84.4538], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([84.1973], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([84.0236], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([83.9085], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([83.8097], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([83.7310], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([83.6509], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([83.5874], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([83.5197], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([83.4499], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([83.3646], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([83.2274], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([83.1134], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([83.0312], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([82.9535], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([82.8988], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([82.8576], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([82.7970], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([82.7191], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([82.6535], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([82.6004], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([82.5609], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([82.5260], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([82.4784], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([82.4072], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([82.3440], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([82.2923], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([82.2441], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([82.2052], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([82.1711], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([82.1051], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([82.0611], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([82.0258], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([82.0035], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([81.9840], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([81.9708], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([81.9022], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([81.8127], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([81.7499], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([81.7063], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([81.6727], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([81.6454], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([81.5788], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([81.5395], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([81.4037], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([81.3224], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([81.3077], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([81.2877], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([81.2635], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([81.2404], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([81.1739], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([81.1240], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([81.0932], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([81.0685], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([81.0465], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([81.0233], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([80.8637], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([80.8124], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([80.7850], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([80.7565], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([80.7110], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([80.6403], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([80.5090], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([15578.1826], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([16751.4609], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([16751.4648], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([16751.4648], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([16751.4629], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([16751.4629], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([16751.4629], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([16751.4629], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([16751.4629], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([16751.4590], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([16751.4590], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([16751.4590], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([16751.4590], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([16751.4590], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([16751.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([16751.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([16751.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([16751.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([16751.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([16751.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([16751.4609], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([16751.4609], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([16751.4609], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([16751.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([16751.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([16751.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([16751.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([16751.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([16751.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([16751.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([16751.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39\n",
      " ---------------------- loss: tensor([16751.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([16751.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([16751.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([16751.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([16751.4512], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([16751.4512], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([16751.4512], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([16751.4512], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([16751.4512], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([16751.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([16751.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([16751.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([16751.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([16751.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([16751.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([16751.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([16751.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([16751.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([16751.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([16751.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([16751.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([16751.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([16751.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([16751.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([16751.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([16751.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([16751.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([16751.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([16751.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([16751.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([16751.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([16751.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([16751.4395], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([16751.4395], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([16751.4395], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([16751.4395], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([16751.4434], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([16283.5127], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([16148.0371], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([16021.3428], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([15923.3525], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([15838.9014], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([15759.7256], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([15661.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([15530.7676], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([15410.1025], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([15297.5693], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([15178.1807], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([15044.1436], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([14906.8848], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([14781.2441], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([14640.8096], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([14342.5225], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([7767.8975], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([7514.4604], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([7351.6460], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([7214.6655], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([7090.0591], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([6973.2075], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([6841.6318], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([6699.5957], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([6536.4761], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([6374.6353], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([6152.2559], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([5900.1387], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([5695.4863], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([5473.7886], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([5131.7935], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([4714.0439], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([4318.1841], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([3944.6592], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([3649.4421], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([3405.8936], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([3168.7920], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138\n",
      " ---------------------- loss: tensor([2941.8992], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([2729.4089], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([2495.6646], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([2258.1382], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([2059.8198], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([1885.5251], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([1719.0076], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([1566.5428], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([1441.1930], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([1335.8652], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([1223.2686], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([1086.1929], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([980.8981], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([900.2111], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([809.9568], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([730.0430], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([660.5655], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([619.4118], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([522.8899], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([484.4840], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([459.7252], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([440.4264], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([416.8213], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([400.4368], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([390.1867], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([380.4261], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([366.8826], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([358.0526], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([351.3380], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([344.3365], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([338.0544], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([333.1399], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([328.5364], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([323.9767], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([320.1194], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([316.8575], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([313.9509], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([310.9515], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([308.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([306.6190], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([304.8022], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([302.3033], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([299.5366], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([293.9631], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([288.2267], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([279.9431], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([275.0948], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([271.6240], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([266.1109], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([261.0976], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([257.4868], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([253.6144], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([250.2860], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([247.4916], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([244.5253], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([241.5303], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([239.0228], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([236.6571], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([234.5417], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([232.5335], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([230.7554], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([229.1100], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([227.5348], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([226.1333], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([224.8196], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([223.6802], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([222.6483], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([221.6739], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([220.8335], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([219.8288], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([218.4779], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([216.9684], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([215.1813], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([213.6893], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([212.7702], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([211.9428], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([211.1398], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([210.3784], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([209.6864], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([209.0719], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([208.3657], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([207.1555], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([205.4207], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([204.6604], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([203.8070], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([203.0910], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([202.5733], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([202.0598], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([201.5797], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([200.9536], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([200.2451], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([199.2676], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([198.4880], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([197.5293], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([197.1927], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([196.3260], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([195.9778], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([192.6985], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([192.5923], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237\n",
      " ---------------------- loss: tensor([192.5062], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([192.3930], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([192.0901], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([191.3098], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([190.5251], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([189.5831], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([189.0175], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([188.4361], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([187.8662], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([186.2998], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([186.0928], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([185.7407], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([185.4919], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([185.2358], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([184.7939], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([184.2059], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([183.6487], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([183.1894], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([182.7145], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([182.3780], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([182.0956], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([181.8296], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([181.3678], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([181.0838], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([180.7637], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([180.2670], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([179.9151], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([179.5888], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([179.1035], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([178.6529], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([178.4393], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([178.1326], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([177.9248], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([177.7360], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([177.1613], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([177.0219], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([176.8145], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([176.6554], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([176.4960], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([176.2499], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([175.6066], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([175.3793], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([174.8781], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([174.7676], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([174.4848], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([174.3159], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([174.2096], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([173.2257], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([173.1651], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([173.1031], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([172.9777], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([172.8271], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([172.4758], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([170.7787], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([170.7167], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([170.6218], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([170.4116], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([169.7559], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([169.5819], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([169.4676], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([169.3216], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([169.1495], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([169.0531], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([168.8302], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upper_r = 6\n",
    "lower_r = 1e-2\n",
    "steps = 100\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "epochs = 300\n",
    "lrs = [1e-1, 5e-2, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5]\n",
    "Phis_t = []\n",
    "Es = []\n",
    "\n",
    "for lr in lrs:\n",
    "    model = NeuralNetwork().to(device)\n",
    "    initialize_weights(model)\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n ---------------------- loss: {loss_fn(R_train.to(device))}\")\n",
    "        training(R_train, loss_fn, optimizer)\n",
    "    print(\"Done!\\n\\n\")\n",
    "    Phis_t.append(Phi_t(R_train).detach().numpy())\n",
    "    Es.append(E.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "147400e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = np.linspace(lower_r, upper_r, steps)[:,None]\n",
    "fig, axs = plt.subplots(3,3,figsize=(15,10))\n",
    "\n",
    "fil = 0\n",
    "col = 0\n",
    "for i in range(len(Es)):\n",
    "    yy = Phis_t[i]\n",
    "    axs[fil,col].plot(rr, yy.squeeze(), \".\", label=f\"learning rate {lrs[i]}\")\n",
    "    axs[fil,col].set_xlabel(\"$r$\")\n",
    "    axs[fil,col].set_ylabel(\"$\\phi(x)$\")\n",
    "    axs[fil,col].legend(loc=\"best\")\n",
    "    axs[fil,col].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    if col == 2:\n",
    "       col = 0\n",
    "       fil = fil+1\n",
    "    else:\n",
    "       col = col+1\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c859117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-13.725535], dtype=float32),\n",
       " array([-16.66944], dtype=float32),\n",
       " array([-46.313175], dtype=float32),\n",
       " array([-31.324167], dtype=float32),\n",
       " array([-18.9474], dtype=float32),\n",
       " array([0.5863087], dtype=float32),\n",
       " array([-16.669441], dtype=float32),\n",
       " array([0.9039318], dtype=float32),\n",
       " array([1.8452773], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105a26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef7d4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x, loss_fn, optimizer):\n",
    "    x = x.to(device)\n",
    "    def closure():\n",
    "        loss = loss_fn(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99517e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------- loss: tensor([15006.7773], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([19447.0664], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([16223.8066], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([16216.6865], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([16207.5947], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([16196.0264], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([16181.1982], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([15830.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([15547.6006], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([15354.9043], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([15195.1279], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([15044.6416], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([14873.5791], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([14583.2529], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([14331.5771], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([14141.4004], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([13974.0020], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([13743.1416], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([13329.7129], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([12886.3438], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([12322.0244], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([10337.2158], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([9376.4502], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([8790.7158], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([8260.8301], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([7803.3916], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([7406.8687], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([6963.5156], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([6495.2617], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([6072.6689], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([5665.9307], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([5295.5981], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([4968.8555], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([4650.2822], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([4346.6255], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([4058.3501], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([3819.9272], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([3653.2043], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([3531.1975], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([3386.3301], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([3241.2654], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([3129.6870], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([3040.1904], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([2963.2263], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([2895.5881], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([2834.5835], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([2769.0735], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([2693.6890], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([2619.9092], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([2547.9302], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([2472.6765], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([2406.6848], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([2356.0034], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([2313.8684], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([2277.0876], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([2228.8398], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([2165.1455], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([2101.0259], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([2037.1388], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([1982.3134], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([1942.7751], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([1904.1631], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([1860.1167], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([1816.5723], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([1777.7401], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([1731.8318], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([1693.6252], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([135.3243], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([134.2537], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([128.5957], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([127.4223], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([126.2053], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([124.4814], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([123.8371], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([114.7659], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([114.4239], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([114.0637], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([113.6070], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([112.5334], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([111.8507], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([103.4292], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([103.0313], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([102.8984], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([102.5412], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([102.3208], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([98.7389], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([98.5932], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([98.1216], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([97.2549], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([91.5510], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([90.9837], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([90.9349], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([90.8541], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([90.7986], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([90.7445], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([90.6692], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([89.4047], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([88.8356], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([88.5977], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([87.9073], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101\n",
      " ---------------------- loss: tensor([85.4976], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([85.4601], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([85.4265], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([85.3400], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([85.2609], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([85.0690], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([84.3458], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([83.9504], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([82.7745], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([82.4263], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([82.3450], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([82.3050], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([82.2838], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([82.2521], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([82.0586], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([82.0061], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([81.4179], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([80.7087], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([79.6161], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([79.3806], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([79.2945], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([79.0451], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([78.6066], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([78.4272], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([78.0019], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([77.8640], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([77.2546], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([76.1325], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([75.7320], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([75.4563], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([75.2997], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([75.2678], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([75.2033], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([75.1041], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([75.0325], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([74.9473], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([74.8648], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([74.8400], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([73.9857], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([17095.4824], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([16890.4355], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([16844.3633], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([16758.9121], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([16691.1426], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([16630.1582], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([16566.4512], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([16456.1055], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([16319.0449], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([16154.1445], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([15961.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([15751.1074], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([15512.3750], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([15185.3760], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([7165.6787], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([7114.9980], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([7064.0908], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([7012.9722], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([6961.6001], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([6910.0264], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([6858.2271], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([6806.1646], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([6753.8608], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([6701.3145], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([6648.5210], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([6595.4956], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([6542.1890], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([6488.6426], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([6434.8267], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([6380.7622], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([6326.4478], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([6271.8691], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([6217.0088], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([6161.9014], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([6106.5044], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([6050.8530], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([5994.9170], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([5938.7485], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([5882.2935], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([5825.5430], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([5768.5117], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([5711.1978], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([5653.6245], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([5595.7905], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([5537.6714], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([5479.2798], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([5420.5903], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([5361.6528], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([5302.4160], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([5242.9155], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([5183.1797], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([5123.1475], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([5062.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([5002.3438], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([4941.5273], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([4880.4722], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([4819.1948], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([4757.6748], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([4695.9253], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([4633.8887], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200\n",
      " ---------------------- loss: tensor([4571.6343], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([30606.8848], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([18754.8477], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([17707.4883], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([17683.9980], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([17647.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([17588.9434], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([17496.5527], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([17298.8730], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([17119.6855], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([16970.5234], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([16811.2969], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([16593.9727], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([16293.5254], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([15941.6924], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([11977.1104], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([8848.4463], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([8480.2480], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([8237.7158], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([8041.8037], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([7861.5522], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([7687.5884], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([7457.7437], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([7234.6846], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([7052.9312], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([6876.9976], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([6617.8257], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([6347.2661], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([6112.7119], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([5717.2139], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([5400.1533], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([5135.3413], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([4843.5024], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([4601.1216], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([4393.0298], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([4174.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([4001.2197], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([3861.6155], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([3727.3552], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([3591.9277], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([3478.7737], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([3386.1777], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([3304.0076], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([3222.5144], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([3143.2349], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([3074.9395], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([3015.3005], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([2955.4199], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([2892.7966], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([2836.1858], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([2787.8408], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([2739.4099], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([2692.9871], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([2652.9983], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([2619.6155], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([2588.0442], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([2559.2083], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([2534.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([2514.9580], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([2497.4185], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([2481.7642], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([2464.6370], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([2457.3286], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([2399.3430], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([2361.1040], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([2294.7576], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([2225.9048], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([2180.3999], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([2108.8516], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([2025.7340], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([1955.1442], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([1901.1608], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([1843.4001], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([1788.4104], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([1726.1470], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([1673.4686], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([1629.4690], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([1588.9830], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([1547.8850], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([1505.5945], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([1464.9685], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([1423.7742], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([1381.1178], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([1334.8344], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([1283.1188], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([1220.7544], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([1131.3262], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([971.4210], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([844.7653], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([764.2334], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([704.0751], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([652.8489], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([605.3218], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([559.9017], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([512.0069], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([458.9187], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([393.6839], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([342.0290], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([309.4145], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([284.2329], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      " ---------------------- loss: tensor([236.6245], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([230.8966], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([2715.5647], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([2655.8384], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([2605.5159], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([2540.2952], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([2487.7207], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([2445.4226], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([2407.1680], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([2347.2695], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([2285.3660], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([2230.0706], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([2174.4431], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([2120.8252], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([2070.9241], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([2023.0389], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([1977.3247], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([1936.5193], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([1898.8967], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([1864.6738], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([1834.6431], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([1808.1117], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([1784.0682], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([1762.9750], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([1740.9740], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([1725.1538], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([1707.7513], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([1694.8816], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([1683.0659], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([1668.8783], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([1641.3757], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([1619.2219], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([1600.8584], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([1588.1943], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([1574.5844], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([1545.6586], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([1518.8114], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([1486.5724], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([1452.3533], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([1421.4086], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([1391.9404], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([1351.0236], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([1313.6025], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([1275.2965], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([1239.8071], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([1198.2332], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([1164.1577], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([1134.2966], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([1087.9696], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([1053.2693], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([1017.6978], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([989.1306], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([960.2763], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([931.5372], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([905.1588], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([879.1375], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([848.4937], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([821.4821], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([794.3217], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([769.0774], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([746.4691], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([726.6407], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([705.4536], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([686.4025], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([667.3447], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([646.4485], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([625.6221], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([604.2997], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([586.2805], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([569.9736], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([554.7856], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([540.4227], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([526.5139], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([513.4552], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([499.5471], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([486.0022], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([471.3693], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([457.4682], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([444.1945], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([432.4490], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([421.7254], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([411.0170], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([401.7524], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([391.5977], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([381.6951], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([369.9111], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([360.2759], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([349.9518], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([341.0482], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([332.1076], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([324.7846], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([317.9522], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([311.1728], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([304.4836], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([296.2847], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([288.4536], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([280.5653], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([272.7875], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([266.6222], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199\n",
      " ---------------------- loss: tensor([260.6058], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([255.0815], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([249.8629], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([243.8585], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([239.7854], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([233.2427], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([227.3315], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([220.9397], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([212.9521], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([207.7999], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([204.5863], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([201.5747], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([197.6659], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([194.6954], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([191.2643], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([186.9974], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([182.5002], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([177.7804], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([172.3464], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([169.1591], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([166.4931], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([163.9152], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([161.6774], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([159.4274], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([154.8552], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([151.6336], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([146.7837], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([143.1950], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([141.4571], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([139.2458], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([135.2299], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([134.1475], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([131.8182], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([130.1117], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([128.1126], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([124.6938], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([120.9928], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([118.7724], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([116.1479], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([114.3782], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([112.6991], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([111.3800], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([106.2041], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([158000.1250], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([156169.9375], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([155370.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([154769.7656], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([154232.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([153850.2188], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([153281.8906], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([152554.0938], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([151934.1094], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([151374.3594], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([150779.5938], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([150175.5156], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([149625.4688], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([149149.5938], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([148679.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([148195.7656], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([147634.2812], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([147060.0781], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([146571.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([146099.1719], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([145646.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([145158.7656], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([144495.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([143886.0781], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([143286.3594], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([142762.6875], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([142322.5000], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([141849.0156], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([141384.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([140803.0312], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([140076.1562], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([139402.5312], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([138873.], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([138393.0781], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([137797.4688], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([137213.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([136439.2812], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([136007.1406], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([135127.3438], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([134400.3594], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([133820.2969], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([133200.3281], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([132571.9375], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([132004.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([131471.1719], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([130971.0859], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([130470.1484], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([129750.2578], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([128884.5078], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([128150.0547], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([127465.7109], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([126920.0469], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([126464.0547], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([125995.4375], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([125133.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([124242.5859], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298\n",
      " ---------------------- loss: tensor([123314.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([122549.5312], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([121786.7656], grad_fn=<DivBackward0>)\n",
      "Epoch 301\n",
      " ---------------------- loss: tensor([121121.7812], grad_fn=<DivBackward0>)\n",
      "Epoch 302\n",
      " ---------------------- loss: tensor([120579.4766], grad_fn=<DivBackward0>)\n",
      "Epoch 303\n",
      " ---------------------- loss: tensor([120056.1641], grad_fn=<DivBackward0>)\n",
      "Epoch 304\n",
      " ---------------------- loss: tensor([119317.0312], grad_fn=<DivBackward0>)\n",
      "Epoch 305\n",
      " ---------------------- loss: tensor([118487.4062], grad_fn=<DivBackward0>)\n",
      "Epoch 306\n",
      " ---------------------- loss: tensor([117724.1484], grad_fn=<DivBackward0>)\n",
      "Epoch 307\n",
      " ---------------------- loss: tensor([116700.2422], grad_fn=<DivBackward0>)\n",
      "Epoch 308\n",
      " ---------------------- loss: tensor([115896.3281], grad_fn=<DivBackward0>)\n",
      "Epoch 309\n",
      " ---------------------- loss: tensor([115204.3750], grad_fn=<DivBackward0>)\n",
      "Epoch 310\n",
      " ---------------------- loss: tensor([114677.7500], grad_fn=<DivBackward0>)\n",
      "Epoch 311\n",
      " ---------------------- loss: tensor([113887.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 312\n",
      " ---------------------- loss: tensor([113456.1641], grad_fn=<DivBackward0>)\n",
      "Epoch 313\n",
      " ---------------------- loss: tensor([109772.5078], grad_fn=<DivBackward0>)\n",
      "Epoch 314\n",
      " ---------------------- loss: tensor([109600.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 315\n",
      " ---------------------- loss: tensor([109428.6719], grad_fn=<DivBackward0>)\n",
      "Epoch 316\n",
      " ---------------------- loss: tensor([109256.3672], grad_fn=<DivBackward0>)\n",
      "Epoch 317\n",
      " ---------------------- loss: tensor([109084.], grad_fn=<DivBackward0>)\n",
      "Epoch 318\n",
      " ---------------------- loss: tensor([108911.4297], grad_fn=<DivBackward0>)\n",
      "Epoch 319\n",
      " ---------------------- loss: tensor([108739.2188], grad_fn=<DivBackward0>)\n",
      "Epoch 320\n",
      " ---------------------- loss: tensor([108566.6484], grad_fn=<DivBackward0>)\n",
      "Epoch 321\n",
      " ---------------------- loss: tensor([108393.8125], grad_fn=<DivBackward0>)\n",
      "Epoch 322\n",
      " ---------------------- loss: tensor([108220.6016], grad_fn=<DivBackward0>)\n",
      "Epoch 323\n",
      " ---------------------- loss: tensor([108047.0938], grad_fn=<DivBackward0>)\n",
      "Epoch 324\n",
      " ---------------------- loss: tensor([107873.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 325\n",
      " ---------------------- loss: tensor([107699.5781], grad_fn=<DivBackward0>)\n",
      "Epoch 326\n",
      " ---------------------- loss: tensor([107525.5000], grad_fn=<DivBackward0>)\n",
      "Epoch 327\n",
      " ---------------------- loss: tensor([107350.9688], grad_fn=<DivBackward0>)\n",
      "Epoch 328\n",
      " ---------------------- loss: tensor([107176.5078], grad_fn=<DivBackward0>)\n",
      "Epoch 329\n",
      " ---------------------- loss: tensor([107001.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 330\n",
      " ---------------------- loss: tensor([106826.7422], grad_fn=<DivBackward0>)\n",
      "Epoch 331\n",
      " ---------------------- loss: tensor([106651.7812], grad_fn=<DivBackward0>)\n",
      "Epoch 332\n",
      " ---------------------- loss: tensor([106476.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 333\n",
      " ---------------------- loss: tensor([106300.6953], grad_fn=<DivBackward0>)\n",
      "Epoch 334\n",
      " ---------------------- loss: tensor([106124.9219], grad_fn=<DivBackward0>)\n",
      "Epoch 335\n",
      " ---------------------- loss: tensor([105948.7500], grad_fn=<DivBackward0>)\n",
      "Epoch 336\n",
      " ---------------------- loss: tensor([105772.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 337\n",
      " ---------------------- loss: tensor([105596.1016], grad_fn=<DivBackward0>)\n",
      "Epoch 338\n",
      " ---------------------- loss: tensor([105419.4297], grad_fn=<DivBackward0>)\n",
      "Epoch 339\n",
      " ---------------------- loss: tensor([105242.7422], grad_fn=<DivBackward0>)\n",
      "Epoch 340\n",
      " ---------------------- loss: tensor([105063.9297], grad_fn=<DivBackward0>)\n",
      "Epoch 341\n",
      " ---------------------- loss: tensor([104886.7969], grad_fn=<DivBackward0>)\n",
      "Epoch 342\n",
      " ---------------------- loss: tensor([104709.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 343\n",
      " ---------------------- loss: tensor([104532.0938], grad_fn=<DivBackward0>)\n",
      "Epoch 344\n",
      " ---------------------- loss: tensor([104354.7578], grad_fn=<DivBackward0>)\n",
      "Epoch 345\n",
      " ---------------------- loss: tensor([104177.2109], grad_fn=<DivBackward0>)\n",
      "Epoch 346\n",
      " ---------------------- loss: tensor([103999.6797], grad_fn=<DivBackward0>)\n",
      "Epoch 347\n",
      " ---------------------- loss: tensor([103822.1562], grad_fn=<DivBackward0>)\n",
      "Epoch 348\n",
      " ---------------------- loss: tensor([103644.3672], grad_fn=<DivBackward0>)\n",
      "Epoch 349\n",
      " ---------------------- loss: tensor([103466.5703], grad_fn=<DivBackward0>)\n",
      "Epoch 350\n",
      " ---------------------- loss: tensor([103288.2422], grad_fn=<DivBackward0>)\n",
      "Epoch 351\n",
      " ---------------------- loss: tensor([103110.0078], grad_fn=<DivBackward0>)\n",
      "Epoch 352\n",
      " ---------------------- loss: tensor([102931.5703], grad_fn=<DivBackward0>)\n",
      "Epoch 353\n",
      " ---------------------- loss: tensor([102753.1172], grad_fn=<DivBackward0>)\n",
      "Epoch 354\n",
      " ---------------------- loss: tensor([102574.3516], grad_fn=<DivBackward0>)\n",
      "Epoch 355\n",
      " ---------------------- loss: tensor([102395.2734], grad_fn=<DivBackward0>)\n",
      "Epoch 356\n",
      " ---------------------- loss: tensor([102216.1094], grad_fn=<DivBackward0>)\n",
      "Epoch 357\n",
      " ---------------------- loss: tensor([102036.7500], grad_fn=<DivBackward0>)\n",
      "Epoch 358\n",
      " ---------------------- loss: tensor([101857.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 359\n",
      " ---------------------- loss: tensor([101677.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 360\n",
      " ---------------------- loss: tensor([101498.0859], grad_fn=<DivBackward0>)\n",
      "Epoch 361\n",
      " ---------------------- loss: tensor([101318.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 362\n",
      " ---------------------- loss: tensor([101138.6016], grad_fn=<DivBackward0>)\n",
      "Epoch 363\n",
      " ---------------------- loss: tensor([100958.8438], grad_fn=<DivBackward0>)\n",
      "Epoch 364\n",
      " ---------------------- loss: tensor([100778.8984], grad_fn=<DivBackward0>)\n",
      "Epoch 365\n",
      " ---------------------- loss: tensor([100598.9297], grad_fn=<DivBackward0>)\n",
      "Epoch 366\n",
      " ---------------------- loss: tensor([100418.8125], grad_fn=<DivBackward0>)\n",
      "Epoch 367\n",
      " ---------------------- loss: tensor([100238.6406], grad_fn=<DivBackward0>)\n",
      "Epoch 368\n",
      " ---------------------- loss: tensor([100058.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 369\n",
      " ---------------------- loss: tensor([99878.9922], grad_fn=<DivBackward0>)\n",
      "Epoch 370\n",
      " ---------------------- loss: tensor([99699.1250], grad_fn=<DivBackward0>)\n",
      "Epoch 371\n",
      " ---------------------- loss: tensor([99519.1094], grad_fn=<DivBackward0>)\n",
      "Epoch 372\n",
      " ---------------------- loss: tensor([99338.8672], grad_fn=<DivBackward0>)\n",
      "Epoch 373\n",
      " ---------------------- loss: tensor([99158.2891], grad_fn=<DivBackward0>)\n",
      "Epoch 374\n",
      " ---------------------- loss: tensor([98977.2109], grad_fn=<DivBackward0>)\n",
      "Epoch 375\n",
      " ---------------------- loss: tensor([98796.1719], grad_fn=<DivBackward0>)\n",
      "Epoch 376\n",
      " ---------------------- loss: tensor([98615.0703], grad_fn=<DivBackward0>)\n",
      "Epoch 377\n",
      " ---------------------- loss: tensor([98433.9453], grad_fn=<DivBackward0>)\n",
      "Epoch 378\n",
      " ---------------------- loss: tensor([98252.4922], grad_fn=<DivBackward0>)\n",
      "Epoch 379\n",
      " ---------------------- loss: tensor([98071.1328], grad_fn=<DivBackward0>)\n",
      "Epoch 380\n",
      " ---------------------- loss: tensor([97889.6484], grad_fn=<DivBackward0>)\n",
      "Epoch 381\n",
      " ---------------------- loss: tensor([97708.1172], grad_fn=<DivBackward0>)\n",
      "Epoch 382\n",
      " ---------------------- loss: tensor([97526.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 383\n",
      " ---------------------- loss: tensor([97345.0547], grad_fn=<DivBackward0>)\n",
      "Epoch 384\n",
      " ---------------------- loss: tensor([97163.4922], grad_fn=<DivBackward0>)\n",
      "Epoch 385\n",
      " ---------------------- loss: tensor([96981.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 386\n",
      " ---------------------- loss: tensor([90619.7734], grad_fn=<DivBackward0>)\n",
      "Epoch 387\n",
      " ---------------------- loss: tensor([89864.1719], grad_fn=<DivBackward0>)\n",
      "Epoch 388\n",
      " ---------------------- loss: tensor([88729.3047], grad_fn=<DivBackward0>)\n",
      "Epoch 389\n",
      " ---------------------- loss: tensor([87682.0469], grad_fn=<DivBackward0>)\n",
      "Epoch 390\n",
      " ---------------------- loss: tensor([87123.7891], grad_fn=<DivBackward0>)\n",
      "Epoch 391\n",
      " ---------------------- loss: tensor([86742.6797], grad_fn=<DivBackward0>)\n",
      "Epoch 392\n",
      " ---------------------- loss: tensor([86382.7344], grad_fn=<DivBackward0>)\n",
      "Epoch 393\n",
      " ---------------------- loss: tensor([85894.4844], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394\n",
      " ---------------------- loss: tensor([85188.5312], grad_fn=<DivBackward0>)\n",
      "Epoch 395\n",
      " ---------------------- loss: tensor([84113.2734], grad_fn=<DivBackward0>)\n",
      "Epoch 396\n",
      " ---------------------- loss: tensor([83382.0312], grad_fn=<DivBackward0>)\n",
      "Epoch 397\n",
      " ---------------------- loss: tensor([82829.3906], grad_fn=<DivBackward0>)\n",
      "Epoch 398\n",
      " ---------------------- loss: tensor([82229.2266], grad_fn=<DivBackward0>)\n",
      "Epoch 399\n",
      " ---------------------- loss: tensor([81697.2344], grad_fn=<DivBackward0>)\n",
      "Epoch 400\n",
      " ---------------------- loss: tensor([81160.5781], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([15681.2051], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([17625.8496], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([17458.8965], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([17340.4668], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([17259.0137], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([17194.0625], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([17138.1445], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([17085.4180], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([16989.0918], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([16886.0820], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([16802.5820], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([16728.7871], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([16659.1758], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([16585.7422], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([16502.1992], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([16420.6660], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([16347.7930], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([16275.8086], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([16186.6328], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([16073.1777], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([15959.3086], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([15860.0068], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([15732.3662], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([14078.5703], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([13377.1982], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([12975.9180], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([12660.3213], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([12385.9131], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([12120.0078], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([11769.4307], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([11414.4170], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([11045.9131], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([10624.1045], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([10204.8125], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([9871.9531], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([9630.7949], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([9399.6768], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([9154.3623], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([8939.8525], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([8690.4355], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([8438.2451], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([8277.5508], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([8146.4790], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([8034.3345], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([7791.3374], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([7578.5371], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([7429.7710], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([7231.6226], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([7067.2949], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([6942.5483], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([6847.9336], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([6767.2944], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([6498.5103], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([6344.9331], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([6217.6318], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([6004.0410], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([5876.8950], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([5780.8960], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([5700.6313], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([5602.3335], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([5489.7065], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([5360.2583], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([4517.2368], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([2406.4365], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([966.3109], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([949.7851], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([929.6092], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([912.6754], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([898.3851], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([885.2173], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([866.5158], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([844.2881], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([824.7714], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([809.1729], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([796.2716], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([782.1609], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([764.1509], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([747.9585], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([728.6000], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([706.8179], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([690.7445], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([674.0983], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([650.9428], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([633.6222], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([618.0196], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([601.1356], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([586.2694], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([573.0717], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([559.3527], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([545.9611], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([534.0739], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([522.6296], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([511.4373], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([500.7641], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95\n",
      " ---------------------- loss: tensor([490.5356], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([480.5456], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([471.3651], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([462.2455], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([453.4475], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([445.0509], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([437.5386], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([430.2329], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([422.2577], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([416.3396], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([410.1523], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([405.1563], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([399.1032], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([394.4790], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([390.1147], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([386.3358], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([382.5023], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([378.8343], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([375.6951], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([373.0419], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([370.0361], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([367.4325], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([364.4413], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([361.9188], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([359.1042], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([356.5306], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([353.6999], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([349.6810], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([346.9128], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([343.3642], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([340.3800], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([337.5950], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([333.3696], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([329.2788], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([325.5917], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([321.3392], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([316.6666], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([312.1847], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([307.8582], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([303.6280], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([298.5790], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([293.8431], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([289.1946], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([284.7210], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([280.1353], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([275.0764], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([270.3475], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([266.0638], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([261.4989], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([256.0121], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([251.5093], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([247.5131], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([242.4106], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([236.8555], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([232.5203], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([228.4270], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([223.3539], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([218.2327], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([213.9917], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([210.1373], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([205.6688], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([201.3921], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([197.7314], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([194.0842], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([190.3746], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([186.9003], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([183.7771], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([180.7067], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([177.7150], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([174.9019], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([172.1274], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([169.6267], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([164.3483], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([163.2140], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([160.7505], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([158.5960], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([113.7561], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([113.0426], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([109.8537], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([109.1928], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([108.8684], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([108.2014], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([107.8718], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([107.5546], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([104.6325], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([104.3484], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([103.8258], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([103.1045], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([102.8029], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([102.3878], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([101.4733], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([101.0976], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([100.4125], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([99.4645], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([99.2661], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([98.9217], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([98.2391], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([97.5712], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([97.1524], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194\n",
      " ---------------------- loss: tensor([96.8685], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([95.0034], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([94.8723], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([94.7219], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([93.8494], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([93.4403], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([93.0535], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([92.3971], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([90.9813], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([90.7374], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([90.6632], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([90.5150], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([89.2249], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([89.1041], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([88.6202], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([88.0318], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([87.7592], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([87.5697], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([87.0767], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([86.5347], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([85.8160], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([85.1262], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([84.4971], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([84.1615], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([83.6352], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([83.2869], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([82.1035], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([81.9237], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([81.4999], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([80.9824], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([80.6294], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([79.4767], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([73.8837], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([73.8386], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([72.3457], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([71.4884], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([71.3715], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([71.2244], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([71.1227], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([71.0654], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([70.9765], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([70.8359], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([70.6246], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([70.5624], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([70.4001], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([70.2960], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([70.2340], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([70.1073], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([69.6464], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([69.5977], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([69.4885], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([69.3580], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([69.2056], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([69.0628], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([68.9715], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([67.5281], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([67.5278], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([67.5277], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([67.5272], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([67.5272], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([67.5272], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([67.5266], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([67.5265], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([67.5263], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([67.5257], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([67.5257], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([67.5257], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([67.5255], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([67.5249], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([67.5249], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([67.5244], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([67.5242], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([67.5241], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([67.5237], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([67.5235], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([67.5232], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([67.5229], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([67.5228], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([67.5224], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([67.5221], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([67.5217], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([67.5212], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([67.5210], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([67.5205], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([67.5205], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([67.5203], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([67.5198], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([67.5194], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([67.5191], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([67.5191], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([67.5185], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([67.5185], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 301\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 302\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 303\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 304\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 305\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 306\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 307\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 308\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 309\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 310\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 311\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 312\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 313\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 314\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 315\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 316\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 317\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 318\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 319\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 320\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 321\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 322\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 323\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 324\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 325\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 326\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 327\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 328\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 329\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 330\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 331\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 332\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 333\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 334\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 335\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 336\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 337\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 338\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 339\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 340\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 341\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 342\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 343\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 344\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 345\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 346\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 347\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 348\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 349\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 350\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 351\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 352\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 353\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 354\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 355\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 356\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 357\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 358\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 359\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 360\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 361\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 362\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 363\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 364\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 365\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 366\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 367\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 368\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 369\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 370\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 371\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 372\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 373\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 374\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 375\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 376\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 377\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 378\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 379\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 380\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 381\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 382\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 383\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 384\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 385\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 386\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 387\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 388\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 389\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 390\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 391\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 392\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 393\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 394\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 395\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 396\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 397\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 398\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 400\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 401\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 402\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 403\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 404\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 405\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 406\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 407\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 408\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 409\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 410\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 411\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 412\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 413\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 414\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 415\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 416\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 417\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 418\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 419\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 420\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 421\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 422\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 423\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 424\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 425\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 426\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 427\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 428\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 429\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 430\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 431\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 432\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 433\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 434\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 435\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 436\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 437\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 438\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 439\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 440\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 441\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 442\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 443\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 444\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 445\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 446\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 447\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 448\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 449\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 450\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 451\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 452\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 453\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 454\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 455\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 456\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 457\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 458\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 459\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 460\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 461\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 462\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 463\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 464\n",
      " ---------------------- loss: tensor([67.5176], grad_fn=<DivBackward0>)\n",
      "Epoch 465\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 466\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 467\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 468\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 469\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 470\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 471\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 472\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 473\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 474\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 475\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 476\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 477\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 478\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 479\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 480\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 481\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 482\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 483\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 484\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 485\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 486\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 487\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 488\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 489\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 490\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 491\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 492\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 493\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 494\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 495\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 496\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 497\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 498\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 499\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 500\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 501\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 502\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 504\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 505\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 506\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 507\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 508\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 509\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 510\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 511\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 512\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 513\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 514\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 515\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 516\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 517\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 518\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 519\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 520\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 521\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 522\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 523\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 524\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 525\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 526\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 527\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 528\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 529\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 530\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 531\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 532\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 533\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 534\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 535\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 536\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 537\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 538\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 539\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 540\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 541\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 542\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 543\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 544\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 545\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 546\n",
      " ---------------------- loss: tensor([67.5177], grad_fn=<DivBackward0>)\n",
      "Epoch 547\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 548\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 549\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 550\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 551\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 552\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 553\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 554\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 555\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 556\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 557\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 558\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 559\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 560\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 561\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 562\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 563\n",
      " ---------------------- loss: tensor([67.5178], grad_fn=<DivBackward0>)\n",
      "Epoch 564\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 565\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 566\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 567\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 568\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 569\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 570\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 571\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 572\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 573\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 574\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 575\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 576\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 577\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 578\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 579\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 580\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 581\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 582\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 583\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 584\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 585\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 586\n",
      " ---------------------- loss: tensor([67.5181], grad_fn=<DivBackward0>)\n",
      "Epoch 587\n",
      " ---------------------- loss: tensor([67.5181], grad_fn=<DivBackward0>)\n",
      "Epoch 588\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 589\n",
      " ---------------------- loss: tensor([67.5179], grad_fn=<DivBackward0>)\n",
      "Epoch 590\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 591\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 592\n",
      " ---------------------- loss: tensor([67.5181], grad_fn=<DivBackward0>)\n",
      "Epoch 593\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 594\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 595\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Epoch 596\n",
      " ---------------------- loss: tensor([67.5181], grad_fn=<DivBackward0>)\n",
      "Epoch 597\n",
      " ---------------------- loss: tensor([67.5181], grad_fn=<DivBackward0>)\n",
      "Epoch 598\n",
      " ---------------------- loss: tensor([67.5181], grad_fn=<DivBackward0>)\n",
      "Epoch 599\n",
      " ---------------------- loss: tensor([67.5181], grad_fn=<DivBackward0>)\n",
      "Epoch 600\n",
      " ---------------------- loss: tensor([67.5180], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([19944.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([19940.8652], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([19540.2070], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([19410.4395], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      " ---------------------- loss: tensor([19289.0703], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([19189.3145], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([19103.6289], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([19006.4395], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([18861.4375], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([18714.1055], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([18585.2188], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([18471.6680], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([18367.9844], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([18259.2793], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([18127.2715], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([17987.1191], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([17854.6270], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([17731.7441], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([17611.6914], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([17486.8672], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([17354.3379], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([17224.2227], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([17102.3555], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([16983.1953], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([16850.5039], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([16691.8008], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([16523.3164], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([16373.3740], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([16249.0576], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([16131.4365], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([16010.5566], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([15845.1650], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([15660.9941], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([15500.9287], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([15290.4102], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([14887.2012], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([14139.4980], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([9452.6348], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([8719.7275], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([8322.6865], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([8010.3174], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([7733.3208], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([7456.3149], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([7189.5317], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([6910.4482], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([6298.6777], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([5663.8931], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([5246.1313], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([4905.1914], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([4627.2817], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([4360.8306], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([4040.9788], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([3808.3291], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([3653.3562], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([3457.5676], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([3254.1145], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([3116.1062], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([2996.9697], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([2899.0056], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([2801.6428], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([2710.0376], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([2630.1006], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([2561.5771], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([2501.8164], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([2446.8162], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([2384.5850], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([2318.2354], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([2246.6279], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([2168.9443], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([2104.1814], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([2056.2786], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([2014.8046], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([1975.2195], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([1938.1604], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([1897.1809], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([1843.0858], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([1794.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([1755.9427], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([1677.8131], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([1626.0364], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([1588.0935], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([1554.8033], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([1517.4353], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([1479.1725], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([1450.6403], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([1426.1510], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([1402.1443], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([1378.8839], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([1349.1222], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([1317.9802], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([1283.6902], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([1238.3097], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([1210.4725], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([1190.0215], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([1171.4790], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([1149.7747], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([1138.5991], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([1125.8542], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([1104.3807], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([1077.4569], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([1055.0790], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([1034.3103], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([1018.8683], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104\n",
      " ---------------------- loss: tensor([1004.9896], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([993.9164], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([981.2153], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([955.1342], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([933.0863], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([914.3438], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([898.5166], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([885.1743], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([873.2281], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([863.6218], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([843.0807], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([821.5542], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([798.9486], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([776.4204], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([761.1994], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([749.0378], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([741.4932], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([733.2894], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([719.4056], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([702.9028], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([687.4291], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([654.3422], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([631.5889], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([614.8273], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([589.3859], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([571.3543], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([555.7153], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([539.3284], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([523.8044], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([511.7059], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([498.6435], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([484.7512], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([468.6098], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([454.2332], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([440.9957], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([425.9601], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([413.6410], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([400.5061], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([386.1836], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([356.9442], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([316.1509], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([311.7657], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([257.5864], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([255.0379], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([252.5770], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([249.5477], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([242.0382], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([233.6063], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([224.6291], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([219.4266], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([215.9433], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([209.1939], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([206.7421], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([203.5266], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([197.1589], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([192.4130], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([189.1105], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([182.7051], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([171.9796], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([167.4838], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([164.7909], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([160.8987], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([157.8780], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([76.7887], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([76.7756], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([76.5315], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([76.1952], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([75.8556], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([75.5632], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([73.8875], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([73.8656], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([73.8236], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([73.7806], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([73.7008], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([73.6941], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([73.6359], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([73.4904], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([73.3955], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([73.3786], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([73.3598], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([72.4626], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([72.4261], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([72.4234], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([72.4020], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([72.1389], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([71.8623], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([71.0446], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([71.0311], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([70.9959], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([70.9921], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([70.9911], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([70.9924], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([70.9966], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([71.0007], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([71.0050], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([71.0093], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([71.0124], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([71.0165], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([71.0169], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 301\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 302\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 303\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 304\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 305\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 306\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 307\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 308\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 309\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 310\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 311\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 312\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 313\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 314\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 315\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 316\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 317\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 318\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 319\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 320\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 321\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 322\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 323\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 324\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 325\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 327\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 328\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 329\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 330\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 331\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 332\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 333\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 334\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 335\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 336\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 337\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 338\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 339\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 340\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 341\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 342\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 343\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 344\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 345\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 346\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 347\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 348\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 349\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 350\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 351\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 352\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 353\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 354\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 355\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 356\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 357\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 358\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 359\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 360\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 361\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 362\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 363\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 364\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 365\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 366\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 367\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 368\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 369\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 370\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 371\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 372\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 373\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 374\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 375\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 376\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 377\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 378\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 379\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 380\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 381\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 382\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 383\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 384\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 385\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 386\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 387\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 388\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 389\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 390\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 391\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 392\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 393\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 394\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 395\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 396\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 397\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 398\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 399\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 400\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 401\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 402\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 403\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 404\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 405\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 406\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 407\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 408\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 409\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 410\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 411\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 412\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 413\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 414\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 415\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 416\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 417\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 418\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 419\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 420\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 421\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 422\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 423\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 424\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 425\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 426\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 427\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 428\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 429\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 430\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 431\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 432\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 433\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 434\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 435\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 436\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 438\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 439\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 440\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 441\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 442\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 443\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 444\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 445\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 446\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 447\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 448\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 449\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 450\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 451\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 452\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 453\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 454\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 455\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 456\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 457\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 458\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 459\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 460\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 461\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 462\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 463\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 464\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 465\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 466\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 467\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 468\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 469\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 470\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 471\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 472\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 473\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 474\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 475\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 476\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 477\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 478\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 479\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 480\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 481\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 482\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 483\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 484\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 485\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 486\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 487\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 488\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 489\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 490\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 491\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 492\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 493\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 494\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 495\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 496\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 497\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 498\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 499\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 500\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 501\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 502\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 503\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 504\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 505\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 506\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 507\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 508\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 509\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 510\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 511\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 512\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 513\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 514\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 515\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 516\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 517\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 518\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 519\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 520\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 521\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 522\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 523\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 524\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 525\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 526\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 527\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 528\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 529\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 530\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 531\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 532\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 533\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 534\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 535\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 536\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 537\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 538\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 539\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 540\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 541\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 542\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 543\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 544\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 545\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 546\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 547\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 548\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 549\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 550\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 551\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 552\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 553\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 554\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 555\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 556\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 557\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 558\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 559\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 560\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 561\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 562\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 563\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 564\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 565\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 566\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 567\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 568\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 569\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 570\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 571\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 572\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 573\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 574\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 575\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 576\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 577\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 578\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 579\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 580\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 581\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 582\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 583\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 584\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 585\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 586\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 587\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 588\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 589\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 590\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 591\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 592\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 593\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 594\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 595\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 596\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 597\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 598\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 599\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 600\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 601\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 602\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 603\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 604\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 605\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 606\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 607\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 608\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 609\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 610\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 611\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 612\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 613\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 614\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 615\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 616\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 617\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 618\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 619\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 620\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 621\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 622\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 623\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 624\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 625\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 626\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 627\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 628\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 629\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 630\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 631\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 632\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 633\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 634\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 635\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 636\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 637\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 638\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 639\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 640\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 641\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 642\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 643\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 644\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 645\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 646\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 647\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 648\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 649\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 650\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 651\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 652\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 653\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 654\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 655\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 656\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 657\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 658\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 659\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 660\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 661\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 662\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 663\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 664\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 665\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 666\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 667\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 668\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 669\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 670\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 671\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 672\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 673\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 674\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 675\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 676\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 677\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 678\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 679\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 680\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 681\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 682\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 683\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 684\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 685\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 686\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 687\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 688\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 689\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 690\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 691\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 692\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 693\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 694\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 695\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 696\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 697\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 698\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 699\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 700\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 701\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 702\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 703\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 704\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 705\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 706\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 707\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 708\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 709\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 710\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 711\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 712\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 713\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 714\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 715\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 716\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 717\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 718\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 719\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 720\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 721\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 722\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 723\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 724\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 725\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 726\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 727\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 728\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 729\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 730\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 731\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 732\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 733\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 734\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 735\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 736\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 737\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 738\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 739\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 740\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 741\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 742\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 743\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 744\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 745\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 746\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 747\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 748\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 749\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 750\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 751\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 752\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 753\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 754\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 755\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 756\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 757\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 758\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 759\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 760\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 761\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 762\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 763\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 764\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 765\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 766\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 767\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 768\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 769\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 771\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 772\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 773\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 774\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 775\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 776\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 777\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 778\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 779\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 780\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 781\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 782\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 783\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 784\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 785\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 786\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 787\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 788\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 789\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 790\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 791\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 792\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 793\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 794\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 795\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 796\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 797\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 798\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 799\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Epoch 800\n",
      " ---------------------- loss: tensor([71.0150], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n",
      "Epoch 1\n",
      " ---------------------- loss: tensor([12138.6084], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([31229.7207], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([31228.8535], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([31227.9414], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([31227.0137], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([31225.9648], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([31224.9316], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([31223.8047], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([31222.6406], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([31221.4277], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([31220.1309], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([31218.7559], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([31217.3281], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([31215.8262], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([31214.2285], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([31212.5586], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([31210.7969], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([31208.9473], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([31207.0117], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([31204.9492], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([31202.7480], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([31200.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([31198.0293], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([31195.4805], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([31192.7676], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([31189.9102], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([31186.8965], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([31183.6816], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([31180.3027], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([31176.7188], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([31172.9336], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([31168.9121], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([31164.6602], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([31160.1445], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([31155.3828], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([31150.2891], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([31144.9082], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([31139.1992], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([31133.1094], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([31126.6133], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([31119.7188], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([31112.4238], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([31104.6250], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([31096.2832], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([31087.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([31077.9434], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([31067.7988], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([31056.9902], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([31045.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([31033.0508], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([31019.7969], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([31005.5938], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([30990.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([30973.9141], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([30956.3066], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([30937.3516], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([30916.9219], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([30894.9141], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([30871.1328], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([30845.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([30817.6328], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([30787.5566], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([30754.8926], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([30719.4414], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([30680.9004], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([30638.9297], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([30593.1523], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([30543.2168], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([30488.5449], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70\n",
      " ---------------------- loss: tensor([30428.7012], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([30363.0625], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([30290.9062], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([30211.4688], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([30123.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([30027.1328], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([29920.0605], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([29801.3652], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([29669.5371], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([29522.8730], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([29359.4180], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([29176.9316], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([28972.9531], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([28744.5859], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([28488.6484], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([28201.5723], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([27879.3926], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([27517.8691], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([27112.2363], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([26658.0371], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([26150.4395], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([25584.7773], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([24957.1953], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([24264.7520], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([23505.9609], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([22681.2949], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([21793.7773], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([20849.1230], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([19855.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([18825.1426], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([17769.9336], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([9978.9727], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([9974.6191], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([9970.1787], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([9965.6914], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([9961.1357], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([9956.5586], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([9951.7588], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([9946.5830], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([9940.9111], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([9934.5791], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([9927.2744], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([9917.8457], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([9902.9160], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([9870.3408], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([9779.0703], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([9616.8955], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([9469.9121], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([9345.5166], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([9234.5781], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([9116.8711], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([8971.9268], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([8816.8486], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([8676.7568], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([8552.4033], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([8439.2471], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([8326.1113], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([8197.5352], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([8062.4302], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([7931.7358], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([7811.5635], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([7699.5063], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([7590.8887], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([7475.3213], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([7352.5630], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([7234.2349], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([7122.6934], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([7015.8550], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([6910.1812], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([6804.0430], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([6696.0269], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([6585.6875], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([6484.0112], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([6389.8926], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([6292.6133], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([6189.3794], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([6092.3057], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([5993.8438], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([5895.4565], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([5814.9448], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([5745.0039], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([5643.1494], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([5534.9414], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([5457.9375], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([5350.2090], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([5218.0874], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([5127.1855], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([5034.0659], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([4907.2314], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([4806.9839], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([4711.6104], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([4624.7378], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([4533.0557], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([4454.2900], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([4357.9189], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([4270.9185], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([4231.5728], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([4161.2915], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([4089.0820], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169\n",
      " ---------------------- loss: tensor([4019.0139], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([3984.0229], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([3880.8035], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([3847.0796], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([3792.7090], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([3749.7791], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([3708.6890], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([3661.4756], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([3618.4893], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([3568.1907], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([3542.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([3508.9258], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([3398.7627], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([3374.5713], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([3357.7815], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([3304.6104], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([3286.9338], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([3199.9011], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([3166.1348], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([3152.4368], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([3136.3032], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([3102.6179], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([3069.8823], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([3041.8579], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([3021.3606], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([2988.2205], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([2959.9009], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([2924.0842], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([2895.1287], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([2848.9243], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([2813.5088], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([2779.4700], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([2747.0181], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([2707.9673], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([2682.5874], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([2613.7649], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([2473.1992], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([2423.0928], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([2387.6416], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([2361.2659], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([2339.5842], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([2282.4236], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([2232.5264], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([2181.0784], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([2126.8679], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([2081.5984], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([2041.2926], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([1987.1648], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([1941.3529], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([1892.0398], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([1841.8759], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([1797.4506], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([1763.6875], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([1711.9983], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([1663.5853], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([1618.8740], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([1582.5483], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([1542.1215], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([1501.7480], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([1461.5315], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([1428.7053], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([1395.9070], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([1359.8495], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([1326.4240], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([1297.0909], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([1269.8466], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([1240.1445], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([1211.1602], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([1184.3942], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([1161.2118], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([1137.1505], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([1115.4600], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([1091.4606], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([1073.6390], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([1047.6348], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([1032.3114], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([1012.2864], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([989.5832], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([981.1834], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([967.0121], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([944.2049], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([932.2499], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([922.9716], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([908.3511], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([894.4998], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([884.8271], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([868.6963], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([860.2505], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([850.3155], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([831.4327], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([821.2861], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([747.4451], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([746.2039], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([737.4758], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([701.6741], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([690.0428], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([665.6439], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([653.6762], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([543.0542], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268\n",
      " ---------------------- loss: tensor([492.8567], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([487.7930], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([473.3094], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([460.0817], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([451.5451], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([408.2865], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([396.4431], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([388.1574], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([382.7382], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([371.7119], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([366.4562], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([360.5781], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([354.1796], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([345.1870], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([340.7250], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([15784.9561], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([15780.8213], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([15776.6699], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([15772.5029], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([15768.3252], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([15764.1504], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([15759.9297], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([15755.7178], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([15751.4902], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([15747.2383], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([15742.9668], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([15738.6904], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([15734.4023], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([15730.0928], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([15725.7656], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([15721.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([15717.0752], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([15712.6943], grad_fn=<DivBackward0>)\n",
      "Epoch 301\n",
      " ---------------------- loss: tensor([15708.3242], grad_fn=<DivBackward0>)\n",
      "Epoch 302\n",
      " ---------------------- loss: tensor([15703.9150], grad_fn=<DivBackward0>)\n",
      "Epoch 303\n",
      " ---------------------- loss: tensor([15699.5078], grad_fn=<DivBackward0>)\n",
      "Epoch 304\n",
      " ---------------------- loss: tensor([15695.0664], grad_fn=<DivBackward0>)\n",
      "Epoch 305\n",
      " ---------------------- loss: tensor([15690.6338], grad_fn=<DivBackward0>)\n",
      "Epoch 306\n",
      " ---------------------- loss: tensor([15686.1738], grad_fn=<DivBackward0>)\n",
      "Epoch 307\n",
      " ---------------------- loss: tensor([15681.6895], grad_fn=<DivBackward0>)\n",
      "Epoch 308\n",
      " ---------------------- loss: tensor([15677.1943], grad_fn=<DivBackward0>)\n",
      "Epoch 309\n",
      " ---------------------- loss: tensor([15672.6836], grad_fn=<DivBackward0>)\n",
      "Epoch 310\n",
      " ---------------------- loss: tensor([15668.1494], grad_fn=<DivBackward0>)\n",
      "Epoch 311\n",
      " ---------------------- loss: tensor([15663.6182], grad_fn=<DivBackward0>)\n",
      "Epoch 312\n",
      " ---------------------- loss: tensor([15659.0557], grad_fn=<DivBackward0>)\n",
      "Epoch 313\n",
      " ---------------------- loss: tensor([15654.4707], grad_fn=<DivBackward0>)\n",
      "Epoch 314\n",
      " ---------------------- loss: tensor([15649.8818], grad_fn=<DivBackward0>)\n",
      "Epoch 315\n",
      " ---------------------- loss: tensor([15645.2705], grad_fn=<DivBackward0>)\n",
      "Epoch 316\n",
      " ---------------------- loss: tensor([15640.6387], grad_fn=<DivBackward0>)\n",
      "Epoch 317\n",
      " ---------------------- loss: tensor([15635.9961], grad_fn=<DivBackward0>)\n",
      "Epoch 318\n",
      " ---------------------- loss: tensor([15631.3369], grad_fn=<DivBackward0>)\n",
      "Epoch 319\n",
      " ---------------------- loss: tensor([15626.6445], grad_fn=<DivBackward0>)\n",
      "Epoch 320\n",
      " ---------------------- loss: tensor([15621.9541], grad_fn=<DivBackward0>)\n",
      "Epoch 321\n",
      " ---------------------- loss: tensor([15617.2422], grad_fn=<DivBackward0>)\n",
      "Epoch 322\n",
      " ---------------------- loss: tensor([15612.5078], grad_fn=<DivBackward0>)\n",
      "Epoch 323\n",
      " ---------------------- loss: tensor([15607.7637], grad_fn=<DivBackward0>)\n",
      "Epoch 324\n",
      " ---------------------- loss: tensor([15603.0156], grad_fn=<DivBackward0>)\n",
      "Epoch 325\n",
      " ---------------------- loss: tensor([15598.2207], grad_fn=<DivBackward0>)\n",
      "Epoch 326\n",
      " ---------------------- loss: tensor([15593.4268], grad_fn=<DivBackward0>)\n",
      "Epoch 327\n",
      " ---------------------- loss: tensor([15588.6045], grad_fn=<DivBackward0>)\n",
      "Epoch 328\n",
      " ---------------------- loss: tensor([15583.7686], grad_fn=<DivBackward0>)\n",
      "Epoch 329\n",
      " ---------------------- loss: tensor([15578.9209], grad_fn=<DivBackward0>)\n",
      "Epoch 330\n",
      " ---------------------- loss: tensor([15574.0488], grad_fn=<DivBackward0>)\n",
      "Epoch 331\n",
      " ---------------------- loss: tensor([15569.1650], grad_fn=<DivBackward0>)\n",
      "Epoch 332\n",
      " ---------------------- loss: tensor([15564.2588], grad_fn=<DivBackward0>)\n",
      "Epoch 333\n",
      " ---------------------- loss: tensor([15559.3193], grad_fn=<DivBackward0>)\n",
      "Epoch 334\n",
      " ---------------------- loss: tensor([15554.3701], grad_fn=<DivBackward0>)\n",
      "Epoch 335\n",
      " ---------------------- loss: tensor([15549.4131], grad_fn=<DivBackward0>)\n",
      "Epoch 336\n",
      " ---------------------- loss: tensor([15544.4297], grad_fn=<DivBackward0>)\n",
      "Epoch 337\n",
      " ---------------------- loss: tensor([15539.4209], grad_fn=<DivBackward0>)\n",
      "Epoch 338\n",
      " ---------------------- loss: tensor([15534.4053], grad_fn=<DivBackward0>)\n",
      "Epoch 339\n",
      " ---------------------- loss: tensor([15529.3613], grad_fn=<DivBackward0>)\n",
      "Epoch 340\n",
      " ---------------------- loss: tensor([15524.2988], grad_fn=<DivBackward0>)\n",
      "Epoch 341\n",
      " ---------------------- loss: tensor([15519.2090], grad_fn=<DivBackward0>)\n",
      "Epoch 342\n",
      " ---------------------- loss: tensor([15514.1006], grad_fn=<DivBackward0>)\n",
      "Epoch 343\n",
      " ---------------------- loss: tensor([15508.9883], grad_fn=<DivBackward0>)\n",
      "Epoch 344\n",
      " ---------------------- loss: tensor([15503.8477], grad_fn=<DivBackward0>)\n",
      "Epoch 345\n",
      " ---------------------- loss: tensor([15498.6895], grad_fn=<DivBackward0>)\n",
      "Epoch 346\n",
      " ---------------------- loss: tensor([15493.5039], grad_fn=<DivBackward0>)\n",
      "Epoch 347\n",
      " ---------------------- loss: tensor([15488.3008], grad_fn=<DivBackward0>)\n",
      "Epoch 348\n",
      " ---------------------- loss: tensor([15483.0654], grad_fn=<DivBackward0>)\n",
      "Epoch 349\n",
      " ---------------------- loss: tensor([15477.8223], grad_fn=<DivBackward0>)\n",
      "Epoch 350\n",
      " ---------------------- loss: tensor([15472.5605], grad_fn=<DivBackward0>)\n",
      "Epoch 351\n",
      " ---------------------- loss: tensor([15467.2725], grad_fn=<DivBackward0>)\n",
      "Epoch 352\n",
      " ---------------------- loss: tensor([15461.9736], grad_fn=<DivBackward0>)\n",
      "Epoch 353\n",
      " ---------------------- loss: tensor([15456.6572], grad_fn=<DivBackward0>)\n",
      "Epoch 354\n",
      " ---------------------- loss: tensor([15451.3281], grad_fn=<DivBackward0>)\n",
      "Epoch 355\n",
      " ---------------------- loss: tensor([15445.9473], grad_fn=<DivBackward0>)\n",
      "Epoch 356\n",
      " ---------------------- loss: tensor([15440.5586], grad_fn=<DivBackward0>)\n",
      "Epoch 357\n",
      " ---------------------- loss: tensor([15435.1504], grad_fn=<DivBackward0>)\n",
      "Epoch 358\n",
      " ---------------------- loss: tensor([15429.7178], grad_fn=<DivBackward0>)\n",
      "Epoch 359\n",
      " ---------------------- loss: tensor([15424.2588], grad_fn=<DivBackward0>)\n",
      "Epoch 360\n",
      " ---------------------- loss: tensor([15418.7910], grad_fn=<DivBackward0>)\n",
      "Epoch 361\n",
      " ---------------------- loss: tensor([15413.2910], grad_fn=<DivBackward0>)\n",
      "Epoch 362\n",
      " ---------------------- loss: tensor([15407.7471], grad_fn=<DivBackward0>)\n",
      "Epoch 363\n",
      " ---------------------- loss: tensor([15402.2158], grad_fn=<DivBackward0>)\n",
      "Epoch 364\n",
      " ---------------------- loss: tensor([15396.6484], grad_fn=<DivBackward0>)\n",
      "Epoch 365\n",
      " ---------------------- loss: tensor([15391.0566], grad_fn=<DivBackward0>)\n",
      "Epoch 366\n",
      " ---------------------- loss: tensor([15385.4434], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367\n",
      " ---------------------- loss: tensor([15379.8018], grad_fn=<DivBackward0>)\n",
      "Epoch 368\n",
      " ---------------------- loss: tensor([15374.1484], grad_fn=<DivBackward0>)\n",
      "Epoch 369\n",
      " ---------------------- loss: tensor([15368.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 370\n",
      " ---------------------- loss: tensor([15362.7441], grad_fn=<DivBackward0>)\n",
      "Epoch 371\n",
      " ---------------------- loss: tensor([15357.0225], grad_fn=<DivBackward0>)\n",
      "Epoch 372\n",
      " ---------------------- loss: tensor([15351.2734], grad_fn=<DivBackward0>)\n",
      "Epoch 373\n",
      " ---------------------- loss: tensor([15345.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 374\n",
      " ---------------------- loss: tensor([15339.6904], grad_fn=<DivBackward0>)\n",
      "Epoch 375\n",
      " ---------------------- loss: tensor([15333.8545], grad_fn=<DivBackward0>)\n",
      "Epoch 376\n",
      " ---------------------- loss: tensor([15328.0029], grad_fn=<DivBackward0>)\n",
      "Epoch 377\n",
      " ---------------------- loss: tensor([15322.1250], grad_fn=<DivBackward0>)\n",
      "Epoch 378\n",
      " ---------------------- loss: tensor([15316.2207], grad_fn=<DivBackward0>)\n",
      "Epoch 379\n",
      " ---------------------- loss: tensor([15310.2998], grad_fn=<DivBackward0>)\n",
      "Epoch 380\n",
      " ---------------------- loss: tensor([15304.3438], grad_fn=<DivBackward0>)\n",
      "Epoch 381\n",
      " ---------------------- loss: tensor([15298.3633], grad_fn=<DivBackward0>)\n",
      "Epoch 382\n",
      " ---------------------- loss: tensor([15292.3672], grad_fn=<DivBackward0>)\n",
      "Epoch 383\n",
      " ---------------------- loss: tensor([15286.3232], grad_fn=<DivBackward0>)\n",
      "Epoch 384\n",
      " ---------------------- loss: tensor([15280.2715], grad_fn=<DivBackward0>)\n",
      "Epoch 385\n",
      " ---------------------- loss: tensor([15274.1914], grad_fn=<DivBackward0>)\n",
      "Epoch 386\n",
      " ---------------------- loss: tensor([15268.0947], grad_fn=<DivBackward0>)\n",
      "Epoch 387\n",
      " ---------------------- loss: tensor([15261.9639], grad_fn=<DivBackward0>)\n",
      "Epoch 388\n",
      " ---------------------- loss: tensor([15255.8037], grad_fn=<DivBackward0>)\n",
      "Epoch 389\n",
      " ---------------------- loss: tensor([15249.6045], grad_fn=<DivBackward0>)\n",
      "Epoch 390\n",
      " ---------------------- loss: tensor([15243.4043], grad_fn=<DivBackward0>)\n",
      "Epoch 391\n",
      " ---------------------- loss: tensor([15237.1533], grad_fn=<DivBackward0>)\n",
      "Epoch 392\n",
      " ---------------------- loss: tensor([15230.8838], grad_fn=<DivBackward0>)\n",
      "Epoch 393\n",
      " ---------------------- loss: tensor([15224.5908], grad_fn=<DivBackward0>)\n",
      "Epoch 394\n",
      " ---------------------- loss: tensor([15218.2725], grad_fn=<DivBackward0>)\n",
      "Epoch 395\n",
      " ---------------------- loss: tensor([15211.9297], grad_fn=<DivBackward0>)\n",
      "Epoch 396\n",
      " ---------------------- loss: tensor([15205.5459], grad_fn=<DivBackward0>)\n",
      "Epoch 397\n",
      " ---------------------- loss: tensor([15199.1377], grad_fn=<DivBackward0>)\n",
      "Epoch 398\n",
      " ---------------------- loss: tensor([15192.6963], grad_fn=<DivBackward0>)\n",
      "Epoch 399\n",
      " ---------------------- loss: tensor([15186.2256], grad_fn=<DivBackward0>)\n",
      "Epoch 400\n",
      " ---------------------- loss: tensor([15179.7422], grad_fn=<DivBackward0>)\n",
      "Epoch 401\n",
      " ---------------------- loss: tensor([15173.2012], grad_fn=<DivBackward0>)\n",
      "Epoch 402\n",
      " ---------------------- loss: tensor([15166.6523], grad_fn=<DivBackward0>)\n",
      "Epoch 403\n",
      " ---------------------- loss: tensor([15160.0527], grad_fn=<DivBackward0>)\n",
      "Epoch 404\n",
      " ---------------------- loss: tensor([15153.4551], grad_fn=<DivBackward0>)\n",
      "Epoch 405\n",
      " ---------------------- loss: tensor([15146.8008], grad_fn=<DivBackward0>)\n",
      "Epoch 406\n",
      " ---------------------- loss: tensor([15140.1309], grad_fn=<DivBackward0>)\n",
      "Epoch 407\n",
      " ---------------------- loss: tensor([15133.4395], grad_fn=<DivBackward0>)\n",
      "Epoch 408\n",
      " ---------------------- loss: tensor([15126.6777], grad_fn=<DivBackward0>)\n",
      "Epoch 409\n",
      " ---------------------- loss: tensor([15119.9414], grad_fn=<DivBackward0>)\n",
      "Epoch 410\n",
      " ---------------------- loss: tensor([15113.1436], grad_fn=<DivBackward0>)\n",
      "Epoch 411\n",
      " ---------------------- loss: tensor([15106.3213], grad_fn=<DivBackward0>)\n",
      "Epoch 412\n",
      " ---------------------- loss: tensor([15099.4482], grad_fn=<DivBackward0>)\n",
      "Epoch 413\n",
      " ---------------------- loss: tensor([15092.5645], grad_fn=<DivBackward0>)\n",
      "Epoch 414\n",
      " ---------------------- loss: tensor([15085.6377], grad_fn=<DivBackward0>)\n",
      "Epoch 415\n",
      " ---------------------- loss: tensor([15078.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 416\n",
      " ---------------------- loss: tensor([15071.6807], grad_fn=<DivBackward0>)\n",
      "Epoch 417\n",
      " ---------------------- loss: tensor([15064.6709], grad_fn=<DivBackward0>)\n",
      "Epoch 418\n",
      " ---------------------- loss: tensor([15057.6113], grad_fn=<DivBackward0>)\n",
      "Epoch 419\n",
      " ---------------------- loss: tensor([15050.5098], grad_fn=<DivBackward0>)\n",
      "Epoch 420\n",
      " ---------------------- loss: tensor([15043.3896], grad_fn=<DivBackward0>)\n",
      "Epoch 421\n",
      " ---------------------- loss: tensor([15036.2217], grad_fn=<DivBackward0>)\n",
      "Epoch 422\n",
      " ---------------------- loss: tensor([15029.0166], grad_fn=<DivBackward0>)\n",
      "Epoch 423\n",
      " ---------------------- loss: tensor([15021.7979], grad_fn=<DivBackward0>)\n",
      "Epoch 424\n",
      " ---------------------- loss: tensor([15014.5371], grad_fn=<DivBackward0>)\n",
      "Epoch 425\n",
      " ---------------------- loss: tensor([15007.2637], grad_fn=<DivBackward0>)\n",
      "Epoch 426\n",
      " ---------------------- loss: tensor([14999.9277], grad_fn=<DivBackward0>)\n",
      "Epoch 427\n",
      " ---------------------- loss: tensor([14992.5586], grad_fn=<DivBackward0>)\n",
      "Epoch 428\n",
      " ---------------------- loss: tensor([14985.1621], grad_fn=<DivBackward0>)\n",
      "Epoch 429\n",
      " ---------------------- loss: tensor([14977.7285], grad_fn=<DivBackward0>)\n",
      "Epoch 430\n",
      " ---------------------- loss: tensor([14970.2598], grad_fn=<DivBackward0>)\n",
      "Epoch 431\n",
      " ---------------------- loss: tensor([14962.7539], grad_fn=<DivBackward0>)\n",
      "Epoch 432\n",
      " ---------------------- loss: tensor([14955.2061], grad_fn=<DivBackward0>)\n",
      "Epoch 433\n",
      " ---------------------- loss: tensor([14947.6357], grad_fn=<DivBackward0>)\n",
      "Epoch 434\n",
      " ---------------------- loss: tensor([14940.0039], grad_fn=<DivBackward0>)\n",
      "Epoch 435\n",
      " ---------------------- loss: tensor([14932.3428], grad_fn=<DivBackward0>)\n",
      "Epoch 436\n",
      " ---------------------- loss: tensor([14924.6260], grad_fn=<DivBackward0>)\n",
      "Epoch 437\n",
      " ---------------------- loss: tensor([14916.9160], grad_fn=<DivBackward0>)\n",
      "Epoch 438\n",
      " ---------------------- loss: tensor([14909.1279], grad_fn=<DivBackward0>)\n",
      "Epoch 439\n",
      " ---------------------- loss: tensor([14901.3135], grad_fn=<DivBackward0>)\n",
      "Epoch 440\n",
      " ---------------------- loss: tensor([14893.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 441\n",
      " ---------------------- loss: tensor([14885.5605], grad_fn=<DivBackward0>)\n",
      "Epoch 442\n",
      " ---------------------- loss: tensor([14877.6338], grad_fn=<DivBackward0>)\n",
      "Epoch 443\n",
      " ---------------------- loss: tensor([14869.6709], grad_fn=<DivBackward0>)\n",
      "Epoch 444\n",
      " ---------------------- loss: tensor([14861.6543], grad_fn=<DivBackward0>)\n",
      "Epoch 445\n",
      " ---------------------- loss: tensor([14853.5977], grad_fn=<DivBackward0>)\n",
      "Epoch 446\n",
      " ---------------------- loss: tensor([14845.5010], grad_fn=<DivBackward0>)\n",
      "Epoch 447\n",
      " ---------------------- loss: tensor([14837.3535], grad_fn=<DivBackward0>)\n",
      "Epoch 448\n",
      " ---------------------- loss: tensor([14829.1777], grad_fn=<DivBackward0>)\n",
      "Epoch 449\n",
      " ---------------------- loss: tensor([14820.9648], grad_fn=<DivBackward0>)\n",
      "Epoch 450\n",
      " ---------------------- loss: tensor([14812.7031], grad_fn=<DivBackward0>)\n",
      "Epoch 451\n",
      " ---------------------- loss: tensor([14804.3896], grad_fn=<DivBackward0>)\n",
      "Epoch 452\n",
      " ---------------------- loss: tensor([14796.0371], grad_fn=<DivBackward0>)\n",
      "Epoch 453\n",
      " ---------------------- loss: tensor([14787.6523], grad_fn=<DivBackward0>)\n",
      "Epoch 454\n",
      " ---------------------- loss: tensor([14779.2139], grad_fn=<DivBackward0>)\n",
      "Epoch 455\n",
      " ---------------------- loss: tensor([14770.7197], grad_fn=<DivBackward0>)\n",
      "Epoch 456\n",
      " ---------------------- loss: tensor([14762.1963], grad_fn=<DivBackward0>)\n",
      "Epoch 457\n",
      " ---------------------- loss: tensor([14753.6338], grad_fn=<DivBackward0>)\n",
      "Epoch 458\n",
      " ---------------------- loss: tensor([14745.0137], grad_fn=<DivBackward0>)\n",
      "Epoch 459\n",
      " ---------------------- loss: tensor([14736.3340], grad_fn=<DivBackward0>)\n",
      "Epoch 460\n",
      " ---------------------- loss: tensor([14727.6396], grad_fn=<DivBackward0>)\n",
      "Epoch 461\n",
      " ---------------------- loss: tensor([14718.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 462\n",
      " ---------------------- loss: tensor([14710.0938], grad_fn=<DivBackward0>)\n",
      "Epoch 463\n",
      " ---------------------- loss: tensor([14701.2256], grad_fn=<DivBackward0>)\n",
      "Epoch 464\n",
      " ---------------------- loss: tensor([14692.3594], grad_fn=<DivBackward0>)\n",
      "Epoch 465\n",
      " ---------------------- loss: tensor([14683.4033], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466\n",
      " ---------------------- loss: tensor([14674.4092], grad_fn=<DivBackward0>)\n",
      "Epoch 467\n",
      " ---------------------- loss: tensor([14665.3740], grad_fn=<DivBackward0>)\n",
      "Epoch 468\n",
      " ---------------------- loss: tensor([14656.2959], grad_fn=<DivBackward0>)\n",
      "Epoch 469\n",
      " ---------------------- loss: tensor([14647.1367], grad_fn=<DivBackward0>)\n",
      "Epoch 470\n",
      " ---------------------- loss: tensor([14637.9199], grad_fn=<DivBackward0>)\n",
      "Epoch 471\n",
      " ---------------------- loss: tensor([14628.6904], grad_fn=<DivBackward0>)\n",
      "Epoch 472\n",
      " ---------------------- loss: tensor([14619.3945], grad_fn=<DivBackward0>)\n",
      "Epoch 473\n",
      " ---------------------- loss: tensor([14610.0615], grad_fn=<DivBackward0>)\n",
      "Epoch 474\n",
      " ---------------------- loss: tensor([14600.6699], grad_fn=<DivBackward0>)\n",
      "Epoch 475\n",
      " ---------------------- loss: tensor([14591.2236], grad_fn=<DivBackward0>)\n",
      "Epoch 476\n",
      " ---------------------- loss: tensor([14581.7178], grad_fn=<DivBackward0>)\n",
      "Epoch 477\n",
      " ---------------------- loss: tensor([14572.1514], grad_fn=<DivBackward0>)\n",
      "Epoch 478\n",
      " ---------------------- loss: tensor([14562.5479], grad_fn=<DivBackward0>)\n",
      "Epoch 479\n",
      " ---------------------- loss: tensor([14552.8643], grad_fn=<DivBackward0>)\n",
      "Epoch 480\n",
      " ---------------------- loss: tensor([14543.1309], grad_fn=<DivBackward0>)\n",
      "Epoch 481\n",
      " ---------------------- loss: tensor([14533.3457], grad_fn=<DivBackward0>)\n",
      "Epoch 482\n",
      " ---------------------- loss: tensor([14523.5068], grad_fn=<DivBackward0>)\n",
      "Epoch 483\n",
      " ---------------------- loss: tensor([14513.6191], grad_fn=<DivBackward0>)\n",
      "Epoch 484\n",
      " ---------------------- loss: tensor([14503.6729], grad_fn=<DivBackward0>)\n",
      "Epoch 485\n",
      " ---------------------- loss: tensor([14493.6807], grad_fn=<DivBackward0>)\n",
      "Epoch 486\n",
      " ---------------------- loss: tensor([14483.6191], grad_fn=<DivBackward0>)\n",
      "Epoch 487\n",
      " ---------------------- loss: tensor([14473.4795], grad_fn=<DivBackward0>)\n",
      "Epoch 488\n",
      " ---------------------- loss: tensor([14463.2900], grad_fn=<DivBackward0>)\n",
      "Epoch 489\n",
      " ---------------------- loss: tensor([14453.0430], grad_fn=<DivBackward0>)\n",
      "Epoch 490\n",
      " ---------------------- loss: tensor([14442.7549], grad_fn=<DivBackward0>)\n",
      "Epoch 491\n",
      " ---------------------- loss: tensor([14432.3965], grad_fn=<DivBackward0>)\n",
      "Epoch 492\n",
      " ---------------------- loss: tensor([14421.9434], grad_fn=<DivBackward0>)\n",
      "Epoch 493\n",
      " ---------------------- loss: tensor([14411.4805], grad_fn=<DivBackward0>)\n",
      "Epoch 494\n",
      " ---------------------- loss: tensor([14400.9502], grad_fn=<DivBackward0>)\n",
      "Epoch 495\n",
      " ---------------------- loss: tensor([14390.3311], grad_fn=<DivBackward0>)\n",
      "Epoch 496\n",
      " ---------------------- loss: tensor([14379.6758], grad_fn=<DivBackward0>)\n",
      "Epoch 497\n",
      " ---------------------- loss: tensor([14368.9297], grad_fn=<DivBackward0>)\n",
      "Epoch 498\n",
      " ---------------------- loss: tensor([14358.1357], grad_fn=<DivBackward0>)\n",
      "Epoch 499\n",
      " ---------------------- loss: tensor([14347.2705], grad_fn=<DivBackward0>)\n",
      "Epoch 500\n",
      " ---------------------- loss: tensor([14336.3340], grad_fn=<DivBackward0>)\n",
      "Epoch 501\n",
      " ---------------------- loss: tensor([14325.3447], grad_fn=<DivBackward0>)\n",
      "Epoch 502\n",
      " ---------------------- loss: tensor([14314.2627], grad_fn=<DivBackward0>)\n",
      "Epoch 503\n",
      " ---------------------- loss: tensor([14303.1328], grad_fn=<DivBackward0>)\n",
      "Epoch 504\n",
      " ---------------------- loss: tensor([14291.9502], grad_fn=<DivBackward0>)\n",
      "Epoch 505\n",
      " ---------------------- loss: tensor([14280.6729], grad_fn=<DivBackward0>)\n",
      "Epoch 506\n",
      " ---------------------- loss: tensor([14269.3438], grad_fn=<DivBackward0>)\n",
      "Epoch 507\n",
      " ---------------------- loss: tensor([14257.9346], grad_fn=<DivBackward0>)\n",
      "Epoch 508\n",
      " ---------------------- loss: tensor([14246.4541], grad_fn=<DivBackward0>)\n",
      "Epoch 509\n",
      " ---------------------- loss: tensor([14234.8926], grad_fn=<DivBackward0>)\n",
      "Epoch 510\n",
      " ---------------------- loss: tensor([14223.2744], grad_fn=<DivBackward0>)\n",
      "Epoch 511\n",
      " ---------------------- loss: tensor([14211.5645], grad_fn=<DivBackward0>)\n",
      "Epoch 512\n",
      " ---------------------- loss: tensor([14199.7793], grad_fn=<DivBackward0>)\n",
      "Epoch 513\n",
      " ---------------------- loss: tensor([14187.9307], grad_fn=<DivBackward0>)\n",
      "Epoch 514\n",
      " ---------------------- loss: tensor([14176.0020], grad_fn=<DivBackward0>)\n",
      "Epoch 515\n",
      " ---------------------- loss: tensor([14164.0059], grad_fn=<DivBackward0>)\n",
      "Epoch 516\n",
      " ---------------------- loss: tensor([14151.9082], grad_fn=<DivBackward0>)\n",
      "Epoch 517\n",
      " ---------------------- loss: tensor([14139.7588], grad_fn=<DivBackward0>)\n",
      "Epoch 518\n",
      " ---------------------- loss: tensor([14127.5322], grad_fn=<DivBackward0>)\n",
      "Epoch 519\n",
      " ---------------------- loss: tensor([14115.2002], grad_fn=<DivBackward0>)\n",
      "Epoch 520\n",
      " ---------------------- loss: tensor([14102.8076], grad_fn=<DivBackward0>)\n",
      "Epoch 521\n",
      " ---------------------- loss: tensor([14090.3486], grad_fn=<DivBackward0>)\n",
      "Epoch 522\n",
      " ---------------------- loss: tensor([14077.7988], grad_fn=<DivBackward0>)\n",
      "Epoch 523\n",
      " ---------------------- loss: tensor([14065.1514], grad_fn=<DivBackward0>)\n",
      "Epoch 524\n",
      " ---------------------- loss: tensor([14052.4424], grad_fn=<DivBackward0>)\n",
      "Epoch 525\n",
      " ---------------------- loss: tensor([14039.6240], grad_fn=<DivBackward0>)\n",
      "Epoch 526\n",
      " ---------------------- loss: tensor([14026.7207], grad_fn=<DivBackward0>)\n",
      "Epoch 527\n",
      " ---------------------- loss: tensor([14013.7207], grad_fn=<DivBackward0>)\n",
      "Epoch 528\n",
      " ---------------------- loss: tensor([14000.6670], grad_fn=<DivBackward0>)\n",
      "Epoch 529\n",
      " ---------------------- loss: tensor([13987.5059], grad_fn=<DivBackward0>)\n",
      "Epoch 530\n",
      " ---------------------- loss: tensor([13974.2725], grad_fn=<DivBackward0>)\n",
      "Epoch 531\n",
      " ---------------------- loss: tensor([13960.9277], grad_fn=<DivBackward0>)\n",
      "Epoch 532\n",
      " ---------------------- loss: tensor([13947.5166], grad_fn=<DivBackward0>)\n",
      "Epoch 533\n",
      " ---------------------- loss: tensor([13934.0068], grad_fn=<DivBackward0>)\n",
      "Epoch 534\n",
      " ---------------------- loss: tensor([13920.4141], grad_fn=<DivBackward0>)\n",
      "Epoch 535\n",
      " ---------------------- loss: tensor([13906.7246], grad_fn=<DivBackward0>)\n",
      "Epoch 536\n",
      " ---------------------- loss: tensor([13892.9248], grad_fn=<DivBackward0>)\n",
      "Epoch 537\n",
      " ---------------------- loss: tensor([13879.0293], grad_fn=<DivBackward0>)\n",
      "Epoch 538\n",
      " ---------------------- loss: tensor([13865.0381], grad_fn=<DivBackward0>)\n",
      "Epoch 539\n",
      " ---------------------- loss: tensor([13850.9424], grad_fn=<DivBackward0>)\n",
      "Epoch 540\n",
      " ---------------------- loss: tensor([13836.7627], grad_fn=<DivBackward0>)\n",
      "Epoch 541\n",
      " ---------------------- loss: tensor([13822.4639], grad_fn=<DivBackward0>)\n",
      "Epoch 542\n",
      " ---------------------- loss: tensor([13808.0928], grad_fn=<DivBackward0>)\n",
      "Epoch 543\n",
      " ---------------------- loss: tensor([13793.5947], grad_fn=<DivBackward0>)\n",
      "Epoch 544\n",
      " ---------------------- loss: tensor([13779.0186], grad_fn=<DivBackward0>)\n",
      "Epoch 545\n",
      " ---------------------- loss: tensor([13764.3174], grad_fn=<DivBackward0>)\n",
      "Epoch 546\n",
      " ---------------------- loss: tensor([13749.5098], grad_fn=<DivBackward0>)\n",
      "Epoch 547\n",
      " ---------------------- loss: tensor([13734.6133], grad_fn=<DivBackward0>)\n",
      "Epoch 548\n",
      " ---------------------- loss: tensor([13719.5869], grad_fn=<DivBackward0>)\n",
      "Epoch 549\n",
      " ---------------------- loss: tensor([13704.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 550\n",
      " ---------------------- loss: tensor([13689.2334], grad_fn=<DivBackward0>)\n",
      "Epoch 551\n",
      " ---------------------- loss: tensor([13673.8662], grad_fn=<DivBackward0>)\n",
      "Epoch 552\n",
      " ---------------------- loss: tensor([13658.4160], grad_fn=<DivBackward0>)\n",
      "Epoch 553\n",
      " ---------------------- loss: tensor([13642.8447], grad_fn=<DivBackward0>)\n",
      "Epoch 554\n",
      " ---------------------- loss: tensor([13627.1660], grad_fn=<DivBackward0>)\n",
      "Epoch 555\n",
      " ---------------------- loss: tensor([13611.3555], grad_fn=<DivBackward0>)\n",
      "Epoch 556\n",
      " ---------------------- loss: tensor([13595.4346], grad_fn=<DivBackward0>)\n",
      "Epoch 557\n",
      " ---------------------- loss: tensor([13579.4160], grad_fn=<DivBackward0>)\n",
      "Epoch 558\n",
      " ---------------------- loss: tensor([13563.2529], grad_fn=<DivBackward0>)\n",
      "Epoch 559\n",
      " ---------------------- loss: tensor([13546.9561], grad_fn=<DivBackward0>)\n",
      "Epoch 560\n",
      " ---------------------- loss: tensor([13530.5723], grad_fn=<DivBackward0>)\n",
      "Epoch 561\n",
      " ---------------------- loss: tensor([13514.0352], grad_fn=<DivBackward0>)\n",
      "Epoch 562\n",
      " ---------------------- loss: tensor([13497.3779], grad_fn=<DivBackward0>)\n",
      "Epoch 563\n",
      " ---------------------- loss: tensor([13480.6152], grad_fn=<DivBackward0>)\n",
      "Epoch 564\n",
      " ---------------------- loss: tensor([13463.6992], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565\n",
      " ---------------------- loss: tensor([13446.6592], grad_fn=<DivBackward0>)\n",
      "Epoch 566\n",
      " ---------------------- loss: tensor([13429.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 567\n",
      " ---------------------- loss: tensor([13412.1914], grad_fn=<DivBackward0>)\n",
      "Epoch 568\n",
      " ---------------------- loss: tensor([13394.7783], grad_fn=<DivBackward0>)\n",
      "Epoch 569\n",
      " ---------------------- loss: tensor([13377.2051], grad_fn=<DivBackward0>)\n",
      "Epoch 570\n",
      " ---------------------- loss: tensor([13359.4902], grad_fn=<DivBackward0>)\n",
      "Epoch 571\n",
      " ---------------------- loss: tensor([13341.6406], grad_fn=<DivBackward0>)\n",
      "Epoch 572\n",
      " ---------------------- loss: tensor([13323.6436], grad_fn=<DivBackward0>)\n",
      "Epoch 573\n",
      " ---------------------- loss: tensor([13305.4902], grad_fn=<DivBackward0>)\n",
      "Epoch 574\n",
      " ---------------------- loss: tensor([13287.2197], grad_fn=<DivBackward0>)\n",
      "Epoch 575\n",
      " ---------------------- loss: tensor([13268.7930], grad_fn=<DivBackward0>)\n",
      "Epoch 576\n",
      " ---------------------- loss: tensor([13250.2275], grad_fn=<DivBackward0>)\n",
      "Epoch 577\n",
      " ---------------------- loss: tensor([13231.5186], grad_fn=<DivBackward0>)\n",
      "Epoch 578\n",
      " ---------------------- loss: tensor([13212.6650], grad_fn=<DivBackward0>)\n",
      "Epoch 579\n",
      " ---------------------- loss: tensor([13193.6553], grad_fn=<DivBackward0>)\n",
      "Epoch 580\n",
      " ---------------------- loss: tensor([13174.4648], grad_fn=<DivBackward0>)\n",
      "Epoch 581\n",
      " ---------------------- loss: tensor([13155.1357], grad_fn=<DivBackward0>)\n",
      "Epoch 582\n",
      " ---------------------- loss: tensor([13135.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 583\n",
      " ---------------------- loss: tensor([13115.9873], grad_fn=<DivBackward0>)\n",
      "Epoch 584\n",
      " ---------------------- loss: tensor([13096.1611], grad_fn=<DivBackward0>)\n",
      "Epoch 585\n",
      " ---------------------- loss: tensor([13076.1543], grad_fn=<DivBackward0>)\n",
      "Epoch 586\n",
      " ---------------------- loss: tensor([13055.9893], grad_fn=<DivBackward0>)\n",
      "Epoch 587\n",
      " ---------------------- loss: tensor([13035.6572], grad_fn=<DivBackward0>)\n",
      "Epoch 588\n",
      " ---------------------- loss: tensor([13015.1680], grad_fn=<DivBackward0>)\n",
      "Epoch 589\n",
      " ---------------------- loss: tensor([12994.5449], grad_fn=<DivBackward0>)\n",
      "Epoch 590\n",
      " ---------------------- loss: tensor([12973.7158], grad_fn=<DivBackward0>)\n",
      "Epoch 591\n",
      " ---------------------- loss: tensor([12952.6934], grad_fn=<DivBackward0>)\n",
      "Epoch 592\n",
      " ---------------------- loss: tensor([12931.5078], grad_fn=<DivBackward0>)\n",
      "Epoch 593\n",
      " ---------------------- loss: tensor([12910.1172], grad_fn=<DivBackward0>)\n",
      "Epoch 594\n",
      " ---------------------- loss: tensor([12888.5781], grad_fn=<DivBackward0>)\n",
      "Epoch 595\n",
      " ---------------------- loss: tensor([12866.8496], grad_fn=<DivBackward0>)\n",
      "Epoch 596\n",
      " ---------------------- loss: tensor([12844.9590], grad_fn=<DivBackward0>)\n",
      "Epoch 597\n",
      " ---------------------- loss: tensor([12822.8359], grad_fn=<DivBackward0>)\n",
      "Epoch 598\n",
      " ---------------------- loss: tensor([12800.5439], grad_fn=<DivBackward0>)\n",
      "Epoch 599\n",
      " ---------------------- loss: tensor([12778.0361], grad_fn=<DivBackward0>)\n",
      "Epoch 600\n",
      " ---------------------- loss: tensor([12755.3682], grad_fn=<DivBackward0>)\n",
      "Epoch 601\n",
      " ---------------------- loss: tensor([12732.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 602\n",
      " ---------------------- loss: tensor([12709.3291], grad_fn=<DivBackward0>)\n",
      "Epoch 603\n",
      " ---------------------- loss: tensor([12686.0049], grad_fn=<DivBackward0>)\n",
      "Epoch 604\n",
      " ---------------------- loss: tensor([12662.4844], grad_fn=<DivBackward0>)\n",
      "Epoch 605\n",
      " ---------------------- loss: tensor([12638.7383], grad_fn=<DivBackward0>)\n",
      "Epoch 606\n",
      " ---------------------- loss: tensor([12614.7988], grad_fn=<DivBackward0>)\n",
      "Epoch 607\n",
      " ---------------------- loss: tensor([12590.6416], grad_fn=<DivBackward0>)\n",
      "Epoch 608\n",
      " ---------------------- loss: tensor([12566.2607], grad_fn=<DivBackward0>)\n",
      "Epoch 609\n",
      " ---------------------- loss: tensor([12541.6738], grad_fn=<DivBackward0>)\n",
      "Epoch 610\n",
      " ---------------------- loss: tensor([12516.8350], grad_fn=<DivBackward0>)\n",
      "Epoch 611\n",
      " ---------------------- loss: tensor([12491.7891], grad_fn=<DivBackward0>)\n",
      "Epoch 612\n",
      " ---------------------- loss: tensor([12466.4941], grad_fn=<DivBackward0>)\n",
      "Epoch 613\n",
      " ---------------------- loss: tensor([12440.9746], grad_fn=<DivBackward0>)\n",
      "Epoch 614\n",
      " ---------------------- loss: tensor([12415.2285], grad_fn=<DivBackward0>)\n",
      "Epoch 615\n",
      " ---------------------- loss: tensor([12389.2646], grad_fn=<DivBackward0>)\n",
      "Epoch 616\n",
      " ---------------------- loss: tensor([12362.9854], grad_fn=<DivBackward0>)\n",
      "Epoch 617\n",
      " ---------------------- loss: tensor([12336.4941], grad_fn=<DivBackward0>)\n",
      "Epoch 618\n",
      " ---------------------- loss: tensor([12309.7578], grad_fn=<DivBackward0>)\n",
      "Epoch 619\n",
      " ---------------------- loss: tensor([12282.7715], grad_fn=<DivBackward0>)\n",
      "Epoch 620\n",
      " ---------------------- loss: tensor([12255.5615], grad_fn=<DivBackward0>)\n",
      "Epoch 621\n",
      " ---------------------- loss: tensor([12228.0664], grad_fn=<DivBackward0>)\n",
      "Epoch 622\n",
      " ---------------------- loss: tensor([12200.3301], grad_fn=<DivBackward0>)\n",
      "Epoch 623\n",
      " ---------------------- loss: tensor([12172.3086], grad_fn=<DivBackward0>)\n",
      "Epoch 624\n",
      " ---------------------- loss: tensor([12144.0303], grad_fn=<DivBackward0>)\n",
      "Epoch 625\n",
      " ---------------------- loss: tensor([12115.4648], grad_fn=<DivBackward0>)\n",
      "Epoch 626\n",
      " ---------------------- loss: tensor([12086.5811], grad_fn=<DivBackward0>)\n",
      "Epoch 627\n",
      " ---------------------- loss: tensor([12057.4834], grad_fn=<DivBackward0>)\n",
      "Epoch 628\n",
      " ---------------------- loss: tensor([12028.0703], grad_fn=<DivBackward0>)\n",
      "Epoch 629\n",
      " ---------------------- loss: tensor([11998.3857], grad_fn=<DivBackward0>)\n",
      "Epoch 630\n",
      " ---------------------- loss: tensor([11968.3496], grad_fn=<DivBackward0>)\n",
      "Epoch 631\n",
      " ---------------------- loss: tensor([11938.0918], grad_fn=<DivBackward0>)\n",
      "Epoch 632\n",
      " ---------------------- loss: tensor([11907.5107], grad_fn=<DivBackward0>)\n",
      "Epoch 633\n",
      " ---------------------- loss: tensor([11876.6191], grad_fn=<DivBackward0>)\n",
      "Epoch 634\n",
      " ---------------------- loss: tensor([11845.4443], grad_fn=<DivBackward0>)\n",
      "Epoch 635\n",
      " ---------------------- loss: tensor([11813.9346], grad_fn=<DivBackward0>)\n",
      "Epoch 636\n",
      " ---------------------- loss: tensor([11782.0742], grad_fn=<DivBackward0>)\n",
      "Epoch 637\n",
      " ---------------------- loss: tensor([11749.9346], grad_fn=<DivBackward0>)\n",
      "Epoch 638\n",
      " ---------------------- loss: tensor([11717.4258], grad_fn=<DivBackward0>)\n",
      "Epoch 639\n",
      " ---------------------- loss: tensor([11684.6211], grad_fn=<DivBackward0>)\n",
      "Epoch 640\n",
      " ---------------------- loss: tensor([11651.4814], grad_fn=<DivBackward0>)\n",
      "Epoch 641\n",
      " ---------------------- loss: tensor([11618.0088], grad_fn=<DivBackward0>)\n",
      "Epoch 642\n",
      " ---------------------- loss: tensor([11584.1738], grad_fn=<DivBackward0>)\n",
      "Epoch 643\n",
      " ---------------------- loss: tensor([11550.0156], grad_fn=<DivBackward0>)\n",
      "Epoch 644\n",
      " ---------------------- loss: tensor([11515.5000], grad_fn=<DivBackward0>)\n",
      "Epoch 645\n",
      " ---------------------- loss: tensor([11480.6680], grad_fn=<DivBackward0>)\n",
      "Epoch 646\n",
      " ---------------------- loss: tensor([11445.4775], grad_fn=<DivBackward0>)\n",
      "Epoch 647\n",
      " ---------------------- loss: tensor([11409.8633], grad_fn=<DivBackward0>)\n",
      "Epoch 648\n",
      " ---------------------- loss: tensor([11373.8711], grad_fn=<DivBackward0>)\n",
      "Epoch 649\n",
      " ---------------------- loss: tensor([11337.4912], grad_fn=<DivBackward0>)\n",
      "Epoch 650\n",
      " ---------------------- loss: tensor([11300.7891], grad_fn=<DivBackward0>)\n",
      "Epoch 651\n",
      " ---------------------- loss: tensor([11263.7061], grad_fn=<DivBackward0>)\n",
      "Epoch 652\n",
      " ---------------------- loss: tensor([11226.2295], grad_fn=<DivBackward0>)\n",
      "Epoch 653\n",
      " ---------------------- loss: tensor([11188.3379], grad_fn=<DivBackward0>)\n",
      "Epoch 654\n",
      " ---------------------- loss: tensor([11150.0762], grad_fn=<DivBackward0>)\n",
      "Epoch 655\n",
      " ---------------------- loss: tensor([11111.3662], grad_fn=<DivBackward0>)\n",
      "Epoch 656\n",
      " ---------------------- loss: tensor([11072.2783], grad_fn=<DivBackward0>)\n",
      "Epoch 657\n",
      " ---------------------- loss: tensor([11032.7871], grad_fn=<DivBackward0>)\n",
      "Epoch 658\n",
      " ---------------------- loss: tensor([10992.8125], grad_fn=<DivBackward0>)\n",
      "Epoch 659\n",
      " ---------------------- loss: tensor([10952.4287], grad_fn=<DivBackward0>)\n",
      "Epoch 660\n",
      " ---------------------- loss: tensor([10911.6436], grad_fn=<DivBackward0>)\n",
      "Epoch 661\n",
      " ---------------------- loss: tensor([10870.3906], grad_fn=<DivBackward0>)\n",
      "Epoch 662\n",
      " ---------------------- loss: tensor([10828.7266], grad_fn=<DivBackward0>)\n",
      "Epoch 663\n",
      " ---------------------- loss: tensor([10786.5820], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 664\n",
      " ---------------------- loss: tensor([10744.0361], grad_fn=<DivBackward0>)\n",
      "Epoch 665\n",
      " ---------------------- loss: tensor([10701.0635], grad_fn=<DivBackward0>)\n",
      "Epoch 666\n",
      " ---------------------- loss: tensor([10657.5693], grad_fn=<DivBackward0>)\n",
      "Epoch 667\n",
      " ---------------------- loss: tensor([10613.6494], grad_fn=<DivBackward0>)\n",
      "Epoch 668\n",
      " ---------------------- loss: tensor([10569.2969], grad_fn=<DivBackward0>)\n",
      "Epoch 669\n",
      " ---------------------- loss: tensor([10524.4541], grad_fn=<DivBackward0>)\n",
      "Epoch 670\n",
      " ---------------------- loss: tensor([10479.0508], grad_fn=<DivBackward0>)\n",
      "Epoch 671\n",
      " ---------------------- loss: tensor([10433.2236], grad_fn=<DivBackward0>)\n",
      "Epoch 672\n",
      " ---------------------- loss: tensor([10386.8770], grad_fn=<DivBackward0>)\n",
      "Epoch 673\n",
      " ---------------------- loss: tensor([10339.9756], grad_fn=<DivBackward0>)\n",
      "Epoch 674\n",
      " ---------------------- loss: tensor([10292.6201], grad_fn=<DivBackward0>)\n",
      "Epoch 675\n",
      " ---------------------- loss: tensor([10244.7549], grad_fn=<DivBackward0>)\n",
      "Epoch 676\n",
      " ---------------------- loss: tensor([10196.4121], grad_fn=<DivBackward0>)\n",
      "Epoch 677\n",
      " ---------------------- loss: tensor([10147.5059], grad_fn=<DivBackward0>)\n",
      "Epoch 678\n",
      " ---------------------- loss: tensor([10098.0713], grad_fn=<DivBackward0>)\n",
      "Epoch 679\n",
      " ---------------------- loss: tensor([10048.1191], grad_fn=<DivBackward0>)\n",
      "Epoch 680\n",
      " ---------------------- loss: tensor([9997.6973], grad_fn=<DivBackward0>)\n",
      "Epoch 681\n",
      " ---------------------- loss: tensor([9946.7080], grad_fn=<DivBackward0>)\n",
      "Epoch 682\n",
      " ---------------------- loss: tensor([9895.1270], grad_fn=<DivBackward0>)\n",
      "Epoch 683\n",
      " ---------------------- loss: tensor([9842.9473], grad_fn=<DivBackward0>)\n",
      "Epoch 684\n",
      " ---------------------- loss: tensor([9790.3154], grad_fn=<DivBackward0>)\n",
      "Epoch 685\n",
      " ---------------------- loss: tensor([9737.2188], grad_fn=<DivBackward0>)\n",
      "Epoch 686\n",
      " ---------------------- loss: tensor([9683.4180], grad_fn=<DivBackward0>)\n",
      "Epoch 687\n",
      " ---------------------- loss: tensor([9629.0947], grad_fn=<DivBackward0>)\n",
      "Epoch 688\n",
      " ---------------------- loss: tensor([9574.1416], grad_fn=<DivBackward0>)\n",
      "Epoch 689\n",
      " ---------------------- loss: tensor([9518.6631], grad_fn=<DivBackward0>)\n",
      "Epoch 690\n",
      " ---------------------- loss: tensor([9462.6152], grad_fn=<DivBackward0>)\n",
      "Epoch 691\n",
      " ---------------------- loss: tensor([9405.9697], grad_fn=<DivBackward0>)\n",
      "Epoch 692\n",
      " ---------------------- loss: tensor([9348.7988], grad_fn=<DivBackward0>)\n",
      "Epoch 693\n",
      " ---------------------- loss: tensor([9290.9922], grad_fn=<DivBackward0>)\n",
      "Epoch 694\n",
      " ---------------------- loss: tensor([9232.5605], grad_fn=<DivBackward0>)\n",
      "Epoch 695\n",
      " ---------------------- loss: tensor([9173.5820], grad_fn=<DivBackward0>)\n",
      "Epoch 696\n",
      " ---------------------- loss: tensor([9113.9746], grad_fn=<DivBackward0>)\n",
      "Epoch 697\n",
      " ---------------------- loss: tensor([9053.8398], grad_fn=<DivBackward0>)\n",
      "Epoch 698\n",
      " ---------------------- loss: tensor([8993.0459], grad_fn=<DivBackward0>)\n",
      "Epoch 699\n",
      " ---------------------- loss: tensor([8931.6279], grad_fn=<DivBackward0>)\n",
      "Epoch 700\n",
      " ---------------------- loss: tensor([8869.6660], grad_fn=<DivBackward0>)\n",
      "Epoch 701\n",
      " ---------------------- loss: tensor([8807.1211], grad_fn=<DivBackward0>)\n",
      "Epoch 702\n",
      " ---------------------- loss: tensor([8744.0234], grad_fn=<DivBackward0>)\n",
      "Epoch 703\n",
      " ---------------------- loss: tensor([8680.2393], grad_fn=<DivBackward0>)\n",
      "Epoch 704\n",
      " ---------------------- loss: tensor([8615.9785], grad_fn=<DivBackward0>)\n",
      "Epoch 705\n",
      " ---------------------- loss: tensor([8551.], grad_fn=<DivBackward0>)\n",
      "Epoch 706\n",
      " ---------------------- loss: tensor([8485.5186], grad_fn=<DivBackward0>)\n",
      "Epoch 707\n",
      " ---------------------- loss: tensor([8419.4697], grad_fn=<DivBackward0>)\n",
      "Epoch 708\n",
      " ---------------------- loss: tensor([8352.8311], grad_fn=<DivBackward0>)\n",
      "Epoch 709\n",
      " ---------------------- loss: tensor([8285.5449], grad_fn=<DivBackward0>)\n",
      "Epoch 710\n",
      " ---------------------- loss: tensor([8217.7090], grad_fn=<DivBackward0>)\n",
      "Epoch 711\n",
      " ---------------------- loss: tensor([8149.2354], grad_fn=<DivBackward0>)\n",
      "Epoch 712\n",
      " ---------------------- loss: tensor([8080.3413], grad_fn=<DivBackward0>)\n",
      "Epoch 713\n",
      " ---------------------- loss: tensor([8010.7871], grad_fn=<DivBackward0>)\n",
      "Epoch 714\n",
      " ---------------------- loss: tensor([7940.6987], grad_fn=<DivBackward0>)\n",
      "Epoch 715\n",
      " ---------------------- loss: tensor([7870.1221], grad_fn=<DivBackward0>)\n",
      "Epoch 716\n",
      " ---------------------- loss: tensor([7799.0205], grad_fn=<DivBackward0>)\n",
      "Epoch 717\n",
      " ---------------------- loss: tensor([7727.3081], grad_fn=<DivBackward0>)\n",
      "Epoch 718\n",
      " ---------------------- loss: tensor([7655.2354], grad_fn=<DivBackward0>)\n",
      "Epoch 719\n",
      " ---------------------- loss: tensor([7582.5044], grad_fn=<DivBackward0>)\n",
      "Epoch 720\n",
      " ---------------------- loss: tensor([7509.3042], grad_fn=<DivBackward0>)\n",
      "Epoch 721\n",
      " ---------------------- loss: tensor([7435.5811], grad_fn=<DivBackward0>)\n",
      "Epoch 722\n",
      " ---------------------- loss: tensor([7361.4634], grad_fn=<DivBackward0>)\n",
      "Epoch 723\n",
      " ---------------------- loss: tensor([7286.8770], grad_fn=<DivBackward0>)\n",
      "Epoch 724\n",
      " ---------------------- loss: tensor([7211.8364], grad_fn=<DivBackward0>)\n",
      "Epoch 725\n",
      " ---------------------- loss: tensor([7136.2944], grad_fn=<DivBackward0>)\n",
      "Epoch 726\n",
      " ---------------------- loss: tensor([7060.4766], grad_fn=<DivBackward0>)\n",
      "Epoch 727\n",
      " ---------------------- loss: tensor([6984.2822], grad_fn=<DivBackward0>)\n",
      "Epoch 728\n",
      " ---------------------- loss: tensor([6907.6055], grad_fn=<DivBackward0>)\n",
      "Epoch 729\n",
      " ---------------------- loss: tensor([6830.6177], grad_fn=<DivBackward0>)\n",
      "Epoch 730\n",
      " ---------------------- loss: tensor([6753.3286], grad_fn=<DivBackward0>)\n",
      "Epoch 731\n",
      " ---------------------- loss: tensor([6675.7627], grad_fn=<DivBackward0>)\n",
      "Epoch 732\n",
      " ---------------------- loss: tensor([6597.8423], grad_fn=<DivBackward0>)\n",
      "Epoch 733\n",
      " ---------------------- loss: tensor([6519.7876], grad_fn=<DivBackward0>)\n",
      "Epoch 734\n",
      " ---------------------- loss: tensor([6441.3960], grad_fn=<DivBackward0>)\n",
      "Epoch 735\n",
      " ---------------------- loss: tensor([6362.8213], grad_fn=<DivBackward0>)\n",
      "Epoch 736\n",
      " ---------------------- loss: tensor([6284.1714], grad_fn=<DivBackward0>)\n",
      "Epoch 737\n",
      " ---------------------- loss: tensor([6205.3076], grad_fn=<DivBackward0>)\n",
      "Epoch 738\n",
      " ---------------------- loss: tensor([6126.1382], grad_fn=<DivBackward0>)\n",
      "Epoch 739\n",
      " ---------------------- loss: tensor([6046.9482], grad_fn=<DivBackward0>)\n",
      "Epoch 740\n",
      " ---------------------- loss: tensor([5967.6636], grad_fn=<DivBackward0>)\n",
      "Epoch 741\n",
      " ---------------------- loss: tensor([5888.3071], grad_fn=<DivBackward0>)\n",
      "Epoch 742\n",
      " ---------------------- loss: tensor([854.7612], grad_fn=<DivBackward0>)\n",
      "Epoch 743\n",
      " ---------------------- loss: tensor([854.0776], grad_fn=<DivBackward0>)\n",
      "Epoch 744\n",
      " ---------------------- loss: tensor([29270.2441], grad_fn=<DivBackward0>)\n",
      "Epoch 745\n",
      " ---------------------- loss: tensor([29262.7441], grad_fn=<DivBackward0>)\n",
      "Epoch 746\n",
      " ---------------------- loss: tensor([29255.2070], grad_fn=<DivBackward0>)\n",
      "Epoch 747\n",
      " ---------------------- loss: tensor([29247.6602], grad_fn=<DivBackward0>)\n",
      "Epoch 748\n",
      " ---------------------- loss: tensor([29240.0195], grad_fn=<DivBackward0>)\n",
      "Epoch 749\n",
      " ---------------------- loss: tensor([29232.3359], grad_fn=<DivBackward0>)\n",
      "Epoch 750\n",
      " ---------------------- loss: tensor([29224.6016], grad_fn=<DivBackward0>)\n",
      "Epoch 751\n",
      " ---------------------- loss: tensor([29216.8496], grad_fn=<DivBackward0>)\n",
      "Epoch 752\n",
      " ---------------------- loss: tensor([29209.1309], grad_fn=<DivBackward0>)\n",
      "Epoch 753\n",
      " ---------------------- loss: tensor([29201.3535], grad_fn=<DivBackward0>)\n",
      "Epoch 754\n",
      " ---------------------- loss: tensor([29193.5586], grad_fn=<DivBackward0>)\n",
      "Epoch 755\n",
      " ---------------------- loss: tensor([29185.6660], grad_fn=<DivBackward0>)\n",
      "Epoch 756\n",
      " ---------------------- loss: tensor([29177.6973], grad_fn=<DivBackward0>)\n",
      "Epoch 757\n",
      " ---------------------- loss: tensor([29169.7070], grad_fn=<DivBackward0>)\n",
      "Epoch 758\n",
      " ---------------------- loss: tensor([29161.7480], grad_fn=<DivBackward0>)\n",
      "Epoch 759\n",
      " ---------------------- loss: tensor([29153.7266], grad_fn=<DivBackward0>)\n",
      "Epoch 760\n",
      " ---------------------- loss: tensor([29145.7129], grad_fn=<DivBackward0>)\n",
      "Epoch 761\n",
      " ---------------------- loss: tensor([29137.5938], grad_fn=<DivBackward0>)\n",
      "Epoch 762\n",
      " ---------------------- loss: tensor([29129.4785], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 763\n",
      " ---------------------- loss: tensor([29121.3008], grad_fn=<DivBackward0>)\n",
      "Epoch 764\n",
      " ---------------------- loss: tensor([29113.0215], grad_fn=<DivBackward0>)\n",
      "Epoch 765\n",
      " ---------------------- loss: tensor([29104.6797], grad_fn=<DivBackward0>)\n",
      "Epoch 766\n",
      " ---------------------- loss: tensor([29096.2637], grad_fn=<DivBackward0>)\n",
      "Epoch 767\n",
      " ---------------------- loss: tensor([29087.8301], grad_fn=<DivBackward0>)\n",
      "Epoch 768\n",
      " ---------------------- loss: tensor([29079.4180], grad_fn=<DivBackward0>)\n",
      "Epoch 769\n",
      " ---------------------- loss: tensor([29070.9805], grad_fn=<DivBackward0>)\n",
      "Epoch 770\n",
      " ---------------------- loss: tensor([29062.4980], grad_fn=<DivBackward0>)\n",
      "Epoch 771\n",
      " ---------------------- loss: tensor([29053.9570], grad_fn=<DivBackward0>)\n",
      "Epoch 772\n",
      " ---------------------- loss: tensor([29045.4570], grad_fn=<DivBackward0>)\n",
      "Epoch 773\n",
      " ---------------------- loss: tensor([29036.7344], grad_fn=<DivBackward0>)\n",
      "Epoch 774\n",
      " ---------------------- loss: tensor([29027.9824], grad_fn=<DivBackward0>)\n",
      "Epoch 775\n",
      " ---------------------- loss: tensor([29019.2422], grad_fn=<DivBackward0>)\n",
      "Epoch 776\n",
      " ---------------------- loss: tensor([29010.5664], grad_fn=<DivBackward0>)\n",
      "Epoch 777\n",
      " ---------------------- loss: tensor([29001.8203], grad_fn=<DivBackward0>)\n",
      "Epoch 778\n",
      " ---------------------- loss: tensor([28993.0117], grad_fn=<DivBackward0>)\n",
      "Epoch 779\n",
      " ---------------------- loss: tensor([28984.2402], grad_fn=<DivBackward0>)\n",
      "Epoch 780\n",
      " ---------------------- loss: tensor([28975.3828], grad_fn=<DivBackward0>)\n",
      "Epoch 781\n",
      " ---------------------- loss: tensor([28966.4395], grad_fn=<DivBackward0>)\n",
      "Epoch 782\n",
      " ---------------------- loss: tensor([28957.4082], grad_fn=<DivBackward0>)\n",
      "Epoch 783\n",
      " ---------------------- loss: tensor([28948.3770], grad_fn=<DivBackward0>)\n",
      "Epoch 784\n",
      " ---------------------- loss: tensor([28939.2129], grad_fn=<DivBackward0>)\n",
      "Epoch 785\n",
      " ---------------------- loss: tensor([28929.9961], grad_fn=<DivBackward0>)\n",
      "Epoch 786\n",
      " ---------------------- loss: tensor([28920.8066], grad_fn=<DivBackward0>)\n",
      "Epoch 787\n",
      " ---------------------- loss: tensor([28911.5566], grad_fn=<DivBackward0>)\n",
      "Epoch 788\n",
      " ---------------------- loss: tensor([28902.3613], grad_fn=<DivBackward0>)\n",
      "Epoch 789\n",
      " ---------------------- loss: tensor([28893.1113], grad_fn=<DivBackward0>)\n",
      "Epoch 790\n",
      " ---------------------- loss: tensor([28883.8477], grad_fn=<DivBackward0>)\n",
      "Epoch 791\n",
      " ---------------------- loss: tensor([28874.3984], grad_fn=<DivBackward0>)\n",
      "Epoch 792\n",
      " ---------------------- loss: tensor([28864.9082], grad_fn=<DivBackward0>)\n",
      "Epoch 793\n",
      " ---------------------- loss: tensor([28855.3965], grad_fn=<DivBackward0>)\n",
      "Epoch 794\n",
      " ---------------------- loss: tensor([28845.8984], grad_fn=<DivBackward0>)\n",
      "Epoch 795\n",
      " ---------------------- loss: tensor([28836.3730], grad_fn=<DivBackward0>)\n",
      "Epoch 796\n",
      " ---------------------- loss: tensor([28826.7617], grad_fn=<DivBackward0>)\n",
      "Epoch 797\n",
      " ---------------------- loss: tensor([28817.0488], grad_fn=<DivBackward0>)\n",
      "Epoch 798\n",
      " ---------------------- loss: tensor([28807.3242], grad_fn=<DivBackward0>)\n",
      "Epoch 799\n",
      " ---------------------- loss: tensor([28797.4453], grad_fn=<DivBackward0>)\n",
      "Epoch 800\n",
      " ---------------------- loss: tensor([28787.4746], grad_fn=<DivBackward0>)\n",
      "Epoch 801\n",
      " ---------------------- loss: tensor([28777.5840], grad_fn=<DivBackward0>)\n",
      "Epoch 802\n",
      " ---------------------- loss: tensor([28767.6387], grad_fn=<DivBackward0>)\n",
      "Epoch 803\n",
      " ---------------------- loss: tensor([28757.6230], grad_fn=<DivBackward0>)\n",
      "Epoch 804\n",
      " ---------------------- loss: tensor([28747.6367], grad_fn=<DivBackward0>)\n",
      "Epoch 805\n",
      " ---------------------- loss: tensor([28737.5566], grad_fn=<DivBackward0>)\n",
      "Epoch 806\n",
      " ---------------------- loss: tensor([28727.4648], grad_fn=<DivBackward0>)\n",
      "Epoch 807\n",
      " ---------------------- loss: tensor([28717.3145], grad_fn=<DivBackward0>)\n",
      "Epoch 808\n",
      " ---------------------- loss: tensor([28707.0391], grad_fn=<DivBackward0>)\n",
      "Epoch 809\n",
      " ---------------------- loss: tensor([28696.7637], grad_fn=<DivBackward0>)\n",
      "Epoch 810\n",
      " ---------------------- loss: tensor([28686.3633], grad_fn=<DivBackward0>)\n",
      "Epoch 811\n",
      " ---------------------- loss: tensor([28675.9922], grad_fn=<DivBackward0>)\n",
      "Epoch 812\n",
      " ---------------------- loss: tensor([28665.5840], grad_fn=<DivBackward0>)\n",
      "Epoch 813\n",
      " ---------------------- loss: tensor([28655.1465], grad_fn=<DivBackward0>)\n",
      "Epoch 814\n",
      " ---------------------- loss: tensor([28644.7656], grad_fn=<DivBackward0>)\n",
      "Epoch 815\n",
      " ---------------------- loss: tensor([28634.3516], grad_fn=<DivBackward0>)\n",
      "Epoch 816\n",
      " ---------------------- loss: tensor([28623.7715], grad_fn=<DivBackward0>)\n",
      "Epoch 817\n",
      " ---------------------- loss: tensor([28613.0039], grad_fn=<DivBackward0>)\n",
      "Epoch 818\n",
      " ---------------------- loss: tensor([28602.1719], grad_fn=<DivBackward0>)\n",
      "Epoch 819\n",
      " ---------------------- loss: tensor([28591.2598], grad_fn=<DivBackward0>)\n",
      "Epoch 820\n",
      " ---------------------- loss: tensor([28580.3398], grad_fn=<DivBackward0>)\n",
      "Epoch 821\n",
      " ---------------------- loss: tensor([28569.4160], grad_fn=<DivBackward0>)\n",
      "Epoch 822\n",
      " ---------------------- loss: tensor([28558.4492], grad_fn=<DivBackward0>)\n",
      "Epoch 823\n",
      " ---------------------- loss: tensor([28547.3965], grad_fn=<DivBackward0>)\n",
      "Epoch 824\n",
      " ---------------------- loss: tensor([28536.2852], grad_fn=<DivBackward0>)\n",
      "Epoch 825\n",
      " ---------------------- loss: tensor([28525.0859], grad_fn=<DivBackward0>)\n",
      "Epoch 826\n",
      " ---------------------- loss: tensor([28513.9258], grad_fn=<DivBackward0>)\n",
      "Epoch 827\n",
      " ---------------------- loss: tensor([28502.7344], grad_fn=<DivBackward0>)\n",
      "Epoch 828\n",
      " ---------------------- loss: tensor([28491.4883], grad_fn=<DivBackward0>)\n",
      "Epoch 829\n",
      " ---------------------- loss: tensor([28480.1133], grad_fn=<DivBackward0>)\n",
      "Epoch 830\n",
      " ---------------------- loss: tensor([28468.7227], grad_fn=<DivBackward0>)\n",
      "Epoch 831\n",
      " ---------------------- loss: tensor([28457.3320], grad_fn=<DivBackward0>)\n",
      "Epoch 832\n",
      " ---------------------- loss: tensor([28445.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 833\n",
      " ---------------------- loss: tensor([28434.3359], grad_fn=<DivBackward0>)\n",
      "Epoch 834\n",
      " ---------------------- loss: tensor([28422.7812], grad_fn=<DivBackward0>)\n",
      "Epoch 835\n",
      " ---------------------- loss: tensor([28411.0410], grad_fn=<DivBackward0>)\n",
      "Epoch 836\n",
      " ---------------------- loss: tensor([28399.2695], grad_fn=<DivBackward0>)\n",
      "Epoch 837\n",
      " ---------------------- loss: tensor([28387.5449], grad_fn=<DivBackward0>)\n",
      "Epoch 838\n",
      " ---------------------- loss: tensor([28375.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 839\n",
      " ---------------------- loss: tensor([28364.], grad_fn=<DivBackward0>)\n",
      "Epoch 840\n",
      " ---------------------- loss: tensor([28352.0371], grad_fn=<DivBackward0>)\n",
      "Epoch 841\n",
      " ---------------------- loss: tensor([28339.8320], grad_fn=<DivBackward0>)\n",
      "Epoch 842\n",
      " ---------------------- loss: tensor([28327.6543], grad_fn=<DivBackward0>)\n",
      "Epoch 843\n",
      " ---------------------- loss: tensor([28315.4316], grad_fn=<DivBackward0>)\n",
      "Epoch 844\n",
      " ---------------------- loss: tensor([28303.2129], grad_fn=<DivBackward0>)\n",
      "Epoch 845\n",
      " ---------------------- loss: tensor([28291.], grad_fn=<DivBackward0>)\n",
      "Epoch 846\n",
      " ---------------------- loss: tensor([28278.6953], grad_fn=<DivBackward0>)\n",
      "Epoch 847\n",
      " ---------------------- loss: tensor([28266.3770], grad_fn=<DivBackward0>)\n",
      "Epoch 848\n",
      " ---------------------- loss: tensor([28253.9219], grad_fn=<DivBackward0>)\n",
      "Epoch 849\n",
      " ---------------------- loss: tensor([28241.3750], grad_fn=<DivBackward0>)\n",
      "Epoch 850\n",
      " ---------------------- loss: tensor([28228.7969], grad_fn=<DivBackward0>)\n",
      "Epoch 851\n",
      " ---------------------- loss: tensor([28216.1973], grad_fn=<DivBackward0>)\n",
      "Epoch 852\n",
      " ---------------------- loss: tensor([28203.4590], grad_fn=<DivBackward0>)\n",
      "Epoch 853\n",
      " ---------------------- loss: tensor([28190.7070], grad_fn=<DivBackward0>)\n",
      "Epoch 854\n",
      " ---------------------- loss: tensor([28177.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 855\n",
      " ---------------------- loss: tensor([28165.0820], grad_fn=<DivBackward0>)\n",
      "Epoch 856\n",
      " ---------------------- loss: tensor([28152.1328], grad_fn=<DivBackward0>)\n",
      "Epoch 857\n",
      " ---------------------- loss: tensor([28139.1348], grad_fn=<DivBackward0>)\n",
      "Epoch 858\n",
      " ---------------------- loss: tensor([28126.0664], grad_fn=<DivBackward0>)\n",
      "Epoch 859\n",
      " ---------------------- loss: tensor([28112.9668], grad_fn=<DivBackward0>)\n",
      "Epoch 860\n",
      " ---------------------- loss: tensor([28099.8203], grad_fn=<DivBackward0>)\n",
      "Epoch 861\n",
      " ---------------------- loss: tensor([28086.6367], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 862\n",
      " ---------------------- loss: tensor([28073.4473], grad_fn=<DivBackward0>)\n",
      "Epoch 863\n",
      " ---------------------- loss: tensor([28060.1328], grad_fn=<DivBackward0>)\n",
      "Epoch 864\n",
      " ---------------------- loss: tensor([28046.5605], grad_fn=<DivBackward0>)\n",
      "Epoch 865\n",
      " ---------------------- loss: tensor([28032.9902], grad_fn=<DivBackward0>)\n",
      "Epoch 866\n",
      " ---------------------- loss: tensor([28019.4219], grad_fn=<DivBackward0>)\n",
      "Epoch 867\n",
      " ---------------------- loss: tensor([28005.8496], grad_fn=<DivBackward0>)\n",
      "Epoch 868\n",
      " ---------------------- loss: tensor([27992.2266], grad_fn=<DivBackward0>)\n",
      "Epoch 869\n",
      " ---------------------- loss: tensor([27978.4238], grad_fn=<DivBackward0>)\n",
      "Epoch 870\n",
      " ---------------------- loss: tensor([27964.5430], grad_fn=<DivBackward0>)\n",
      "Epoch 871\n",
      " ---------------------- loss: tensor([27950.5156], grad_fn=<DivBackward0>)\n",
      "Epoch 872\n",
      " ---------------------- loss: tensor([27936.4883], grad_fn=<DivBackward0>)\n",
      "Epoch 873\n",
      " ---------------------- loss: tensor([27922.4531], grad_fn=<DivBackward0>)\n",
      "Epoch 874\n",
      " ---------------------- loss: tensor([27908.3496], grad_fn=<DivBackward0>)\n",
      "Epoch 875\n",
      " ---------------------- loss: tensor([27894.2070], grad_fn=<DivBackward0>)\n",
      "Epoch 876\n",
      " ---------------------- loss: tensor([27880.0332], grad_fn=<DivBackward0>)\n",
      "Epoch 877\n",
      " ---------------------- loss: tensor([27865.7930], grad_fn=<DivBackward0>)\n",
      "Epoch 878\n",
      " ---------------------- loss: tensor([27851.4902], grad_fn=<DivBackward0>)\n",
      "Epoch 879\n",
      " ---------------------- loss: tensor([27836.9043], grad_fn=<DivBackward0>)\n",
      "Epoch 880\n",
      " ---------------------- loss: tensor([27822.3516], grad_fn=<DivBackward0>)\n",
      "Epoch 881\n",
      " ---------------------- loss: tensor([27807.8164], grad_fn=<DivBackward0>)\n",
      "Epoch 882\n",
      " ---------------------- loss: tensor([27793.2383], grad_fn=<DivBackward0>)\n",
      "Epoch 883\n",
      " ---------------------- loss: tensor([27778.6660], grad_fn=<DivBackward0>)\n",
      "Epoch 884\n",
      " ---------------------- loss: tensor([27764.0957], grad_fn=<DivBackward0>)\n",
      "Epoch 885\n",
      " ---------------------- loss: tensor([27749.3008], grad_fn=<DivBackward0>)\n",
      "Epoch 886\n",
      " ---------------------- loss: tensor([27734.2109], grad_fn=<DivBackward0>)\n",
      "Epoch 887\n",
      " ---------------------- loss: tensor([27719.1680], grad_fn=<DivBackward0>)\n",
      "Epoch 888\n",
      " ---------------------- loss: tensor([27703.9805], grad_fn=<DivBackward0>)\n",
      "Epoch 889\n",
      " ---------------------- loss: tensor([27688.6797], grad_fn=<DivBackward0>)\n",
      "Epoch 890\n",
      " ---------------------- loss: tensor([27673.3691], grad_fn=<DivBackward0>)\n",
      "Epoch 891\n",
      " ---------------------- loss: tensor([27657.9922], grad_fn=<DivBackward0>)\n",
      "Epoch 892\n",
      " ---------------------- loss: tensor([27642.5273], grad_fn=<DivBackward0>)\n",
      "Epoch 893\n",
      " ---------------------- loss: tensor([27627.1055], grad_fn=<DivBackward0>)\n",
      "Epoch 894\n",
      " ---------------------- loss: tensor([27611.5215], grad_fn=<DivBackward0>)\n",
      "Epoch 895\n",
      " ---------------------- loss: tensor([27595.8965], grad_fn=<DivBackward0>)\n",
      "Epoch 896\n",
      " ---------------------- loss: tensor([27580.1777], grad_fn=<DivBackward0>)\n",
      "Epoch 897\n",
      " ---------------------- loss: tensor([27564.3789], grad_fn=<DivBackward0>)\n",
      "Epoch 898\n",
      " ---------------------- loss: tensor([27548.4941], grad_fn=<DivBackward0>)\n",
      "Epoch 899\n",
      " ---------------------- loss: tensor([27532.5488], grad_fn=<DivBackward0>)\n",
      "Epoch 900\n",
      " ---------------------- loss: tensor([27516.6582], grad_fn=<DivBackward0>)\n",
      "Epoch 901\n",
      " ---------------------- loss: tensor([27500.4395], grad_fn=<DivBackward0>)\n",
      "Epoch 902\n",
      " ---------------------- loss: tensor([27484.2754], grad_fn=<DivBackward0>)\n",
      "Epoch 903\n",
      " ---------------------- loss: tensor([27468.0449], grad_fn=<DivBackward0>)\n",
      "Epoch 904\n",
      " ---------------------- loss: tensor([27451.7227], grad_fn=<DivBackward0>)\n",
      "Epoch 905\n",
      " ---------------------- loss: tensor([27435.4180], grad_fn=<DivBackward0>)\n",
      "Epoch 906\n",
      " ---------------------- loss: tensor([27418.9199], grad_fn=<DivBackward0>)\n",
      "Epoch 907\n",
      " ---------------------- loss: tensor([27402.3027], grad_fn=<DivBackward0>)\n",
      "Epoch 908\n",
      " ---------------------- loss: tensor([27385.5234], grad_fn=<DivBackward0>)\n",
      "Epoch 909\n",
      " ---------------------- loss: tensor([27368.6602], grad_fn=<DivBackward0>)\n",
      "Epoch 910\n",
      " ---------------------- loss: tensor([27351.7383], grad_fn=<DivBackward0>)\n",
      "Epoch 911\n",
      " ---------------------- loss: tensor([27334.7852], grad_fn=<DivBackward0>)\n",
      "Epoch 912\n",
      " ---------------------- loss: tensor([27317.8105], grad_fn=<DivBackward0>)\n",
      "Epoch 913\n",
      " ---------------------- loss: tensor([27300.8047], grad_fn=<DivBackward0>)\n",
      "Epoch 914\n",
      " ---------------------- loss: tensor([27283.8633], grad_fn=<DivBackward0>)\n",
      "Epoch 915\n",
      " ---------------------- loss: tensor([27266.7949], grad_fn=<DivBackward0>)\n",
      "Epoch 916\n",
      " ---------------------- loss: tensor([27249.3789], grad_fn=<DivBackward0>)\n",
      "Epoch 917\n",
      " ---------------------- loss: tensor([27231.9668], grad_fn=<DivBackward0>)\n",
      "Epoch 918\n",
      " ---------------------- loss: tensor([27214.5156], grad_fn=<DivBackward0>)\n",
      "Epoch 919\n",
      " ---------------------- loss: tensor([27196.9316], grad_fn=<DivBackward0>)\n",
      "Epoch 920\n",
      " ---------------------- loss: tensor([27179.3926], grad_fn=<DivBackward0>)\n",
      "Epoch 921\n",
      " ---------------------- loss: tensor([27161.6875], grad_fn=<DivBackward0>)\n",
      "Epoch 922\n",
      " ---------------------- loss: tensor([27143.9297], grad_fn=<DivBackward0>)\n",
      "Epoch 923\n",
      " ---------------------- loss: tensor([27126.1035], grad_fn=<DivBackward0>)\n",
      "Epoch 924\n",
      " ---------------------- loss: tensor([27108.1562], grad_fn=<DivBackward0>)\n",
      "Epoch 925\n",
      " ---------------------- loss: tensor([27090.1621], grad_fn=<DivBackward0>)\n",
      "Epoch 926\n",
      " ---------------------- loss: tensor([27072.0566], grad_fn=<DivBackward0>)\n",
      "Epoch 927\n",
      " ---------------------- loss: tensor([27053.8887], grad_fn=<DivBackward0>)\n",
      "Epoch 928\n",
      " ---------------------- loss: tensor([27035.6953], grad_fn=<DivBackward0>)\n",
      "Epoch 929\n",
      " ---------------------- loss: tensor([27017.4707], grad_fn=<DivBackward0>)\n",
      "Epoch 930\n",
      " ---------------------- loss: tensor([26999.0410], grad_fn=<DivBackward0>)\n",
      "Epoch 931\n",
      " ---------------------- loss: tensor([26980.4512], grad_fn=<DivBackward0>)\n",
      "Epoch 932\n",
      " ---------------------- loss: tensor([26961.9805], grad_fn=<DivBackward0>)\n",
      "Epoch 933\n",
      " ---------------------- loss: tensor([26943.4512], grad_fn=<DivBackward0>)\n",
      "Epoch 934\n",
      " ---------------------- loss: tensor([26924.8340], grad_fn=<DivBackward0>)\n",
      "Epoch 935\n",
      " ---------------------- loss: tensor([26906.1387], grad_fn=<DivBackward0>)\n",
      "Epoch 936\n",
      " ---------------------- loss: tensor([26887.2793], grad_fn=<DivBackward0>)\n",
      "Epoch 937\n",
      " ---------------------- loss: tensor([26868.2363], grad_fn=<DivBackward0>)\n",
      "Epoch 938\n",
      " ---------------------- loss: tensor([26849.1895], grad_fn=<DivBackward0>)\n",
      "Epoch 939\n",
      " ---------------------- loss: tensor([26830.0879], grad_fn=<DivBackward0>)\n",
      "Epoch 940\n",
      " ---------------------- loss: tensor([26810.9805], grad_fn=<DivBackward0>)\n",
      "Epoch 941\n",
      " ---------------------- loss: tensor([26791.8066], grad_fn=<DivBackward0>)\n",
      "Epoch 942\n",
      " ---------------------- loss: tensor([26772.5273], grad_fn=<DivBackward0>)\n",
      "Epoch 943\n",
      " ---------------------- loss: tensor([26753.1680], grad_fn=<DivBackward0>)\n",
      "Epoch 944\n",
      " ---------------------- loss: tensor([26733.7031], grad_fn=<DivBackward0>)\n",
      "Epoch 945\n",
      " ---------------------- loss: tensor([26714.0918], grad_fn=<DivBackward0>)\n",
      "Epoch 946\n",
      " ---------------------- loss: tensor([26694.4668], grad_fn=<DivBackward0>)\n",
      "Epoch 947\n",
      " ---------------------- loss: tensor([26674.7637], grad_fn=<DivBackward0>)\n",
      "Epoch 948\n",
      " ---------------------- loss: tensor([26654.9238], grad_fn=<DivBackward0>)\n",
      "Epoch 949\n",
      " ---------------------- loss: tensor([26635.0117], grad_fn=<DivBackward0>)\n",
      "Epoch 950\n",
      " ---------------------- loss: tensor([26615.1426], grad_fn=<DivBackward0>)\n",
      "Epoch 951\n",
      " ---------------------- loss: tensor([26595.0605], grad_fn=<DivBackward0>)\n",
      "Epoch 952\n",
      " ---------------------- loss: tensor([26574.5918], grad_fn=<DivBackward0>)\n",
      "Epoch 953\n",
      " ---------------------- loss: tensor([26554.1465], grad_fn=<DivBackward0>)\n",
      "Epoch 954\n",
      " ---------------------- loss: tensor([26533.7695], grad_fn=<DivBackward0>)\n",
      "Epoch 955\n",
      " ---------------------- loss: tensor([26513.3223], grad_fn=<DivBackward0>)\n",
      "Epoch 956\n",
      " ---------------------- loss: tensor([26492.7676], grad_fn=<DivBackward0>)\n",
      "Epoch 957\n",
      " ---------------------- loss: tensor([26472.1230], grad_fn=<DivBackward0>)\n",
      "Epoch 958\n",
      " ---------------------- loss: tensor([26451.5039], grad_fn=<DivBackward0>)\n",
      "Epoch 959\n",
      " ---------------------- loss: tensor([26430.7383], grad_fn=<DivBackward0>)\n",
      "Epoch 960\n",
      " ---------------------- loss: tensor([26409.7871], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961\n",
      " ---------------------- loss: tensor([26388.7090], grad_fn=<DivBackward0>)\n",
      "Epoch 962\n",
      " ---------------------- loss: tensor([26367.6094], grad_fn=<DivBackward0>)\n",
      "Epoch 963\n",
      " ---------------------- loss: tensor([26346.4688], grad_fn=<DivBackward0>)\n",
      "Epoch 964\n",
      " ---------------------- loss: tensor([26325.3887], grad_fn=<DivBackward0>)\n",
      "Epoch 965\n",
      " ---------------------- loss: tensor([26304.1953], grad_fn=<DivBackward0>)\n",
      "Epoch 966\n",
      " ---------------------- loss: tensor([26282.9219], grad_fn=<DivBackward0>)\n",
      "Epoch 967\n",
      " ---------------------- loss: tensor([26261.4941], grad_fn=<DivBackward0>)\n",
      "Epoch 968\n",
      " ---------------------- loss: tensor([26239.9238], grad_fn=<DivBackward0>)\n",
      "Epoch 969\n",
      " ---------------------- loss: tensor([26218.0957], grad_fn=<DivBackward0>)\n",
      "Epoch 970\n",
      " ---------------------- loss: tensor([26196.0898], grad_fn=<DivBackward0>)\n",
      "Epoch 971\n",
      " ---------------------- loss: tensor([26174.0352], grad_fn=<DivBackward0>)\n",
      "Epoch 972\n",
      " ---------------------- loss: tensor([26152.0391], grad_fn=<DivBackward0>)\n",
      "Epoch 973\n",
      " ---------------------- loss: tensor([26129.9512], grad_fn=<DivBackward0>)\n",
      "Epoch 974\n",
      " ---------------------- loss: tensor([26107.7539], grad_fn=<DivBackward0>)\n",
      "Epoch 975\n",
      " ---------------------- loss: tensor([26085.4277], grad_fn=<DivBackward0>)\n",
      "Epoch 976\n",
      " ---------------------- loss: tensor([26063.0020], grad_fn=<DivBackward0>)\n",
      "Epoch 977\n",
      " ---------------------- loss: tensor([26040.5820], grad_fn=<DivBackward0>)\n",
      "Epoch 978\n",
      " ---------------------- loss: tensor([26018.1094], grad_fn=<DivBackward0>)\n",
      "Epoch 979\n",
      " ---------------------- loss: tensor([25995.5488], grad_fn=<DivBackward0>)\n",
      "Epoch 980\n",
      " ---------------------- loss: tensor([25972.8613], grad_fn=<DivBackward0>)\n",
      "Epoch 981\n",
      " ---------------------- loss: tensor([25950.1074], grad_fn=<DivBackward0>)\n",
      "Epoch 982\n",
      " ---------------------- loss: tensor([25927.1230], grad_fn=<DivBackward0>)\n",
      "Epoch 983\n",
      " ---------------------- loss: tensor([25904.1562], grad_fn=<DivBackward0>)\n",
      "Epoch 984\n",
      " ---------------------- loss: tensor([25881.2051], grad_fn=<DivBackward0>)\n",
      "Epoch 985\n",
      " ---------------------- loss: tensor([25858.1602], grad_fn=<DivBackward0>)\n",
      "Epoch 986\n",
      " ---------------------- loss: tensor([25835.0195], grad_fn=<DivBackward0>)\n",
      "Epoch 987\n",
      " ---------------------- loss: tensor([25811.7695], grad_fn=<DivBackward0>)\n",
      "Epoch 988\n",
      " ---------------------- loss: tensor([25788.3438], grad_fn=<DivBackward0>)\n",
      "Epoch 989\n",
      " ---------------------- loss: tensor([25764.6504], grad_fn=<DivBackward0>)\n",
      "Epoch 990\n",
      " ---------------------- loss: tensor([25740.7383], grad_fn=<DivBackward0>)\n",
      "Epoch 991\n",
      " ---------------------- loss: tensor([25716.8145], grad_fn=<DivBackward0>)\n",
      "Epoch 992\n",
      " ---------------------- loss: tensor([25692.8535], grad_fn=<DivBackward0>)\n",
      "Epoch 993\n",
      " ---------------------- loss: tensor([25668.9082], grad_fn=<DivBackward0>)\n",
      "Epoch 994\n",
      " ---------------------- loss: tensor([25644.9824], grad_fn=<DivBackward0>)\n",
      "Epoch 995\n",
      " ---------------------- loss: tensor([25620.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 996\n",
      " ---------------------- loss: tensor([25596.8242], grad_fn=<DivBackward0>)\n",
      "Epoch 997\n",
      " ---------------------- loss: tensor([25572.4512], grad_fn=<DivBackward0>)\n",
      "Epoch 998\n",
      " ---------------------- loss: tensor([25547.9941], grad_fn=<DivBackward0>)\n",
      "Epoch 999\n",
      " ---------------------- loss: tensor([25523.4941], grad_fn=<DivBackward0>)\n",
      "Epoch 1000\n",
      " ---------------------- loss: tensor([25498.8906], grad_fn=<DivBackward0>)\n",
      "Done!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upper_r = 6\n",
    "lower_r = 1e-2\n",
    "steps = 100\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "epochs = [200, 400, 600, 800, 1000]\n",
    "lrs = 1e-5\n",
    "Phis_t = []\n",
    "Es = []\n",
    "\n",
    "for epoch in epochs:\n",
    "    model = NeuralNetwork().to(device)\n",
    "    initialize_weights(model)\n",
    "    optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)\n",
    "    for t in range(epoch):\n",
    "        print(f\"Epoch {t+1}\\n ---------------------- loss: {loss_fn(R_train.to(device))}\")\n",
    "        training(R_train, loss_fn, optimizer)\n",
    "    print(\"Done!\\n\\n\")\n",
    "    Phis_t.append(Phi_t(R_train).detach().numpy())\n",
    "    Es.append(E.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59fdecbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = np.linspace(lower_r, upper_r, steps)[:,None]\n",
    "fig, axs = plt.subplots(2,3,figsize=(15,7))\n",
    "\n",
    "fil = 0\n",
    "col = 0\n",
    "for i in range(len(Es)):\n",
    "    yy = Phis_t[i]\n",
    "    axs[fil,col].plot(rr, yy.squeeze(), \".\", label=f\"Epochs {epochs[i]}\")\n",
    "    axs[fil,col].set_xlabel(\"$r$\")\n",
    "    axs[fil,col].set_ylabel(\"$\\phi(x)$\")\n",
    "    axs[fil,col].legend(loc=\"best\")\n",
    "    axs[fil,col].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    if col == 2:\n",
    "       col = 0\n",
    "       fil = fil+1\n",
    "    else:\n",
    "       col = col+1\n",
    "axs[1,2].plot(epochs, Es, \"r.\", label=\"Energies\")\n",
    "axs[1,2].legend(loc=\"best\")\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d34983f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-3.8018124], dtype=float32),\n",
       " array([-6.030247], dtype=float32),\n",
       " array([0.9127078], dtype=float32),\n",
       " array([0.7607378], dtype=float32),\n",
       " array([-19.443386], dtype=float32)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd372e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7e01634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    # Initializes weights according to the DCGAN paper\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Linear)):\n",
    "            nn.init.xavier_normal_(m.weight.data, 0.01)\n",
    "        # if you also want for linear layers ,add one more elif condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8cc6ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x, loss_fn, optimizer):\n",
    "    x = x.to(device)\n",
    "    def closure():\n",
    "        loss = loss_fn(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9bdb5cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------- loss: tensor([16593.7715], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([16591.9785], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([16590.1094], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([16588.2109], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([16586.2832], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([16584.3359], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([16582.3613], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([16580.3496], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([16578.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([16576.2461], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([16574.1406], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([16572.0039], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([16569.8379], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([16567.6230], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([16565.3730], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([16563.0840], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([16560.7578], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([16558.3867], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([16555.9609], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([16553.4922], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([16550.9707], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([16548.3984], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([16545.7734], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([16543.0820], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([16540.3340], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([16537.5234], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([16534.6348], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([16531.6855], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([16528.6465], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([16525.5430], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([16522.3398], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([16519.0586], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([16515.6602], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([16512.1797], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([16508.5762], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([16504.8516], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([16501.0039], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([16497.0176], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([16492.8926], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([16488.6055], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([16484.1289], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([16479.4785], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([16474.6113], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([16469.5371], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([16464.1973], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([16458.5938], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([16452.6875], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([16446.4336], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([16439.7891], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([16432.7207], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([16425.1836], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([16417.0664], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([16408.3125], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([16398.8086], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([16388.3594], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([16376.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([16364.0586], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([16349.6484], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([16333.1230], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([16313.8857], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([16290.9482], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([16262.7139], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([16226.3838], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([16176.2656], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([16098.5889], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([15942.7510], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([14381.4258], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([17704.6660], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([17674.6172], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([17644.0762], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([17613.2734], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([17581.8750], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([17550.1719], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([17518.1191], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([17485.6719], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([17452.7539], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([17419.3965], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([17385.8184], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([17351.6191], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([17317.0684], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([17282.2852], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([17246.9648], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([17211.2852], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([17175.2285], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([17138.7832], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([17102.0117], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([17064.7617], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([17027.1504], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([16989.2305], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([16950.9062], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([16912.2266], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([16873.1855], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([16833.8262], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([16794.0898], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([16754.0215], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([16713.6289], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([16672.9141], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([16631.8711], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([16590.5098], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100\n",
      " ---------------------- loss: tensor([16548.8594], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([16506.8867], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([16464.6289], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([16422.0938], grad_fn=<DivBackward0>)\n",
      "Epoch 104\n",
      " ---------------------- loss: tensor([16379.2832], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([16336.1914], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([16292.8486], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([16249.2783], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([16205.3877], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([16161.3223], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([16117.0156], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([16072.4648], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([16027.6885], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([15982.7393], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([15937.5732], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([15892.2080], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([15846.6953], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([15800.9844], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([15755.1250], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([15709.1025], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([15662.9277], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([14204.2373], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([13699.2959], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([13333.9531], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([13022.1953], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([12726.6426], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([12436.9688], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([12114.2910], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([11784.0547], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([11329.1211], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([10799.2090], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([10347.4912], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([9936.1875], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([9508.4648], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([9123.1787], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([8752.9414], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([8381.4785], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([7769.3906], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([7132.7515], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([6611.0996], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([6068.6631], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([5500.6885], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([4961.8745], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([2388.8054], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([373.8375], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([370.4247], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([360.3722], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([324.0316], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([299.9516], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([283.3784], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([270.5204], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([259.5908], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([246.7914], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([226.5197], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([211.6616], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([200.7949], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([192.0733], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([184.3545], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([176.8856], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([166.5484], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([156.3888], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([149.5059], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([144.1768], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([139.1444], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([134.2990], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([129.2440], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([122.2667], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([117.2128], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([113.8061], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([110.6581], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([107.3750], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([104.4316], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([100.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([96.5939], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([94.1922], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([92.2499], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([90.1362], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([88.1643], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([85.8375], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([83.3859], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([81.7034], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([80.4253], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([79.1215], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([77.8581], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([76.5680], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([75.0515], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([73.9080], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([73.0311], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([72.2218], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([71.4345], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([70.6590], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([69.8656], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([69.1799], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([68.5715], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([67.9901], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([67.4481], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([66.9713], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([66.5038], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([66.1332], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199\n",
      " ---------------------- loss: tensor([65.7330], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([65.2669], grad_fn=<DivBackward0>)\n",
      "Epoch 201\n",
      " ---------------------- loss: tensor([64.8702], grad_fn=<DivBackward0>)\n",
      "Epoch 202\n",
      " ---------------------- loss: tensor([64.4674], grad_fn=<DivBackward0>)\n",
      "Epoch 203\n",
      " ---------------------- loss: tensor([64.2350], grad_fn=<DivBackward0>)\n",
      "Epoch 204\n",
      " ---------------------- loss: tensor([64.0195], grad_fn=<DivBackward0>)\n",
      "Epoch 205\n",
      " ---------------------- loss: tensor([63.7630], grad_fn=<DivBackward0>)\n",
      "Epoch 206\n",
      " ---------------------- loss: tensor([63.3808], grad_fn=<DivBackward0>)\n",
      "Epoch 207\n",
      " ---------------------- loss: tensor([63.0114], grad_fn=<DivBackward0>)\n",
      "Epoch 208\n",
      " ---------------------- loss: tensor([62.8264], grad_fn=<DivBackward0>)\n",
      "Epoch 209\n",
      " ---------------------- loss: tensor([62.6260], grad_fn=<DivBackward0>)\n",
      "Epoch 210\n",
      " ---------------------- loss: tensor([62.4835], grad_fn=<DivBackward0>)\n",
      "Epoch 211\n",
      " ---------------------- loss: tensor([62.2507], grad_fn=<DivBackward0>)\n",
      "Epoch 212\n",
      " ---------------------- loss: tensor([61.9682], grad_fn=<DivBackward0>)\n",
      "Epoch 213\n",
      " ---------------------- loss: tensor([61.7533], grad_fn=<DivBackward0>)\n",
      "Epoch 214\n",
      " ---------------------- loss: tensor([61.4398], grad_fn=<DivBackward0>)\n",
      "Epoch 215\n",
      " ---------------------- loss: tensor([60.8254], grad_fn=<DivBackward0>)\n",
      "Epoch 216\n",
      " ---------------------- loss: tensor([60.7971], grad_fn=<DivBackward0>)\n",
      "Epoch 217\n",
      " ---------------------- loss: tensor([60.7425], grad_fn=<DivBackward0>)\n",
      "Epoch 218\n",
      " ---------------------- loss: tensor([60.6800], grad_fn=<DivBackward0>)\n",
      "Epoch 219\n",
      " ---------------------- loss: tensor([60.4381], grad_fn=<DivBackward0>)\n",
      "Epoch 220\n",
      " ---------------------- loss: tensor([60.2478], grad_fn=<DivBackward0>)\n",
      "Epoch 221\n",
      " ---------------------- loss: tensor([60.0958], grad_fn=<DivBackward0>)\n",
      "Epoch 222\n",
      " ---------------------- loss: tensor([59.9286], grad_fn=<DivBackward0>)\n",
      "Epoch 223\n",
      " ---------------------- loss: tensor([59.8378], grad_fn=<DivBackward0>)\n",
      "Epoch 224\n",
      " ---------------------- loss: tensor([59.6596], grad_fn=<DivBackward0>)\n",
      "Epoch 225\n",
      " ---------------------- loss: tensor([59.5550], grad_fn=<DivBackward0>)\n",
      "Epoch 226\n",
      " ---------------------- loss: tensor([59.4126], grad_fn=<DivBackward0>)\n",
      "Epoch 227\n",
      " ---------------------- loss: tensor([59.2380], grad_fn=<DivBackward0>)\n",
      "Epoch 228\n",
      " ---------------------- loss: tensor([59.0748], grad_fn=<DivBackward0>)\n",
      "Epoch 229\n",
      " ---------------------- loss: tensor([58.7874], grad_fn=<DivBackward0>)\n",
      "Epoch 230\n",
      " ---------------------- loss: tensor([56.9197], grad_fn=<DivBackward0>)\n",
      "Epoch 231\n",
      " ---------------------- loss: tensor([54.7929], grad_fn=<DivBackward0>)\n",
      "Epoch 232\n",
      " ---------------------- loss: tensor([54.3488], grad_fn=<DivBackward0>)\n",
      "Epoch 233\n",
      " ---------------------- loss: tensor([52.9569], grad_fn=<DivBackward0>)\n",
      "Epoch 234\n",
      " ---------------------- loss: tensor([52.9418], grad_fn=<DivBackward0>)\n",
      "Epoch 235\n",
      " ---------------------- loss: tensor([52.7280], grad_fn=<DivBackward0>)\n",
      "Epoch 236\n",
      " ---------------------- loss: tensor([52.6948], grad_fn=<DivBackward0>)\n",
      "Epoch 237\n",
      " ---------------------- loss: tensor([52.6790], grad_fn=<DivBackward0>)\n",
      "Epoch 238\n",
      " ---------------------- loss: tensor([52.6682], grad_fn=<DivBackward0>)\n",
      "Epoch 239\n",
      " ---------------------- loss: tensor([52.6216], grad_fn=<DivBackward0>)\n",
      "Epoch 240\n",
      " ---------------------- loss: tensor([52.5904], grad_fn=<DivBackward0>)\n",
      "Epoch 241\n",
      " ---------------------- loss: tensor([52.5838], grad_fn=<DivBackward0>)\n",
      "Epoch 242\n",
      " ---------------------- loss: tensor([52.5784], grad_fn=<DivBackward0>)\n",
      "Epoch 243\n",
      " ---------------------- loss: tensor([52.1949], grad_fn=<DivBackward0>)\n",
      "Epoch 244\n",
      " ---------------------- loss: tensor([52.1289], grad_fn=<DivBackward0>)\n",
      "Epoch 245\n",
      " ---------------------- loss: tensor([52.0377], grad_fn=<DivBackward0>)\n",
      "Epoch 246\n",
      " ---------------------- loss: tensor([51.9909], grad_fn=<DivBackward0>)\n",
      "Epoch 247\n",
      " ---------------------- loss: tensor([51.9877], grad_fn=<DivBackward0>)\n",
      "Epoch 248\n",
      " ---------------------- loss: tensor([51.8828], grad_fn=<DivBackward0>)\n",
      "Epoch 249\n",
      " ---------------------- loss: tensor([51.8383], grad_fn=<DivBackward0>)\n",
      "Epoch 250\n",
      " ---------------------- loss: tensor([51.7782], grad_fn=<DivBackward0>)\n",
      "Epoch 251\n",
      " ---------------------- loss: tensor([51.6777], grad_fn=<DivBackward0>)\n",
      "Epoch 252\n",
      " ---------------------- loss: tensor([51.4527], grad_fn=<DivBackward0>)\n",
      "Epoch 253\n",
      " ---------------------- loss: tensor([1795.2616], grad_fn=<DivBackward0>)\n",
      "Epoch 254\n",
      " ---------------------- loss: tensor([1757.6356], grad_fn=<DivBackward0>)\n",
      "Epoch 255\n",
      " ---------------------- loss: tensor([1712.7012], grad_fn=<DivBackward0>)\n",
      "Epoch 256\n",
      " ---------------------- loss: tensor([1657.7222], grad_fn=<DivBackward0>)\n",
      "Epoch 257\n",
      " ---------------------- loss: tensor([1590.0659], grad_fn=<DivBackward0>)\n",
      "Epoch 258\n",
      " ---------------------- loss: tensor([1507.1272], grad_fn=<DivBackward0>)\n",
      "Epoch 259\n",
      " ---------------------- loss: tensor([1402.7457], grad_fn=<DivBackward0>)\n",
      "Epoch 260\n",
      " ---------------------- loss: tensor([1275.9990], grad_fn=<DivBackward0>)\n",
      "Epoch 261\n",
      " ---------------------- loss: tensor([1127.8464], grad_fn=<DivBackward0>)\n",
      "Epoch 262\n",
      " ---------------------- loss: tensor([963.4368], grad_fn=<DivBackward0>)\n",
      "Epoch 263\n",
      " ---------------------- loss: tensor([591.0867], grad_fn=<DivBackward0>)\n",
      "Epoch 264\n",
      " ---------------------- loss: tensor([369.9268], grad_fn=<DivBackward0>)\n",
      "Epoch 265\n",
      " ---------------------- loss: tensor([368.0231], grad_fn=<DivBackward0>)\n",
      "Epoch 266\n",
      " ---------------------- loss: tensor([366.4750], grad_fn=<DivBackward0>)\n",
      "Epoch 267\n",
      " ---------------------- loss: tensor([364.7390], grad_fn=<DivBackward0>)\n",
      "Epoch 268\n",
      " ---------------------- loss: tensor([333.4050], grad_fn=<DivBackward0>)\n",
      "Epoch 269\n",
      " ---------------------- loss: tensor([330.8216], grad_fn=<DivBackward0>)\n",
      "Epoch 270\n",
      " ---------------------- loss: tensor([329.4011], grad_fn=<DivBackward0>)\n",
      "Epoch 271\n",
      " ---------------------- loss: tensor([324.7472], grad_fn=<DivBackward0>)\n",
      "Epoch 272\n",
      " ---------------------- loss: tensor([317.5543], grad_fn=<DivBackward0>)\n",
      "Epoch 273\n",
      " ---------------------- loss: tensor([304.1399], grad_fn=<DivBackward0>)\n",
      "Epoch 274\n",
      " ---------------------- loss: tensor([258.5991], grad_fn=<DivBackward0>)\n",
      "Epoch 275\n",
      " ---------------------- loss: tensor([255.5515], grad_fn=<DivBackward0>)\n",
      "Epoch 276\n",
      " ---------------------- loss: tensor([253.9699], grad_fn=<DivBackward0>)\n",
      "Epoch 277\n",
      " ---------------------- loss: tensor([251.1298], grad_fn=<DivBackward0>)\n",
      "Epoch 278\n",
      " ---------------------- loss: tensor([249.7125], grad_fn=<DivBackward0>)\n",
      "Epoch 279\n",
      " ---------------------- loss: tensor([227.4340], grad_fn=<DivBackward0>)\n",
      "Epoch 280\n",
      " ---------------------- loss: tensor([223.2304], grad_fn=<DivBackward0>)\n",
      "Epoch 281\n",
      " ---------------------- loss: tensor([201.5281], grad_fn=<DivBackward0>)\n",
      "Epoch 282\n",
      " ---------------------- loss: tensor([181.2447], grad_fn=<DivBackward0>)\n",
      "Epoch 283\n",
      " ---------------------- loss: tensor([170.4350], grad_fn=<DivBackward0>)\n",
      "Epoch 284\n",
      " ---------------------- loss: tensor([141.9533], grad_fn=<DivBackward0>)\n",
      "Epoch 285\n",
      " ---------------------- loss: tensor([140.5694], grad_fn=<DivBackward0>)\n",
      "Epoch 286\n",
      " ---------------------- loss: tensor([139.7161], grad_fn=<DivBackward0>)\n",
      "Epoch 287\n",
      " ---------------------- loss: tensor([138.6497], grad_fn=<DivBackward0>)\n",
      "Epoch 288\n",
      " ---------------------- loss: tensor([138.2523], grad_fn=<DivBackward0>)\n",
      "Epoch 289\n",
      " ---------------------- loss: tensor([137.2000], grad_fn=<DivBackward0>)\n",
      "Epoch 290\n",
      " ---------------------- loss: tensor([136.6698], grad_fn=<DivBackward0>)\n",
      "Epoch 291\n",
      " ---------------------- loss: tensor([136.5894], grad_fn=<DivBackward0>)\n",
      "Epoch 292\n",
      " ---------------------- loss: tensor([136.3861], grad_fn=<DivBackward0>)\n",
      "Epoch 293\n",
      " ---------------------- loss: tensor([135.2948], grad_fn=<DivBackward0>)\n",
      "Epoch 294\n",
      " ---------------------- loss: tensor([100.8921], grad_fn=<DivBackward0>)\n",
      "Epoch 295\n",
      " ---------------------- loss: tensor([98.9687], grad_fn=<DivBackward0>)\n",
      "Epoch 296\n",
      " ---------------------- loss: tensor([98.8001], grad_fn=<DivBackward0>)\n",
      "Epoch 297\n",
      " ---------------------- loss: tensor([97.2451], grad_fn=<DivBackward0>)\n",
      "Epoch 298\n",
      " ---------------------- loss: tensor([96.8183], grad_fn=<DivBackward0>)\n",
      "Epoch 299\n",
      " ---------------------- loss: tensor([95.7403], grad_fn=<DivBackward0>)\n",
      "Epoch 300\n",
      " ---------------------- loss: tensor([95.2090], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301\n",
      " ---------------------- loss: tensor([90.4188], grad_fn=<DivBackward0>)\n",
      "Epoch 302\n",
      " ---------------------- loss: tensor([85.7574], grad_fn=<DivBackward0>)\n",
      "Epoch 303\n",
      " ---------------------- loss: tensor([85.6140], grad_fn=<DivBackward0>)\n",
      "Epoch 304\n",
      " ---------------------- loss: tensor([84.7527], grad_fn=<DivBackward0>)\n",
      "Epoch 305\n",
      " ---------------------- loss: tensor([83.8665], grad_fn=<DivBackward0>)\n",
      "Epoch 306\n",
      " ---------------------- loss: tensor([82.9888], grad_fn=<DivBackward0>)\n",
      "Epoch 307\n",
      " ---------------------- loss: tensor([83.0031], grad_fn=<DivBackward0>)\n",
      "Epoch 308\n",
      " ---------------------- loss: tensor([83.1050], grad_fn=<DivBackward0>)\n",
      "Epoch 309\n",
      " ---------------------- loss: tensor([83.2152], grad_fn=<DivBackward0>)\n",
      "Epoch 310\n",
      " ---------------------- loss: tensor([83.0720], grad_fn=<DivBackward0>)\n",
      "Epoch 311\n",
      " ---------------------- loss: tensor([82.9809], grad_fn=<DivBackward0>)\n",
      "Epoch 312\n",
      " ---------------------- loss: tensor([82.9574], grad_fn=<DivBackward0>)\n",
      "Epoch 313\n",
      " ---------------------- loss: tensor([82.9357], grad_fn=<DivBackward0>)\n",
      "Epoch 314\n",
      " ---------------------- loss: tensor([81.0310], grad_fn=<DivBackward0>)\n",
      "Epoch 315\n",
      " ---------------------- loss: tensor([80.0181], grad_fn=<DivBackward0>)\n",
      "Epoch 316\n",
      " ---------------------- loss: tensor([78.7894], grad_fn=<DivBackward0>)\n",
      "Epoch 317\n",
      " ---------------------- loss: tensor([78.4922], grad_fn=<DivBackward0>)\n",
      "Epoch 318\n",
      " ---------------------- loss: tensor([78.2944], grad_fn=<DivBackward0>)\n",
      "Epoch 319\n",
      " ---------------------- loss: tensor([76.9225], grad_fn=<DivBackward0>)\n",
      "Epoch 320\n",
      " ---------------------- loss: tensor([74.4500], grad_fn=<DivBackward0>)\n",
      "Epoch 321\n",
      " ---------------------- loss: tensor([73.1232], grad_fn=<DivBackward0>)\n",
      "Epoch 322\n",
      " ---------------------- loss: tensor([71.1540], grad_fn=<DivBackward0>)\n",
      "Epoch 323\n",
      " ---------------------- loss: tensor([70.3083], grad_fn=<DivBackward0>)\n",
      "Epoch 324\n",
      " ---------------------- loss: tensor([68.6348], grad_fn=<DivBackward0>)\n",
      "Epoch 325\n",
      " ---------------------- loss: tensor([68.3191], grad_fn=<DivBackward0>)\n",
      "Epoch 326\n",
      " ---------------------- loss: tensor([68.3027], grad_fn=<DivBackward0>)\n",
      "Epoch 327\n",
      " ---------------------- loss: tensor([68.2058], grad_fn=<DivBackward0>)\n",
      "Epoch 328\n",
      " ---------------------- loss: tensor([68.1542], grad_fn=<DivBackward0>)\n",
      "Epoch 329\n",
      " ---------------------- loss: tensor([68.1249], grad_fn=<DivBackward0>)\n",
      "Epoch 330\n",
      " ---------------------- loss: tensor([68.0814], grad_fn=<DivBackward0>)\n",
      "Epoch 331\n",
      " ---------------------- loss: tensor([67.2020], grad_fn=<DivBackward0>)\n",
      "Epoch 332\n",
      " ---------------------- loss: tensor([66.2399], grad_fn=<DivBackward0>)\n",
      "Epoch 333\n",
      " ---------------------- loss: tensor([65.0982], grad_fn=<DivBackward0>)\n",
      "Epoch 334\n",
      " ---------------------- loss: tensor([63.9290], grad_fn=<DivBackward0>)\n",
      "Epoch 335\n",
      " ---------------------- loss: tensor([62.7771], grad_fn=<DivBackward0>)\n",
      "Epoch 336\n",
      " ---------------------- loss: tensor([61.4483], grad_fn=<DivBackward0>)\n",
      "Epoch 337\n",
      " ---------------------- loss: tensor([60.0614], grad_fn=<DivBackward0>)\n",
      "Epoch 338\n",
      " ---------------------- loss: tensor([56.5631], grad_fn=<DivBackward0>)\n",
      "Epoch 339\n",
      " ---------------------- loss: tensor([54.8564], grad_fn=<DivBackward0>)\n",
      "Epoch 340\n",
      " ---------------------- loss: tensor([54.8396], grad_fn=<DivBackward0>)\n",
      "Epoch 341\n",
      " ---------------------- loss: tensor([54.3991], grad_fn=<DivBackward0>)\n",
      "Epoch 342\n",
      " ---------------------- loss: tensor([53.1342], grad_fn=<DivBackward0>)\n",
      "Epoch 343\n",
      " ---------------------- loss: tensor([50.7810], grad_fn=<DivBackward0>)\n",
      "Epoch 344\n",
      " ---------------------- loss: tensor([48.3598], grad_fn=<DivBackward0>)\n",
      "Epoch 345\n",
      " ---------------------- loss: tensor([45.8212], grad_fn=<DivBackward0>)\n",
      "Epoch 346\n",
      " ---------------------- loss: tensor([43.2142], grad_fn=<DivBackward0>)\n",
      "Epoch 347\n",
      " ---------------------- loss: tensor([41.0740], grad_fn=<DivBackward0>)\n",
      "Epoch 348\n",
      " ---------------------- loss: tensor([35.3700], grad_fn=<DivBackward0>)\n",
      "Epoch 349\n",
      " ---------------------- loss: tensor([35.0039], grad_fn=<DivBackward0>)\n",
      "Epoch 350\n",
      " ---------------------- loss: tensor([35.0097], grad_fn=<DivBackward0>)\n",
      "Epoch 351\n",
      " ---------------------- loss: tensor([35.0281], grad_fn=<DivBackward0>)\n",
      "Epoch 352\n",
      " ---------------------- loss: tensor([35.0038], grad_fn=<DivBackward0>)\n",
      "Epoch 353\n",
      " ---------------------- loss: tensor([34.9321], grad_fn=<DivBackward0>)\n",
      "Epoch 354\n",
      " ---------------------- loss: tensor([34.6347], grad_fn=<DivBackward0>)\n",
      "Epoch 355\n",
      " ---------------------- loss: tensor([34.3553], grad_fn=<DivBackward0>)\n",
      "Epoch 356\n",
      " ---------------------- loss: tensor([34.0248], grad_fn=<DivBackward0>)\n",
      "Epoch 357\n",
      " ---------------------- loss: tensor([33.4956], grad_fn=<DivBackward0>)\n",
      "Epoch 358\n",
      " ---------------------- loss: tensor([33.0041], grad_fn=<DivBackward0>)\n",
      "Epoch 359\n",
      " ---------------------- loss: tensor([32.4343], grad_fn=<DivBackward0>)\n",
      "Epoch 360\n",
      " ---------------------- loss: tensor([32.4122], grad_fn=<DivBackward0>)\n",
      "Epoch 361\n",
      " ---------------------- loss: tensor([30.2064], grad_fn=<DivBackward0>)\n",
      "Epoch 362\n",
      " ---------------------- loss: tensor([29.0648], grad_fn=<DivBackward0>)\n",
      "Epoch 363\n",
      " ---------------------- loss: tensor([29.0070], grad_fn=<DivBackward0>)\n",
      "Epoch 364\n",
      " ---------------------- loss: tensor([28.9378], grad_fn=<DivBackward0>)\n",
      "Epoch 365\n",
      " ---------------------- loss: tensor([28.9020], grad_fn=<DivBackward0>)\n",
      "Epoch 366\n",
      " ---------------------- loss: tensor([28.7410], grad_fn=<DivBackward0>)\n",
      "Epoch 367\n",
      " ---------------------- loss: tensor([28.5912], grad_fn=<DivBackward0>)\n",
      "Epoch 368\n",
      " ---------------------- loss: tensor([28.4351], grad_fn=<DivBackward0>)\n",
      "Epoch 369\n",
      " ---------------------- loss: tensor([28.2898], grad_fn=<DivBackward0>)\n",
      "Epoch 370\n",
      " ---------------------- loss: tensor([28.1420], grad_fn=<DivBackward0>)\n",
      "Epoch 371\n",
      " ---------------------- loss: tensor([27.9875], grad_fn=<DivBackward0>)\n",
      "Epoch 372\n",
      " ---------------------- loss: tensor([27.7906], grad_fn=<DivBackward0>)\n",
      "Epoch 373\n",
      " ---------------------- loss: tensor([27.3594], grad_fn=<DivBackward0>)\n",
      "Epoch 374\n",
      " ---------------------- loss: tensor([26.8366], grad_fn=<DivBackward0>)\n",
      "Epoch 375\n",
      " ---------------------- loss: tensor([26.3894], grad_fn=<DivBackward0>)\n",
      "Epoch 376\n",
      " ---------------------- loss: tensor([25.4729], grad_fn=<DivBackward0>)\n",
      "Epoch 377\n",
      " ---------------------- loss: tensor([25.3507], grad_fn=<DivBackward0>)\n",
      "Epoch 378\n",
      " ---------------------- loss: tensor([25.3414], grad_fn=<DivBackward0>)\n",
      "Epoch 379\n",
      " ---------------------- loss: tensor([25.3337], grad_fn=<DivBackward0>)\n",
      "Epoch 380\n",
      " ---------------------- loss: tensor([25.3143], grad_fn=<DivBackward0>)\n",
      "Epoch 381\n",
      " ---------------------- loss: tensor([25.1920], grad_fn=<DivBackward0>)\n",
      "Epoch 382\n",
      " ---------------------- loss: tensor([24.5419], grad_fn=<DivBackward0>)\n",
      "Epoch 383\n",
      " ---------------------- loss: tensor([24.3927], grad_fn=<DivBackward0>)\n",
      "Epoch 384\n",
      " ---------------------- loss: tensor([24.4393], grad_fn=<DivBackward0>)\n",
      "Epoch 385\n",
      " ---------------------- loss: tensor([22.5042], grad_fn=<DivBackward0>)\n",
      "Epoch 386\n",
      " ---------------------- loss: tensor([22.4938], grad_fn=<DivBackward0>)\n",
      "Epoch 387\n",
      " ---------------------- loss: tensor([22.4859], grad_fn=<DivBackward0>)\n",
      "Epoch 388\n",
      " ---------------------- loss: tensor([22.4902], grad_fn=<DivBackward0>)\n",
      "Epoch 389\n",
      " ---------------------- loss: tensor([22.4672], grad_fn=<DivBackward0>)\n",
      "Epoch 390\n",
      " ---------------------- loss: tensor([22.4433], grad_fn=<DivBackward0>)\n",
      "Epoch 391\n",
      " ---------------------- loss: tensor([22.4651], grad_fn=<DivBackward0>)\n",
      "Epoch 392\n",
      " ---------------------- loss: tensor([22.4320], grad_fn=<DivBackward0>)\n",
      "Epoch 393\n",
      " ---------------------- loss: tensor([22.4229], grad_fn=<DivBackward0>)\n",
      "Epoch 394\n",
      " ---------------------- loss: tensor([22.4202], grad_fn=<DivBackward0>)\n",
      "Epoch 395\n",
      " ---------------------- loss: tensor([22.4069], grad_fn=<DivBackward0>)\n",
      "Epoch 396\n",
      " ---------------------- loss: tensor([22.3684], grad_fn=<DivBackward0>)\n",
      "Epoch 397\n",
      " ---------------------- loss: tensor([22.3678], grad_fn=<DivBackward0>)\n",
      "Epoch 398\n",
      " ---------------------- loss: tensor([22.3137], grad_fn=<DivBackward0>)\n",
      "Epoch 399\n",
      " ---------------------- loss: tensor([22.2671], grad_fn=<DivBackward0>)\n",
      "Epoch 400\n",
      " ---------------------- loss: tensor([22.1495], grad_fn=<DivBackward0>)\n",
      "Epoch 401\n",
      " ---------------------- loss: tensor([21.9910], grad_fn=<DivBackward0>)\n",
      "Epoch 402\n",
      " ---------------------- loss: tensor([21.9884], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403\n",
      " ---------------------- loss: tensor([21.9797], grad_fn=<DivBackward0>)\n",
      "Epoch 404\n",
      " ---------------------- loss: tensor([21.9796], grad_fn=<DivBackward0>)\n",
      "Epoch 405\n",
      " ---------------------- loss: tensor([21.9775], grad_fn=<DivBackward0>)\n",
      "Epoch 406\n",
      " ---------------------- loss: tensor([21.9647], grad_fn=<DivBackward0>)\n",
      "Epoch 407\n",
      " ---------------------- loss: tensor([21.9485], grad_fn=<DivBackward0>)\n",
      "Epoch 408\n",
      " ---------------------- loss: tensor([21.9440], grad_fn=<DivBackward0>)\n",
      "Epoch 409\n",
      " ---------------------- loss: tensor([21.9343], grad_fn=<DivBackward0>)\n",
      "Epoch 410\n",
      " ---------------------- loss: tensor([21.8978], grad_fn=<DivBackward0>)\n",
      "Epoch 411\n",
      " ---------------------- loss: tensor([21.8871], grad_fn=<DivBackward0>)\n",
      "Epoch 412\n",
      " ---------------------- loss: tensor([21.8826], grad_fn=<DivBackward0>)\n",
      "Epoch 413\n",
      " ---------------------- loss: tensor([21.8742], grad_fn=<DivBackward0>)\n",
      "Epoch 414\n",
      " ---------------------- loss: tensor([21.8846], grad_fn=<DivBackward0>)\n",
      "Epoch 415\n",
      " ---------------------- loss: tensor([21.8901], grad_fn=<DivBackward0>)\n",
      "Epoch 416\n",
      " ---------------------- loss: tensor([21.8764], grad_fn=<DivBackward0>)\n",
      "Epoch 417\n",
      " ---------------------- loss: tensor([21.8655], grad_fn=<DivBackward0>)\n",
      "Epoch 418\n",
      " ---------------------- loss: tensor([21.8636], grad_fn=<DivBackward0>)\n",
      "Epoch 419\n",
      " ---------------------- loss: tensor([21.8662], grad_fn=<DivBackward0>)\n",
      "Epoch 420\n",
      " ---------------------- loss: tensor([21.8595], grad_fn=<DivBackward0>)\n",
      "Epoch 421\n",
      " ---------------------- loss: tensor([21.8581], grad_fn=<DivBackward0>)\n",
      "Epoch 422\n",
      " ---------------------- loss: tensor([21.8486], grad_fn=<DivBackward0>)\n",
      "Epoch 423\n",
      " ---------------------- loss: tensor([21.8450], grad_fn=<DivBackward0>)\n",
      "Epoch 424\n",
      " ---------------------- loss: tensor([21.8256], grad_fn=<DivBackward0>)\n",
      "Epoch 425\n",
      " ---------------------- loss: tensor([21.7790], grad_fn=<DivBackward0>)\n",
      "Epoch 426\n",
      " ---------------------- loss: tensor([21.5405], grad_fn=<DivBackward0>)\n",
      "Epoch 427\n",
      " ---------------------- loss: tensor([21.5086], grad_fn=<DivBackward0>)\n",
      "Epoch 428\n",
      " ---------------------- loss: tensor([21.5027], grad_fn=<DivBackward0>)\n",
      "Epoch 429\n",
      " ---------------------- loss: tensor([21.4625], grad_fn=<DivBackward0>)\n",
      "Epoch 430\n",
      " ---------------------- loss: tensor([21.4294], grad_fn=<DivBackward0>)\n",
      "Epoch 431\n",
      " ---------------------- loss: tensor([21.3756], grad_fn=<DivBackward0>)\n",
      "Epoch 432\n",
      " ---------------------- loss: tensor([21.3240], grad_fn=<DivBackward0>)\n",
      "Epoch 433\n",
      " ---------------------- loss: tensor([21.3097], grad_fn=<DivBackward0>)\n",
      "Epoch 434\n",
      " ---------------------- loss: tensor([21.3229], grad_fn=<DivBackward0>)\n",
      "Epoch 435\n",
      " ---------------------- loss: tensor([21.3330], grad_fn=<DivBackward0>)\n",
      "Epoch 436\n",
      " ---------------------- loss: tensor([21.3055], grad_fn=<DivBackward0>)\n",
      "Epoch 437\n",
      " ---------------------- loss: tensor([21.2340], grad_fn=<DivBackward0>)\n",
      "Epoch 438\n",
      " ---------------------- loss: tensor([21.1590], grad_fn=<DivBackward0>)\n",
      "Epoch 439\n",
      " ---------------------- loss: tensor([21.0430], grad_fn=<DivBackward0>)\n",
      "Epoch 440\n",
      " ---------------------- loss: tensor([21.0424], grad_fn=<DivBackward0>)\n",
      "Epoch 441\n",
      " ---------------------- loss: tensor([21.0383], grad_fn=<DivBackward0>)\n",
      "Epoch 442\n",
      " ---------------------- loss: tensor([21.0403], grad_fn=<DivBackward0>)\n",
      "Epoch 443\n",
      " ---------------------- loss: tensor([21.0269], grad_fn=<DivBackward0>)\n",
      "Epoch 444\n",
      " ---------------------- loss: tensor([21.0221], grad_fn=<DivBackward0>)\n",
      "Epoch 445\n",
      " ---------------------- loss: tensor([20.8400], grad_fn=<DivBackward0>)\n",
      "Epoch 446\n",
      " ---------------------- loss: tensor([20.8381], grad_fn=<DivBackward0>)\n",
      "Epoch 447\n",
      " ---------------------- loss: tensor([20.8372], grad_fn=<DivBackward0>)\n",
      "Epoch 448\n",
      " ---------------------- loss: tensor([20.8204], grad_fn=<DivBackward0>)\n",
      "Epoch 449\n",
      " ---------------------- loss: tensor([20.7528], grad_fn=<DivBackward0>)\n",
      "Epoch 450\n",
      " ---------------------- loss: tensor([20.7306], grad_fn=<DivBackward0>)\n",
      "Epoch 451\n",
      " ---------------------- loss: tensor([20.7202], grad_fn=<DivBackward0>)\n",
      "Epoch 452\n",
      " ---------------------- loss: tensor([20.5973], grad_fn=<DivBackward0>)\n",
      "Epoch 453\n",
      " ---------------------- loss: tensor([20.2124], grad_fn=<DivBackward0>)\n",
      "Epoch 454\n",
      " ---------------------- loss: tensor([20.2103], grad_fn=<DivBackward0>)\n",
      "Epoch 455\n",
      " ---------------------- loss: tensor([20.2033], grad_fn=<DivBackward0>)\n",
      "Epoch 456\n",
      " ---------------------- loss: tensor([20.2025], grad_fn=<DivBackward0>)\n",
      "Epoch 457\n",
      " ---------------------- loss: tensor([20.1641], grad_fn=<DivBackward0>)\n",
      "Epoch 458\n",
      " ---------------------- loss: tensor([20.1631], grad_fn=<DivBackward0>)\n",
      "Epoch 459\n",
      " ---------------------- loss: tensor([20.1648], grad_fn=<DivBackward0>)\n",
      "Epoch 460\n",
      " ---------------------- loss: tensor([20.1619], grad_fn=<DivBackward0>)\n",
      "Epoch 461\n",
      " ---------------------- loss: tensor([20.1637], grad_fn=<DivBackward0>)\n",
      "Epoch 462\n",
      " ---------------------- loss: tensor([20.1634], grad_fn=<DivBackward0>)\n",
      "Epoch 463\n",
      " ---------------------- loss: tensor([20.1646], grad_fn=<DivBackward0>)\n",
      "Epoch 464\n",
      " ---------------------- loss: tensor([20.1658], grad_fn=<DivBackward0>)\n",
      "Epoch 465\n",
      " ---------------------- loss: tensor([20.1658], grad_fn=<DivBackward0>)\n",
      "Epoch 466\n",
      " ---------------------- loss: tensor([20.1658], grad_fn=<DivBackward0>)\n",
      "Epoch 467\n",
      " ---------------------- loss: tensor([20.1645], grad_fn=<DivBackward0>)\n",
      "Epoch 468\n",
      " ---------------------- loss: tensor([20.1645], grad_fn=<DivBackward0>)\n",
      "Epoch 469\n",
      " ---------------------- loss: tensor([20.1663], grad_fn=<DivBackward0>)\n",
      "Epoch 470\n",
      " ---------------------- loss: tensor([20.1668], grad_fn=<DivBackward0>)\n",
      "Epoch 471\n",
      " ---------------------- loss: tensor([20.1671], grad_fn=<DivBackward0>)\n",
      "Epoch 472\n",
      " ---------------------- loss: tensor([20.1672], grad_fn=<DivBackward0>)\n",
      "Epoch 473\n",
      " ---------------------- loss: tensor([20.1689], grad_fn=<DivBackward0>)\n",
      "Epoch 474\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 475\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 476\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 477\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 478\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 479\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 480\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 481\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 482\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 483\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 484\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 485\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 486\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 487\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 488\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 489\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 490\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 491\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 492\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 493\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 494\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 495\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 496\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 497\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 498\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 499\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 500\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 501\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 502\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 503\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 504\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 505\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 506\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 507\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 508\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 509\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 510\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 511\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 512\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 514\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 515\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 516\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 517\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 518\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 519\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 520\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 521\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 522\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 523\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 524\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 525\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 526\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 527\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 528\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 529\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 530\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 531\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 532\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 533\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 534\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 535\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 536\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 537\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 538\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 539\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 540\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 541\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 542\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 543\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 544\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 545\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 546\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 547\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 548\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 549\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 550\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 551\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 552\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 553\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 554\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 555\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 556\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 557\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 558\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 559\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 560\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 561\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 562\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 563\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 564\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 565\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 566\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 567\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 568\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 569\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 570\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 571\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 572\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 573\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 574\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 575\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 576\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 577\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 578\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 579\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 580\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 581\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 582\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 583\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 584\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 585\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 586\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 587\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 588\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 589\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 590\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 591\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 592\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 593\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 594\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 595\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 596\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 597\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 598\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 599\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 600\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 601\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 602\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 603\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 604\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 605\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 606\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 607\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 608\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 609\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 610\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 611\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 612\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 613\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 615\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 616\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 617\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 618\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 619\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 620\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 621\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 622\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 623\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 624\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 625\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 626\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 627\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 628\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 629\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 630\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 631\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 632\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 633\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 634\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 635\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 636\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 637\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 638\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 639\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 640\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 641\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 642\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 643\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 644\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 645\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 646\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 647\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 648\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 649\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 650\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 651\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 652\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 653\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 654\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 655\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 656\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 657\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 658\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 659\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 660\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 661\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 662\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 663\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 664\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 665\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 666\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 667\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 668\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 669\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 670\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 671\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 672\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 673\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 674\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 675\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 676\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 677\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 678\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 679\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 680\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 681\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 682\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 683\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 684\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 685\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 686\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 687\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 688\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 689\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 690\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 691\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 692\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 693\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 694\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 695\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 696\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 697\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 698\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 699\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 700\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 701\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 702\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 703\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 704\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 705\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 706\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 707\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 708\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 709\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 710\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 711\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 712\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 713\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 714\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 716\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 717\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 718\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 719\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 720\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 721\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 722\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 723\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 724\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 725\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 726\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 727\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 728\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 729\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 730\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 731\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 732\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 733\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 734\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 735\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 736\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 737\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 738\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 739\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 740\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 741\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 742\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 743\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 744\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 745\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 746\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 747\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 748\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 749\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 750\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 751\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 752\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 753\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 754\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 755\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 756\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 757\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 758\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 759\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 760\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 761\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 762\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 763\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 764\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 765\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 766\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 767\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 768\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 769\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 770\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 771\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 772\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 773\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 774\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 775\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 776\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 777\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 778\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 779\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 780\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 781\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 782\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 783\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 784\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 785\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 786\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 787\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 788\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 789\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 790\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 791\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 792\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 793\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 794\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 795\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 796\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 797\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 798\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 799\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 800\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 801\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 802\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 803\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 804\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 805\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 806\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 807\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 808\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 809\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 810\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 811\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 812\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 813\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 814\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 815\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 816\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 817\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 818\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 819\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 820\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 821\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 822\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 823\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 824\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 825\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 826\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 827\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 828\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 829\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 830\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 831\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 832\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 833\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 834\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 835\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 836\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 837\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 838\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 839\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 840\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 841\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 842\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 843\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 844\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 845\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 846\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 847\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 848\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 849\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 850\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 851\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 852\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 853\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 854\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 855\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 856\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 857\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 858\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 859\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 860\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 861\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 862\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 863\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 864\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 865\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 866\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 867\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 868\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 869\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 870\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 871\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 872\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 873\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 874\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 875\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 876\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 877\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 878\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 879\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 880\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 881\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 882\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 883\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 884\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 885\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 886\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 887\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 888\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 889\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 890\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 891\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 892\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 893\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 894\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 895\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 896\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 897\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 898\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 899\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 900\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 901\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 902\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 903\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 904\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 905\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 906\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 907\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 908\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 909\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 910\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 911\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 912\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 913\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 914\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 915\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 916\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 917\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 918\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 919\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 920\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 921\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 922\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 923\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 924\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 925\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 926\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 927\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 928\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 929\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 930\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 931\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 932\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 933\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 934\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 935\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 936\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 937\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 938\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 939\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 940\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 941\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 942\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 943\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 944\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 945\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 946\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 947\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 948\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 949\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 950\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 951\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 952\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 953\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 954\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 955\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 956\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 957\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 958\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 959\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 960\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 961\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 962\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 964\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 965\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 966\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 967\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 968\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 969\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 970\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 971\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 972\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 973\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 974\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 975\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 976\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 977\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 978\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 979\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 980\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 981\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 982\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 983\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 984\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 985\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 986\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 987\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 988\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 989\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 990\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 991\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 992\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 993\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 994\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 995\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 996\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 997\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 998\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 999\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Epoch 1000\n",
      " ---------------------- loss: tensor([20.1712], grad_fn=<DivBackward0>)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "upper_r = 6\n",
    "lower_r = 1e-2\n",
    "steps = 100\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "epoch = 1000\n",
    "lr = 2e-4\n",
    "Phis_t = []\n",
    "Es = []\n",
    "lss = []\n",
    "epochs = []\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "initialize_weights(model)\n",
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=lr)\n",
    "for t in range(epoch):\n",
    "    lss_aux = loss_fn(R_train.to(device))\n",
    "    print(f\"Epoch {t+1}\\n ---------------------- loss: {lss_aux}\")\n",
    "    training(R_train, loss_fn, optimizer)\n",
    "    if t%10 == 0:\n",
    "        Phis_t.append(Phi_t(R_train).detach().numpy())\n",
    "        Es.append(E.detach().numpy())\n",
    "        lss.append(lss_aux.detach().numpy())\n",
    "        epochs.append(t)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "21d7ada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = np.linspace(lower_r, upper_r, steps)[:,None]\n",
    "fig, axs = plt.subplots(3,3,figsize=(15,10))\n",
    "\n",
    "fil = 0\n",
    "col = 0\n",
    "for i in range(1,10):\n",
    "    yy = Phis_t[i]\n",
    "    axs[fil,col].plot(rr, yy.squeeze(), \".\", label=f\"Epochs {epochs[i]}\")\n",
    "    axs[fil,col].set_xlabel(\"$r$\")\n",
    "    axs[fil,col].set_ylabel(\"$\\phi(x)$\")\n",
    "    axs[fil,col].legend(loc=\"best\")\n",
    "    axs[fil,col].ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    if col == 2:\n",
    "       col = 0\n",
    "       fil = fil+1\n",
    "    else:\n",
    "       col = col+1\n",
    "plt.tight_layout()\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b0a3d3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(1,2,figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, Es, \"r.\", label=\"Energies\")\n",
    "plt.title(\"Eigenvalues of Energy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Energy\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, lss, \"b.\", label=\"Losses\")\n",
    "plt.title(\"Loss per 100 epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "19c307db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.19818582], dtype=float32),\n",
       " array([0.19818582], dtype=float32),\n",
       " array([0.19818582], dtype=float32),\n",
       " array([0.19818582], dtype=float32),\n",
       " array([0.19818582], dtype=float32)]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Es[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcbec1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efcc3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
