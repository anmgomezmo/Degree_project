{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb94f89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020576f",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d970ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(1,10),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(10,1, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N = self.layers(x)\n",
    "        return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a56de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x, loss_fn, optimizer):\n",
    "    x = x.to(device)\n",
    "    def closure():\n",
    "        loss = loss_fn(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d63b2",
   "metadata": {},
   "source": [
    "### Differential equation\n",
    "$$\\frac{d^2\\phi(r)}{dr^2} + \\frac{2m}{\\hbar^2}\\left(E-\\frac{l(l+1)}{2mr^2}\\hbar^2-V(r)\\right)\\phi(r) = 0$$ \n",
    "Dataset are vectors of domain of differential equation, like the vectors are one-dimentional, the shape of dataset is one by m samples. Trial solution $\\phi_t(r) = e^{-\\beta r^2}N(r,\\vec{p})$, with $\\phi(r=0) = 0$ and $\\phi(r\\rightarrow\\infty) = 0$ as boundary conditions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03384e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=10, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=10, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19eb90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.LBFGS(model.parameters(), lr=0.0001)\n",
    "beta = 2\n",
    "global Z\n",
    "Z = 1\n",
    "global e\n",
    "#e = -1.602e-19\n",
    "e = -1\n",
    "global hbar\n",
    "#hbar = 1.054e-34\n",
    "hbar = 1\n",
    "global m\n",
    "#m = 9.109e-31\n",
    "m = 1\n",
    "global l\n",
    "l = 0\n",
    "V = lambda r: -(Z*e**2)/r\n",
    "Phi_t = lambda r: torch.exp(-beta*r**2) * model.forward(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e21bb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(r):\n",
    "    r.requires_grad = True\n",
    "    \n",
    "    outputs = Phi_t(r)\n",
    "    Phi_t_r = torch.autograd.grad(outputs, r, grad_outputs=torch.ones_like(outputs), create_graph=True)[0]\n",
    "    Phi_t_r_r = torch.autograd.grad(Phi_t_r, r, grad_outputs=torch.ones_like(Phi_t_r), create_graph=True)[0]\n",
    "    H_Phi_t = -(hbar**2/(2*m))*Phi_t_r_r + (l*(l+1)*hbar**2/(2*m*r**2) + V(r))*outputs\n",
    "    \n",
    "    prom = outputs.size()[0]\n",
    "    \n",
    "    delta = r[1]-r[0]\n",
    "    norm = torch.sum(outputs**2)*delta\n",
    "    \n",
    "    global E\n",
    "    E = (torch.sum(outputs*H_Phi_t)*delta)/norm\n",
    "    \n",
    "    return (torch.mean((H_Phi_t - E*outputs)**2)*prom)/norm #multiply by m to avoit division by m in the mean function of torh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "959e5101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------- loss: tensor([18261.6543], grad_fn=<DivBackward0>)\n",
      "Epoch 2\n",
      " ---------------------- loss: tensor([204.1204], grad_fn=<DivBackward0>)\n",
      "Epoch 3\n",
      " ---------------------- loss: tensor([203.4663], grad_fn=<DivBackward0>)\n",
      "Epoch 4\n",
      " ---------------------- loss: tensor([202.8147], grad_fn=<DivBackward0>)\n",
      "Epoch 5\n",
      " ---------------------- loss: tensor([202.1600], grad_fn=<DivBackward0>)\n",
      "Epoch 6\n",
      " ---------------------- loss: tensor([201.5081], grad_fn=<DivBackward0>)\n",
      "Epoch 7\n",
      " ---------------------- loss: tensor([200.8564], grad_fn=<DivBackward0>)\n",
      "Epoch 8\n",
      " ---------------------- loss: tensor([200.2056], grad_fn=<DivBackward0>)\n",
      "Epoch 9\n",
      " ---------------------- loss: tensor([199.5465], grad_fn=<DivBackward0>)\n",
      "Epoch 10\n",
      " ---------------------- loss: tensor([198.8852], grad_fn=<DivBackward0>)\n",
      "Epoch 11\n",
      " ---------------------- loss: tensor([198.2242], grad_fn=<DivBackward0>)\n",
      "Epoch 12\n",
      " ---------------------- loss: tensor([197.5576], grad_fn=<DivBackward0>)\n",
      "Epoch 13\n",
      " ---------------------- loss: tensor([196.8899], grad_fn=<DivBackward0>)\n",
      "Epoch 14\n",
      " ---------------------- loss: tensor([196.2148], grad_fn=<DivBackward0>)\n",
      "Epoch 15\n",
      " ---------------------- loss: tensor([195.5314], grad_fn=<DivBackward0>)\n",
      "Epoch 16\n",
      " ---------------------- loss: tensor([194.8336], grad_fn=<DivBackward0>)\n",
      "Epoch 17\n",
      " ---------------------- loss: tensor([194.1083], grad_fn=<DivBackward0>)\n",
      "Epoch 18\n",
      " ---------------------- loss: tensor([193.3396], grad_fn=<DivBackward0>)\n",
      "Epoch 19\n",
      " ---------------------- loss: tensor([192.4984], grad_fn=<DivBackward0>)\n",
      "Epoch 20\n",
      " ---------------------- loss: tensor([191.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 21\n",
      " ---------------------- loss: tensor([190.4539], grad_fn=<DivBackward0>)\n",
      "Epoch 22\n",
      " ---------------------- loss: tensor([189.0255], grad_fn=<DivBackward0>)\n",
      "Epoch 23\n",
      " ---------------------- loss: tensor([186.7228], grad_fn=<DivBackward0>)\n",
      "Epoch 24\n",
      " ---------------------- loss: tensor([181.9857], grad_fn=<DivBackward0>)\n",
      "Epoch 25\n",
      " ---------------------- loss: tensor([174.8181], grad_fn=<DivBackward0>)\n",
      "Epoch 26\n",
      " ---------------------- loss: tensor([168.1572], grad_fn=<DivBackward0>)\n",
      "Epoch 27\n",
      " ---------------------- loss: tensor([162.5800], grad_fn=<DivBackward0>)\n",
      "Epoch 28\n",
      " ---------------------- loss: tensor([157.6167], grad_fn=<DivBackward0>)\n",
      "Epoch 29\n",
      " ---------------------- loss: tensor([152.7140], grad_fn=<DivBackward0>)\n",
      "Epoch 30\n",
      " ---------------------- loss: tensor([147.2770], grad_fn=<DivBackward0>)\n",
      "Epoch 31\n",
      " ---------------------- loss: tensor([141.7872], grad_fn=<DivBackward0>)\n",
      "Epoch 32\n",
      " ---------------------- loss: tensor([136.9875], grad_fn=<DivBackward0>)\n",
      "Epoch 33\n",
      " ---------------------- loss: tensor([132.8810], grad_fn=<DivBackward0>)\n",
      "Epoch 34\n",
      " ---------------------- loss: tensor([129.2859], grad_fn=<DivBackward0>)\n",
      "Epoch 35\n",
      " ---------------------- loss: tensor([125.9174], grad_fn=<DivBackward0>)\n",
      "Epoch 36\n",
      " ---------------------- loss: tensor([122.4184], grad_fn=<DivBackward0>)\n",
      "Epoch 37\n",
      " ---------------------- loss: tensor([118.7113], grad_fn=<DivBackward0>)\n",
      "Epoch 38\n",
      " ---------------------- loss: tensor([115.2542], grad_fn=<DivBackward0>)\n",
      "Epoch 39\n",
      " ---------------------- loss: tensor([112.2969], grad_fn=<DivBackward0>)\n",
      "Epoch 40\n",
      " ---------------------- loss: tensor([109.7082], grad_fn=<DivBackward0>)\n",
      "Epoch 41\n",
      " ---------------------- loss: tensor([107.3491], grad_fn=<DivBackward0>)\n",
      "Epoch 42\n",
      " ---------------------- loss: tensor([105.1914], grad_fn=<DivBackward0>)\n",
      "Epoch 43\n",
      " ---------------------- loss: tensor([102.9463], grad_fn=<DivBackward0>)\n",
      "Epoch 44\n",
      " ---------------------- loss: tensor([100.3463], grad_fn=<DivBackward0>)\n",
      "Epoch 45\n",
      " ---------------------- loss: tensor([98.1545], grad_fn=<DivBackward0>)\n",
      "Epoch 46\n",
      " ---------------------- loss: tensor([96.3934], grad_fn=<DivBackward0>)\n",
      "Epoch 47\n",
      " ---------------------- loss: tensor([94.7242], grad_fn=<DivBackward0>)\n",
      "Epoch 48\n",
      " ---------------------- loss: tensor([93.1957], grad_fn=<DivBackward0>)\n",
      "Epoch 49\n",
      " ---------------------- loss: tensor([91.9499], grad_fn=<DivBackward0>)\n",
      "Epoch 50\n",
      " ---------------------- loss: tensor([90.3917], grad_fn=<DivBackward0>)\n",
      "Epoch 51\n",
      " ---------------------- loss: tensor([88.5069], grad_fn=<DivBackward0>)\n",
      "Epoch 52\n",
      " ---------------------- loss: tensor([87.1854], grad_fn=<DivBackward0>)\n",
      "Epoch 53\n",
      " ---------------------- loss: tensor([86.0713], grad_fn=<DivBackward0>)\n",
      "Epoch 54\n",
      " ---------------------- loss: tensor([84.9152], grad_fn=<DivBackward0>)\n",
      "Epoch 55\n",
      " ---------------------- loss: tensor([83.9700], grad_fn=<DivBackward0>)\n",
      "Epoch 56\n",
      " ---------------------- loss: tensor([83.1098], grad_fn=<DivBackward0>)\n",
      "Epoch 57\n",
      " ---------------------- loss: tensor([81.7650], grad_fn=<DivBackward0>)\n",
      "Epoch 58\n",
      " ---------------------- loss: tensor([80.6324], grad_fn=<DivBackward0>)\n",
      "Epoch 59\n",
      " ---------------------- loss: tensor([79.8278], grad_fn=<DivBackward0>)\n",
      "Epoch 60\n",
      " ---------------------- loss: tensor([79.0463], grad_fn=<DivBackward0>)\n",
      "Epoch 61\n",
      " ---------------------- loss: tensor([78.2730], grad_fn=<DivBackward0>)\n",
      "Epoch 62\n",
      " ---------------------- loss: tensor([77.6424], grad_fn=<DivBackward0>)\n",
      "Epoch 63\n",
      " ---------------------- loss: tensor([76.9472], grad_fn=<DivBackward0>)\n",
      "Epoch 64\n",
      " ---------------------- loss: tensor([75.9642], grad_fn=<DivBackward0>)\n",
      "Epoch 65\n",
      " ---------------------- loss: tensor([75.2763], grad_fn=<DivBackward0>)\n",
      "Epoch 66\n",
      " ---------------------- loss: tensor([74.7606], grad_fn=<DivBackward0>)\n",
      "Epoch 67\n",
      " ---------------------- loss: tensor([74.1433], grad_fn=<DivBackward0>)\n",
      "Epoch 68\n",
      " ---------------------- loss: tensor([73.4511], grad_fn=<DivBackward0>)\n",
      "Epoch 69\n",
      " ---------------------- loss: tensor([72.9704], grad_fn=<DivBackward0>)\n",
      "Epoch 70\n",
      " ---------------------- loss: tensor([72.5343], grad_fn=<DivBackward0>)\n",
      "Epoch 71\n",
      " ---------------------- loss: tensor([71.8270], grad_fn=<DivBackward0>)\n",
      "Epoch 72\n",
      " ---------------------- loss: tensor([71.2916], grad_fn=<DivBackward0>)\n",
      "Epoch 73\n",
      " ---------------------- loss: tensor([70.8641], grad_fn=<DivBackward0>)\n",
      "Epoch 74\n",
      " ---------------------- loss: tensor([70.4318], grad_fn=<DivBackward0>)\n",
      "Epoch 75\n",
      " ---------------------- loss: tensor([70.1029], grad_fn=<DivBackward0>)\n",
      "Epoch 76\n",
      " ---------------------- loss: tensor([69.8153], grad_fn=<DivBackward0>)\n",
      "Epoch 77\n",
      " ---------------------- loss: tensor([69.5171], grad_fn=<DivBackward0>)\n",
      "Epoch 78\n",
      " ---------------------- loss: tensor([69.1808], grad_fn=<DivBackward0>)\n",
      "Epoch 79\n",
      " ---------------------- loss: tensor([69.0489], grad_fn=<DivBackward0>)\n",
      "Epoch 80\n",
      " ---------------------- loss: tensor([68.8881], grad_fn=<DivBackward0>)\n",
      "Epoch 81\n",
      " ---------------------- loss: tensor([68.6931], grad_fn=<DivBackward0>)\n",
      "Epoch 82\n",
      " ---------------------- loss: tensor([68.5629], grad_fn=<DivBackward0>)\n",
      "Epoch 83\n",
      " ---------------------- loss: tensor([68.4417], grad_fn=<DivBackward0>)\n",
      "Epoch 84\n",
      " ---------------------- loss: tensor([68.2769], grad_fn=<DivBackward0>)\n",
      "Epoch 85\n",
      " ---------------------- loss: tensor([68.1860], grad_fn=<DivBackward0>)\n",
      "Epoch 86\n",
      " ---------------------- loss: tensor([68.1373], grad_fn=<DivBackward0>)\n",
      "Epoch 87\n",
      " ---------------------- loss: tensor([67.9897], grad_fn=<DivBackward0>)\n",
      "Epoch 88\n",
      " ---------------------- loss: tensor([67.8519], grad_fn=<DivBackward0>)\n",
      "Epoch 89\n",
      " ---------------------- loss: tensor([67.7798], grad_fn=<DivBackward0>)\n",
      "Epoch 90\n",
      " ---------------------- loss: tensor([67.6884], grad_fn=<DivBackward0>)\n",
      "Epoch 91\n",
      " ---------------------- loss: tensor([67.6021], grad_fn=<DivBackward0>)\n",
      "Epoch 92\n",
      " ---------------------- loss: tensor([67.5325], grad_fn=<DivBackward0>)\n",
      "Epoch 93\n",
      " ---------------------- loss: tensor([67.4096], grad_fn=<DivBackward0>)\n",
      "Epoch 94\n",
      " ---------------------- loss: tensor([67.3363], grad_fn=<DivBackward0>)\n",
      "Epoch 95\n",
      " ---------------------- loss: tensor([67.2288], grad_fn=<DivBackward0>)\n",
      "Epoch 96\n",
      " ---------------------- loss: tensor([66.8446], grad_fn=<DivBackward0>)\n",
      "Epoch 97\n",
      " ---------------------- loss: tensor([66.8243], grad_fn=<DivBackward0>)\n",
      "Epoch 98\n",
      " ---------------------- loss: tensor([66.3608], grad_fn=<DivBackward0>)\n",
      "Epoch 99\n",
      " ---------------------- loss: tensor([66.3212], grad_fn=<DivBackward0>)\n",
      "Epoch 100\n",
      " ---------------------- loss: tensor([66.2358], grad_fn=<DivBackward0>)\n",
      "Epoch 101\n",
      " ---------------------- loss: tensor([66.1229], grad_fn=<DivBackward0>)\n",
      "Epoch 102\n",
      " ---------------------- loss: tensor([66.0195], grad_fn=<DivBackward0>)\n",
      "Epoch 103\n",
      " ---------------------- loss: tensor([65.9227], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104\n",
      " ---------------------- loss: tensor([65.7871], grad_fn=<DivBackward0>)\n",
      "Epoch 105\n",
      " ---------------------- loss: tensor([65.6721], grad_fn=<DivBackward0>)\n",
      "Epoch 106\n",
      " ---------------------- loss: tensor([65.5894], grad_fn=<DivBackward0>)\n",
      "Epoch 107\n",
      " ---------------------- loss: tensor([65.4887], grad_fn=<DivBackward0>)\n",
      "Epoch 108\n",
      " ---------------------- loss: tensor([64.5562], grad_fn=<DivBackward0>)\n",
      "Epoch 109\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 110\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 111\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 112\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 113\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 114\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 115\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 116\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 117\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 118\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 119\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 120\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 121\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 122\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 123\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 124\n",
      " ---------------------- loss: tensor([64.5561], grad_fn=<DivBackward0>)\n",
      "Epoch 125\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 126\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 127\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 128\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 129\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 130\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 131\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 132\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 133\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 134\n",
      " ---------------------- loss: tensor([64.5560], grad_fn=<DivBackward0>)\n",
      "Epoch 135\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 136\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 137\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 138\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 139\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 140\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 141\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 142\n",
      " ---------------------- loss: tensor([64.5558], grad_fn=<DivBackward0>)\n",
      "Epoch 143\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 144\n",
      " ---------------------- loss: tensor([64.5558], grad_fn=<DivBackward0>)\n",
      "Epoch 145\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 146\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 147\n",
      " ---------------------- loss: tensor([64.5558], grad_fn=<DivBackward0>)\n",
      "Epoch 148\n",
      " ---------------------- loss: tensor([64.5558], grad_fn=<DivBackward0>)\n",
      "Epoch 149\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 150\n",
      " ---------------------- loss: tensor([64.5558], grad_fn=<DivBackward0>)\n",
      "Epoch 151\n",
      " ---------------------- loss: tensor([64.5559], grad_fn=<DivBackward0>)\n",
      "Epoch 152\n",
      " ---------------------- loss: tensor([64.5558], grad_fn=<DivBackward0>)\n",
      "Epoch 153\n",
      " ---------------------- loss: tensor([64.5558], grad_fn=<DivBackward0>)\n",
      "Epoch 154\n",
      " ---------------------- loss: tensor([64.5558], grad_fn=<DivBackward0>)\n",
      "Epoch 155\n",
      " ---------------------- loss: tensor([64.5558], grad_fn=<DivBackward0>)\n",
      "Epoch 156\n",
      " ---------------------- loss: tensor([64.5558], grad_fn=<DivBackward0>)\n",
      "Epoch 157\n",
      " ---------------------- loss: tensor([64.5557], grad_fn=<DivBackward0>)\n",
      "Epoch 158\n",
      " ---------------------- loss: tensor([64.5555], grad_fn=<DivBackward0>)\n",
      "Epoch 159\n",
      " ---------------------- loss: tensor([64.5554], grad_fn=<DivBackward0>)\n",
      "Epoch 160\n",
      " ---------------------- loss: tensor([64.5551], grad_fn=<DivBackward0>)\n",
      "Epoch 161\n",
      " ---------------------- loss: tensor([64.5550], grad_fn=<DivBackward0>)\n",
      "Epoch 162\n",
      " ---------------------- loss: tensor([64.5550], grad_fn=<DivBackward0>)\n",
      "Epoch 163\n",
      " ---------------------- loss: tensor([64.5549], grad_fn=<DivBackward0>)\n",
      "Epoch 164\n",
      " ---------------------- loss: tensor([64.5548], grad_fn=<DivBackward0>)\n",
      "Epoch 165\n",
      " ---------------------- loss: tensor([64.5545], grad_fn=<DivBackward0>)\n",
      "Epoch 166\n",
      " ---------------------- loss: tensor([64.5542], grad_fn=<DivBackward0>)\n",
      "Epoch 167\n",
      " ---------------------- loss: tensor([64.5541], grad_fn=<DivBackward0>)\n",
      "Epoch 168\n",
      " ---------------------- loss: tensor([64.5540], grad_fn=<DivBackward0>)\n",
      "Epoch 169\n",
      " ---------------------- loss: tensor([64.5540], grad_fn=<DivBackward0>)\n",
      "Epoch 170\n",
      " ---------------------- loss: tensor([64.5539], grad_fn=<DivBackward0>)\n",
      "Epoch 171\n",
      " ---------------------- loss: tensor([64.5537], grad_fn=<DivBackward0>)\n",
      "Epoch 172\n",
      " ---------------------- loss: tensor([64.5537], grad_fn=<DivBackward0>)\n",
      "Epoch 173\n",
      " ---------------------- loss: tensor([64.5535], grad_fn=<DivBackward0>)\n",
      "Epoch 174\n",
      " ---------------------- loss: tensor([64.5535], grad_fn=<DivBackward0>)\n",
      "Epoch 175\n",
      " ---------------------- loss: tensor([64.5532], grad_fn=<DivBackward0>)\n",
      "Epoch 176\n",
      " ---------------------- loss: tensor([64.5531], grad_fn=<DivBackward0>)\n",
      "Epoch 177\n",
      " ---------------------- loss: tensor([64.5529], grad_fn=<DivBackward0>)\n",
      "Epoch 178\n",
      " ---------------------- loss: tensor([64.5529], grad_fn=<DivBackward0>)\n",
      "Epoch 179\n",
      " ---------------------- loss: tensor([64.5526], grad_fn=<DivBackward0>)\n",
      "Epoch 180\n",
      " ---------------------- loss: tensor([64.5526], grad_fn=<DivBackward0>)\n",
      "Epoch 181\n",
      " ---------------------- loss: tensor([64.5525], grad_fn=<DivBackward0>)\n",
      "Epoch 182\n",
      " ---------------------- loss: tensor([64.5523], grad_fn=<DivBackward0>)\n",
      "Epoch 183\n",
      " ---------------------- loss: tensor([64.5523], grad_fn=<DivBackward0>)\n",
      "Epoch 184\n",
      " ---------------------- loss: tensor([64.5522], grad_fn=<DivBackward0>)\n",
      "Epoch 185\n",
      " ---------------------- loss: tensor([64.5522], grad_fn=<DivBackward0>)\n",
      "Epoch 186\n",
      " ---------------------- loss: tensor([64.5522], grad_fn=<DivBackward0>)\n",
      "Epoch 187\n",
      " ---------------------- loss: tensor([64.5521], grad_fn=<DivBackward0>)\n",
      "Epoch 188\n",
      " ---------------------- loss: tensor([64.5521], grad_fn=<DivBackward0>)\n",
      "Epoch 189\n",
      " ---------------------- loss: tensor([64.5520], grad_fn=<DivBackward0>)\n",
      "Epoch 190\n",
      " ---------------------- loss: tensor([64.5519], grad_fn=<DivBackward0>)\n",
      "Epoch 191\n",
      " ---------------------- loss: tensor([64.5516], grad_fn=<DivBackward0>)\n",
      "Epoch 192\n",
      " ---------------------- loss: tensor([64.5515], grad_fn=<DivBackward0>)\n",
      "Epoch 193\n",
      " ---------------------- loss: tensor([64.5513], grad_fn=<DivBackward0>)\n",
      "Epoch 194\n",
      " ---------------------- loss: tensor([64.5512], grad_fn=<DivBackward0>)\n",
      "Epoch 195\n",
      " ---------------------- loss: tensor([64.5511], grad_fn=<DivBackward0>)\n",
      "Epoch 196\n",
      " ---------------------- loss: tensor([64.5509], grad_fn=<DivBackward0>)\n",
      "Epoch 197\n",
      " ---------------------- loss: tensor([64.5507], grad_fn=<DivBackward0>)\n",
      "Epoch 198\n",
      " ---------------------- loss: tensor([64.5507], grad_fn=<DivBackward0>)\n",
      "Epoch 199\n",
      " ---------------------- loss: tensor([64.5507], grad_fn=<DivBackward0>)\n",
      "Epoch 200\n",
      " ---------------------- loss: tensor([64.5504], grad_fn=<DivBackward0>)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "upper_r = 6\n",
    "lower_r = 1e-2\n",
    "steps = 100\n",
    "R_train = torch.Tensor(np.linspace(lower_r, upper_r, steps)[:,None])\n",
    "epochs = 200\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n ---------------------- loss: {loss_fn(R_train.to(device))}\")\n",
    "    training(R_train, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c3b74c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17.3116], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47e8fe7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe602d02880>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rr = np.linspace(lower_r, upper_r, steps)[:,None]\n",
    "\n",
    "with torch.no_grad():\n",
    "    yy = Phi_t(torch.Tensor(rr).to(device)).cpu().numpy()\n",
    "#yt = xx**2 + np.exp(-xx**2 / 2)/(1+xx+xx**3)\n",
    "\n",
    "fig, axs = plt.subplots(dpi=100)\n",
    "#axs.plot(xx, yt, label=\"True\")\n",
    "axs.plot(rr, yy, \".\", label=\"Neural Network Approximation\")\n",
    "axs.set_xlabel(\"$x$\")\n",
    "axs.set_ylabel(\"$\\phi(x)$\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3f006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857e160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8dcddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ff0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
