{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries required for Neural Network\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "import time \n",
    "import copy\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "dtype = torch.float\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<torch.cuda.device object at 0x7f608391c220>\n",
      "1\n",
      "NVIDIA GeForce MX230\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "# For plots\n",
    "plt.rcParams.update({'font.size':16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sin() activation function\n",
    "class mySin(torch.nn.Module):\n",
    "    @staticmethod\n",
    "    def activation_function(input):\n",
    "        return torch.sin(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative with auto-differention\n",
    "def df_dx(x,f):\n",
    "    pts = torch.ones(x.shape, dtype=dtype, device=torch.device(device))\n",
    "    return grad([f],[x],grad_outputs=pts,create_graph=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic perturbation of the evaluation points\n",
    "# force t[0]=t0 & force points to be in the t-interval\n",
    "def perturbation(grid,t0,tf,sig=0.5):\n",
    "    delta_t = grid[1] - grid[0]\n",
    "    noise = delta_t * torch.randn_like(grid) * sig\n",
    "    t = grid + noise\n",
    "    t.data[2] = torch.ones(1,1)*(-1)\n",
    "    t.data[t<t0] = t0 - t.data[t<t0]\n",
    "    t.data[t>tf] = 2*tf - t.data[t>tf]\n",
    "    t.data[0] = torch.ones(1,1)*t0\n",
    "    t.data[-1] = torch.ones(1,1)*tf\n",
    "    t.requires_grad = False\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial or parametric solution for boundary contitions \n",
    "def parametric_solution(t,nn,t0,x1,endpoint):\n",
    "    N1,N2 = nn(t)\n",
    "    # There are two parametric solutions, we take some that satisfy dirichlet conditions of radial part of hydrogen atom\n",
    "    f = 1-torch.exp(t-endpoint)\n",
    "    psi_hat = f*N1\n",
    "    return psi_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radial differential equation or eigenvalue problem of hamiltonian operator\n",
    "def hamiltonian_equation(t,psi,E,V):\n",
    "    dpsi_dx = df_dx(t,psi)\n",
    "    dpsi_dxx = df_dx(t,dpsi_dx)\n",
    "    f = dpsi_dxx + dpsi_dx*2/t + (2*E+V)*psi\n",
    "    L = (f.pow(2)).mean()\n",
    "    var_loss = (f.pow(2)).var()    # variance of f\n",
    "    H_psi = -1*dpsi_dxx/2 + V*psi\n",
    "    return L, f, H_psi, var_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives the potential at each point r\n",
    "def potential(Xs):\n",
    "    l = 0\n",
    "    Xsnp = Xs.data.numpy()     # points from tensor to numpy\n",
    "    Vnp = 2/Xsnp - l*(l+1)/Xsnp**2     # potential over numpy arrays\n",
    "    Vtorch = torch.from_numpy(Vnp) \n",
    "    return Vtorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class qNN(torch.nn.Module):\n",
    "    def __init__(self, n_hl=10):      # neurons in hidden layer\n",
    "        super(qNN,self).__init__()\n",
    "\n",
    "        # Define the activation function\n",
    "        self.activ_func = mySin()\n",
    "        # Define layers\n",
    "        self.E_in = torch.nn.Linear(1,1)\n",
    "        self.Lin_1 = torch.nn.Linear(2,n_hl)\n",
    "        self.Lin_2 = torch.nn.Linear(n_hl,n_hl)\n",
    "        self.out = torch.nn.Linear(n_hl,1)\n",
    "\n",
    "    def forward(self,t):\n",
    "            \n",
    "        In_1 = self.E_in(torch.ones_like(t))\n",
    "        L1 = self.Lin_1(torch.cat((t,In_1),1))\n",
    "        h1 = self.activ_func(L1)\n",
    "        L2 = self.Lin_2(h1)\n",
    "        h2 = self.activ_func(L2)\n",
    "        out = self.out(h2)\n",
    "\n",
    "        return out, -1*torch.abs(In_1)   # Negative energy because eigenvalues are negatives for hydrogen atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(t0, tf, x1, neurons, epochs, n_train, lr, minibatch_number=1):\n",
    "    '''        \n",
    "        Inputs\n",
    "        t0 -- left point on domain\n",
    "        tf -- right point on domain\n",
    "        x1 --\n",
    "        neurons -- number of units at hidden layer\n",
    "        epochs -- number of iterations of training\n",
    "        n_train -- number of points between t0 & tf including them\n",
    "        lr -- learning rate \n",
    "        minibatch_number -- size of minibatch for points on domain\n",
    "\n",
    "        Outputs \n",
    "\n",
    "    '''\n",
    "    \n",
    "    par2 = 0\n",
    "    model_0 = qNN(neurons)\n",
    "    model_0 = model_0.to(device)\n",
    "    model_1 = 0\n",
    "    betas = [0.999,0.9999]\n",
    "    optimizer = optim.Adam(model_0.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    # List's to save variables\n",
    "    Loss_history = []         ;         Llim = 1e+20    # Upper limit of loss\n",
    "    En_loss_history = []\n",
    "    boundary_loss_history = []\n",
    "    nontriv_loss_history = []\n",
    "    SE_loss_history = []\n",
    "    Ennontriv_loss_history = []\n",
    "    criteria_loss_history = []\n",
    "    En_history = []\n",
    "    prob_loss = []\n",
    "    EWall_history = []\n",
    "    orth_losses = []\n",
    "    var_loss_history = []\n",
    "    fc_ground = 0\n",
    "    fc_first_excited = 0\n",
    "    reinit = 0\n",
    "    orthtime = 2e+4\n",
    "\n",
    "    di = (None, 1e+20)\n",
    "    dic = {}\n",
    "    for i in range(1000):\n",
    "        dic[i] = di\n",
    "\n",
    "    grid = torch.linspace(t0,tf,n_train).rechape(-1,1)\n",
    "\n",
    "    # Training iterations\n",
    "    TeP0 = time.time()\n",
    "    walle = 0\n",
    "\n",
    "    for tt in range(epochs):\n",
    "        \n",
    "        t = torch.abs(perturbation(grid,t0,tf,sig=0.03*tf)) + 1e-1\n",
    "\n",
    "        # Batching\n",
    "        batch_size = int(n_train/minibatch_number)\n",
    "        batch_start, batch_end = 0, batch_size\n",
    "\n",
    "        idx = np.random.permutation(n_train)\n",
    "        t_b = t[idx]\n",
    "        t_b.requires_grad = True\n",
    "        t_f = t[-1]\n",
    "        t_f = t_f.reshape(-1,1)\n",
    "        t_f.requires_grad = True\n",
    "        loss = 0\n",
    "        \n",
    "        # Reinitialize weights at orthtime\n",
    "        if tt == orthtime:\n",
    "            model_0.apply(weights_init)\n",
    "\n",
    "        for nbatch in range(minibatch_number):\n",
    "            # Batch time set\n",
    "            t_mb = t_b[batch_start:batch_end].to(device)\n",
    "            norm_loss_reg = 1.0\n",
    "\n",
    "            # Neural Network solutions\n",
    "            nn, En = model_0(t_mb)\n",
    "            En_history.append(En[0].data.tolist()[0])  # Append energy values from tensor to scalar (not list)\n",
    "\n",
    "            psi = parametric_solution(t_mb, nn, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('NN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "012450d03bb01005539d256c75e43f99a367f585e0636c001d74ca2aa2e634ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
