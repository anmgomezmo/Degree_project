{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a857260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 09:49:39.719084: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-12 09:49:39.719111: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420dac5",
   "metadata": {},
   "source": [
    "## Differential equation\n",
    "$$\\frac{d\\psi}{dx} + \\left(x+\\frac{1+3x^2}{1+x+x^3} \\right)\\psi = x^3+2x+x^2\\left(\\frac{1+3x^2}{1+x+x^3} \\right)$$ \n",
    "Dataset are vectors of domain of differential equation, like the vectors are one-dimentional, the shape of dataset is one by m samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddff4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytic_sol(x):\n",
    "    psi = x**2 + np.exp(-0.5*x**2)/(1+x+x**3)\n",
    "    return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0370f90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data x:\n",
      " tf.Tensor(\n",
      "[[0.         0.11111111 0.22222222 0.33333334 0.44444445 0.5555556\n",
      "  0.6666667  0.7777778  0.8888889  1.        ]], shape=(1, 10), dtype=float32)\n",
      "Train data y:\n",
      " tf.Tensor(\n",
      "[[1.         0.90570426 0.8405067  0.80140585 0.78879434 0.8048698\n",
      "  0.8523673  0.9336293  1.0500929  1.2021769 ]], shape=(1, 10), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 09:49:47.477959: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-12 09:49:47.477987: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-12 09:49:47.478005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (littlerocket): /proc/driver/nvidia/version does not exist\n",
      "2022-03-12 09:49:47.478535: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "X_train = tf.constant(np.linspace(0,1,10), dtype=tf.float32)\n",
    "X_train = tf.reshape(X_train, (1, tf.shape(X_train)[0]))\n",
    "Y_train = analytic_sol(X_train)\n",
    "print(\"Train data x:\\n\",X_train)\n",
    "print(\"Train data y:\\n\",Y_train)\n",
    "print(type(X_train))\n",
    "print(type(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0f4a9e",
   "metadata": {},
   "source": [
    "## Implementation Neural Network model\n",
    "\n",
    "Neural Network with one hidden layer with 10 hidden units and sigmoid activation, and one linear output unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b6978",
   "metadata": {},
   "source": [
    "### Initialize random parameters and compute forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35f1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(shapes):\n",
    "    '''\n",
    "        Initialize parameters for Neural Network\n",
    "        \n",
    "        Input: \n",
    "        shape -- list of sizes for parameters\n",
    "        \n",
    "        Return:\n",
    "        parameters --  dictionary of tensors W1,b1,W2,b2,..... \n",
    "    '''\n",
    "    n_x, n_h, n_y = shapes\n",
    "    \n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=1)\n",
    "    \n",
    "    W1 = tf.Variable(initializer(shape=(n_h,n_x)))\n",
    "    b1 = tf.Variable(initializer(shape=(n_h,1)))\n",
    "    W2 = tf.Variable(initializer(shape=(n_y,n_h)))\n",
    "    b2 = tf.Variable(initializer(shape=(n_y,1)))\n",
    "    \n",
    "    parameters = {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "677778bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    '''\n",
    "        Forward propagation for model LINEAR -> SIGMOID -> LINEAR -> LINEAR\n",
    "        \n",
    "        Inputs:\n",
    "        X -- input dataset with discrete points of domain of differential equation\n",
    "        \n",
    "        Return:\n",
    "        N -- single output feedforward neural network\n",
    "    '''\n",
    "    \n",
    "    cache = []\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    Z1 = tf.math.add(tf.linalg.matmul(W1,X),b1)\n",
    "    A1 = tf.keras.activations.sigmoid(Z1)\n",
    "    Z2 = tf.linalg.matmul(W2,A1) # its posible compute with bias term b2\n",
    "    N = tf.keras.activations.linear(Z2)\n",
    "    \n",
    "    cache.append(A1)\n",
    "    \n",
    "    return N, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77dc1f",
   "metadata": {},
   "source": [
    "#### Test latest function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46190d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "(10, 1)\n",
      "(1, 10)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "shapes = [1,10,1]\n",
    "parameters = initialize_parameters(shapes)\n",
    "print(parameters[\"W1\"].shape)\n",
    "print(parameters[\"b1\"].shape)\n",
    "print(parameters[\"W2\"].shape)\n",
    "print(parameters[\"b2\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2f701d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.44261885, 0.4258489 , 0.40899485, 0.39210898, 0.37524465,\n",
       "        0.35845542, 0.34179425, 0.32531378, 0.30906472, 0.2930958 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, cache = forward_propagation(X_train, parameters)\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff338992",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "062deaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, N, cache, parameters):\n",
    "    '''\n",
    "        Compute the cost function of differential equation\n",
    "        \n",
    "        Inputs:\n",
    "        N -- output of forward propagation\n",
    "        \n",
    "        Return:\n",
    "        cost -- tensor of the cost function\n",
    "    '''\n",
    "    k = tf.shape(X)[0]\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    A1 = cache[0]\n",
    "    \n",
    "    dpsi_dx = N + tf.multiply(X, tf.linalg.matmul(tf.linalg.matmul(tf.transpose(1-A1), W1), tf.linalg.matmul(W2, A1)))\n",
    "    coeff_1 = tf.multiply(X + (1+3*X**2)/(1+X+X**3), 1 + N*X)\n",
    "    coeff_2 = X**3 + 2*X + tf.multiply(X**2, (1+3*X**2)/(1+X+X**3))\n",
    "    \n",
    "    cost = tf.reduce_sum(tf.square(dpsi_dx + coeff_1 - coeff_2))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac484fb",
   "metadata": {},
   "source": [
    "#### Test cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3833c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=98.05464>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = compute_cost(X_train, N, cache, parameters)\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1331f2a5",
   "metadata": {},
   "source": [
    "## Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73d91d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, shape, learning_rate=0.001, num_epochs = 1000, print_cost = False):\n",
    "    '''\n",
    "        Model definition of newral network for LINEAR -> SIGMOID -> LINEAR -> LINEAR\n",
    "        \n",
    "        Inputs:\n",
    "        X_train -- input dataset of points of domain\n",
    "        Y_train -- input dataset of points of analytic solution\n",
    "        X_test -- input dataset to test different points over domain\n",
    "        Y_test -- input dataset to test different points of analytic solution\n",
    "        num_epochs -- number of iterations to optimize\n",
    "        print_cost -- boolean variable to get cost\n",
    "        \n",
    "        Return:\n",
    "        parameters -- parameters learned by model \n",
    "    '''\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    parameters = initialize_parameters(shape)\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            N, cache = forward_propagation(X_train, parameters)\n",
    "            cost = compute_cost(X_train, N, cache, parameters)\n",
    "        \n",
    "        trainable_variables = [W1, b1, W2]\n",
    "        grads = tape.gradient(cost, trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "        \n",
    "    \n",
    "        if print_cost == True and epoch % 1000 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, cost))\n",
    "            costs.append(cost)\n",
    "            \n",
    "\n",
    "    return parameters, costs, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acba0cf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 133.629593\n",
      "Cost after epoch 1000: 9.869022\n",
      "Cost after epoch 2000: 2.410211\n",
      "Cost after epoch 3000: 1.801761\n",
      "Cost after epoch 4000: 1.287339\n",
      "Cost after epoch 5000: 0.877828\n",
      "Cost after epoch 6000: 0.590569\n",
      "Cost after epoch 7000: 0.405385\n",
      "Cost after epoch 8000: 0.284667\n",
      "Cost after epoch 9000: 0.202384\n",
      "Cost after epoch 10000: 0.146225\n",
      "Cost after epoch 11000: 0.111449\n",
      "Cost after epoch 12000: 0.090462\n",
      "Cost after epoch 13000: 0.077234\n",
      "Cost after epoch 14000: 0.068288\n",
      "Cost after epoch 15000: 0.061870\n",
      "Cost after epoch 16000: 0.057063\n",
      "Cost after epoch 17000: 0.053336\n",
      "Cost after epoch 18000: 0.050312\n",
      "Cost after epoch 19000: 0.047821\n",
      "Cost after epoch 20000: 0.045736\n",
      "Cost after epoch 21000: 0.043937\n",
      "Cost after epoch 22000: 0.042378\n",
      "Cost after epoch 23000: 0.041002\n",
      "Cost after epoch 24000: 0.039786\n",
      "Cost after epoch 25000: 0.038699\n",
      "Cost after epoch 26000: 0.038012\n",
      "Cost after epoch 27000: 0.036829\n",
      "Cost after epoch 28000: 0.036019\n",
      "Cost after epoch 29000: 0.035278\n",
      "Cost after epoch 30000: 0.034592\n",
      "Cost after epoch 31000: 0.033960\n",
      "Cost after epoch 32000: 0.033371\n",
      "Cost after epoch 33000: 0.032823\n",
      "Cost after epoch 34000: 0.032376\n",
      "Cost after epoch 35000: 0.031831\n",
      "Cost after epoch 36000: 0.031380\n",
      "Cost after epoch 37000: 0.030955\n",
      "Cost after epoch 38000: 0.030556\n",
      "Cost after epoch 39000: 0.030181\n",
      "Cost after epoch 40000: 0.029815\n",
      "Cost after epoch 41000: 0.029789\n",
      "Cost after epoch 42000: 0.029409\n",
      "Cost after epoch 43000: 0.028898\n",
      "Cost after epoch 44000: 0.028542\n",
      "Cost after epoch 45000: 0.028258\n",
      "Cost after epoch 46000: 0.027988\n",
      "Cost after epoch 47000: 0.027731\n",
      "Cost after epoch 48000: 0.027479\n",
      "Cost after epoch 49000: 0.027242\n",
      "Cost after epoch 50000: 0.027012\n"
     ]
    }
   ],
   "source": [
    "parameters, costs, cache = model(X_train, shape=shapes, learning_rate=0.001, num_epochs=50001, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2057f7a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': <tf.Variable 'Variable:0' shape=(10, 1) dtype=float32, numpy=\n",
       " array([[ 0.06817397],\n",
       "        [-0.34143415],\n",
       "        [ 0.13167419],\n",
       "        [-0.25099355],\n",
       "        [-0.48240745],\n",
       "        [ 0.00798735],\n",
       "        [ 0.2104287 ],\n",
       "        [-0.15750529],\n",
       "        [-0.0100722 ],\n",
       "        [-0.01821376]], dtype=float32)>,\n",
       " 'b1': <tf.Variable 'Variable:0' shape=(10, 1) dtype=float32, numpy=\n",
       " array([[ 0.5616286 ],\n",
       "        [-0.2571284 ],\n",
       "        [ 0.2928016 ],\n",
       "        [-0.40453166],\n",
       "        [ 0.03279796],\n",
       "        [ 0.32119042],\n",
       "        [ 0.24286646],\n",
       "        [-0.30586624],\n",
       "        [-0.26894614],\n",
       "        [-0.7930353 ]], dtype=float32)>,\n",
       " 'W2': <tf.Variable 'Variable:0' shape=(1, 10) dtype=float32, numpy=\n",
       " array([[ 1.6815192 , -4.3187222 ,  2.6917355 , -2.6418326 , -7.0775423 ,\n",
       "          0.86329585,  3.9608707 , -1.1994966 ,  0.8664877 ,  1.1578201 ]],\n",
       "       dtype=float32)>,\n",
       " 'b2': <tf.Variable 'Variable:0' shape=(1, 1) dtype=float32, numpy=array([[-1.2887479]], dtype=float32)>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23063531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.         0.9127715  0.86822814 0.866147   0.9062285  0.98809713\n",
      "  1.1113034  1.2753277  1.4795817  1.7234142 ]], shape=(1, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sol = 1 + tf.multiply(X_train, forward_propagation(X_train, parameters)[0])\n",
    "print(sol)\n",
    "plt.plot(X_train.numpy()[0], sol.numpy()[0], \"-b\")\n",
    "plt.plot(X_train.numpy()[0], Y_train.numpy()[0], \".r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abb8811f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[0.        , 0.00706726, 0.02772146, 0.06474113, 0.11743414,\n",
       "        0.18322736, 0.25893617, 0.3416984 , 0.42948878, 0.52123725]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = tf.abs(Y_train - sol)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bb5708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e69ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b531bd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function evaluations: 5\n",
      "tf.Tensor([1. 1.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_probability as tfp \n",
    "\n",
    "minimum = np.array([1.0, 1.0])  # The center of the quadratic bowl.\n",
    "scales = np.array([2.0, 3.0])  # The scales along the two axes.\n",
    "\n",
    "# The objective function and the gradient.\n",
    "def quadratic_loss_and_gradient(x):\n",
    "    return tfp.math.value_and_gradient(\n",
    "        lambda x: tf.reduce_sum(\n",
    "            scales * tf.math.squared_difference(x, minimum), axis=-1),\n",
    "        x)\n",
    "\n",
    "start = tf.constant([0.6, 0.8])  # Starting point for the search.\n",
    "optim_results = tfp.optimizer.bfgs_minimize(\n",
    "    quadratic_loss_and_gradient, initial_position=start, tolerance=1e-8)\n",
    "\n",
    "# Check that the search converged\n",
    "assert(optim_results.converged)\n",
    "# Check that the argmin is close to the actual value.\n",
    "np.testing.assert_allclose(optim_results.position, minimum)\n",
    "# Print out the total number of function evaluations it took. Should be 5.\n",
    "print (\"Function evaluations: %d\" % optim_results.num_objective_evaluations)\n",
    "\n",
    "print(optim_results.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f884af66",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 2 has size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquadratic_loss_and_gradient\u001b[39m(x, N, cache, parameters):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tfp\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mvalue_and_gradient(\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: compute_cost(x, N, cache, parameters),\n\u001b[1;32m      4\u001b[0m         x)\n\u001b[0;32m----> 6\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Starting point for the search.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m optim_results \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mbfgs_minimize(\n\u001b[1;32m      8\u001b[0m     quadratic_loss_and_gradient, initial_position\u001b[38;5;241m=\u001b[39mstart, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 2 has size 10"
     ]
    }
   ],
   "source": [
    "def quadratic_loss_and_gradient(x, N, cache, parameters):\n",
    "    return tfp.math.value_and_gradient(\n",
    "        lambda x: compute_cost(x, N, cache, parameters),\n",
    "        x)\n",
    "\n",
    "start = np.concatenate((parameters[\"W1\"], parameters[\"b1\"], parameters[\"W2\"]))  # Starting point for the search.\n",
    "optim_results = tfp.optimizer.bfgs_minimize(\n",
    "    quadratic_loss_and_gradient, initial_position=start, tolerance=1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37742db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
