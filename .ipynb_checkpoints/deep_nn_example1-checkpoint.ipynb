{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c625fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 14:26:46.107913: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-12 14:26:46.107941: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.activations import sigmoid, linear, relu\n",
    "from tensorflow.math import add, subtract\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72898e94",
   "metadata": {},
   "source": [
    "## Differential equation\n",
    "$$\\frac{d\\psi}{dx} + \\left(x+\\frac{1+3x^2}{1+x+x^3} \\right)\\psi = x^3+2x+x^2\\left(\\frac{1+3x^2}{1+x+x^3} \\right)$$ \n",
    "Dataset are vectors of domain of differential equation, like the vectors are one-dimentional, the shape of dataset is one by m samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04419852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytic_sol(x):\n",
    "    psi = tf.pow(x,2) + tf.exp(-0.5*tf.pow(x,2))/(1+x+tf.pow(x,3))\n",
    "    return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4f83f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-12 16:41:30.736069: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-12 16:41:30.765607: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-12 16:41:30.765685: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (littlerocket): /proc/driver/nvidia/version does not exist\n",
      "2022-03-12 16:41:30.847769: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data x:\n",
      " tf.Tensor(\n",
      "[[0.         0.05050505 0.1010101  0.15151516 0.2020202  0.25252524\n",
      "  0.3030303  0.35353535 0.4040404  0.45454547 0.5050505  0.5555556\n",
      "  0.6060606  0.65656567 0.7070707  0.75757575 0.8080808  0.85858583\n",
      "  0.90909094 0.959596   1.010101   1.060606   1.1111112  1.1616162\n",
      "  1.2121212  1.2626263  1.3131313  1.3636364  1.4141414  1.4646465\n",
      "  1.5151515  1.5656565  1.6161616  1.6666666  1.7171717  1.7676767\n",
      "  1.8181819  1.8686869  1.919192   1.969697   2.020202   2.070707\n",
      "  2.121212   2.1717172  2.2222223  2.2727273  2.3232324  2.3737373\n",
      "  2.4242425  2.4747474  2.5252526  2.5757575  2.6262627  2.6767676\n",
      "  2.7272727  2.7777777  2.8282828  2.878788   2.929293   2.979798\n",
      "  3.030303   3.0808082  3.131313   3.1818182  3.2323232  3.2828283\n",
      "  3.3333333  3.3838384  3.4343433  3.4848485  3.5353534  3.5858586\n",
      "  3.6363637  3.6868687  3.7373738  3.7878788  3.838384   3.8888888\n",
      "  3.939394   3.989899   4.040404   4.090909   4.141414   4.1919193\n",
      "  4.242424   4.292929   4.3434343  4.3939395  4.4444447  4.4949493\n",
      "  4.5454545  4.5959597  4.646465   4.6969695  4.7474747  4.79798\n",
      "  4.848485   4.8989897  4.949495   5.        ]], shape=(1, 100), dtype=float32)\n",
      "Train data y:\n",
      " tf.Tensor(\n",
      "[[ 1.          0.953144    0.91299325  0.8788814   0.85038745  0.82728523\n",
      "   0.80950373  0.79709405  0.7902      0.7890297   0.79383147  0.8048698\n",
      "   0.82240635  0.84668374  0.87791264  0.9162644   0.96186554  1.0147976\n",
      "   1.0750982   1.1427644   1.2177593   1.3000154   1.3894432   1.4859345\n",
      "   1.5893698   1.699622    1.816561    1.9400563   2.0699804   2.2062104\n",
      "   2.3486285   2.4971254   2.6515985   2.8119528   2.9781017   3.1499665\n",
      "   3.3274755   3.5105631   3.699172    3.8932505   4.0927515   4.2976356\n",
      "   4.507864    4.723407    4.9442353   5.170324    5.4016514   5.638197\n",
      "   5.8799477   6.126886    6.3790016   6.636281    6.898718    7.1663013\n",
      "   7.439027    7.716886    7.9998765   8.2879925   8.581228    8.879584\n",
      "   9.183055    9.491639    9.805335   10.124141   10.448055   10.777078\n",
      "  11.111204   11.450438   11.794775   12.144218   12.498764   12.858414\n",
      "  13.223167   13.59302    13.967979   14.348039   14.733201   15.123465\n",
      "  15.518831   15.919298   16.324867   16.73554    17.151314   17.57219\n",
      "  17.998163   18.429243   18.865421   19.306704   19.753088   20.204569\n",
      "  20.661158   21.122845   21.589636   22.061522   22.538515   23.02061\n",
      "  23.507807   24.0001     24.4975     25.        ]], shape=(1, 100), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "n_h = 10\n",
    "X_train = tf.constant(np.linspace(0,5,100), dtype=tf.float32)\n",
    "X_train = tf.reshape(X_train, (1, tf.shape(X_train)[0]))\n",
    "Y_train = analytic_sol(X_train)\n",
    "print(\"Train data x:\\n\",X_train)\n",
    "print(\"Train data y:\\n\",Y_train)\n",
    "print(type(X_train))\n",
    "print(type(Y_train))\n",
    "shapes = [tf.shape(X_train)[0],n_h,tf.shape(X_train)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a66c5f",
   "metadata": {},
   "source": [
    "## Implementation Neural Network model\n",
    "\n",
    "Neural Network with one hidden layer with 10 hidden units and sigmoid activation, and one linear output unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2d7359",
   "metadata": {},
   "source": [
    "### Initialize random parameters and compute forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c38fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(shapes):\n",
    "    '''\n",
    "        Initialize parameters for Neural Network\n",
    "        \n",
    "        Input: \n",
    "        shape -- list of sizes for parameters\n",
    "        \n",
    "        Return:\n",
    "        parameters --  dictionary of tensors W1,b1,W2,b2,..... \n",
    "    '''\n",
    "    L = len(shapes)\n",
    "    \n",
    "    parameters = {}\n",
    "    \n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=1)\n",
    "    \n",
    "    for l in range(1,L):\n",
    "        parameters[\"W\" + str(l)] = tf.Variable(initializer(shape=(shapes[l],shapes[l-1])))\n",
    "        parameters[\"b\" + str(l)] = tf.Variable(initializer(shape=(shapes[l],1)))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f09f238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "(5, 1)\n",
      "(5, 5)\n",
      "(5, 1)\n",
      "(1, 5)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters([1,5,5,1])\n",
    "print(parameters[\"W1\"].shape)\n",
    "print(parameters[\"b1\"].shape)\n",
    "print(parameters[\"W2\"].shape)\n",
    "print(parameters[\"b2\"].shape)\n",
    "print(parameters[\"W3\"].shape)\n",
    "print(parameters[\"b3\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46474054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(A_prev, W, b, activation):\n",
    "    '''\n",
    "        Forward propagation for model LINEAR -> SIGMOID -> LINEAR -> SIGMOID -> LINEAR -> LINEAR\n",
    "        \n",
    "        Inputs:\n",
    "        X -- input dataset with discrete points of domain of differential equation\n",
    "        W -- parameter W \n",
    "        B -- parameter b\n",
    "        activation --  activation function of each layer\n",
    "        \n",
    "        Return:\n",
    "        N -- single output feedforward neural network\n",
    "    '''\n",
    "    \n",
    "    cache = []\n",
    "        \n",
    "    Z = add(tf.linalg.matmul(W,A_prev),b)\n",
    "    A = activation(Z)\n",
    "    \n",
    "    cache.append((A, W, b), Z)\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9d430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
